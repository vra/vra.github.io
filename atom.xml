<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yunfeng&#39;s Simple Blog</title>
  
  <subtitle>Love, Life, Linux</subtitle>
  <link href="http://vra.github.io/atom.xml" rel="self"/>
  
  <link href="http://vra.github.io/"/>
  <updated>2023-06-30T14:42:42.742Z</updated>
  <id>http://vra.github.io/</id>
  
  <author>
    <name>Yunfeng Wang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>git diff 的一个妙用</title>
    <link href="http://vra.github.io/2023/06/30/git-diff-a-special-use-case/"/>
    <id>http://vra.github.io/2023/06/30/git-diff-a-special-use-case/</id>
    <published>2023-06-30T14:41:49.000Z</published>
    <updated>2023-06-30T14:42:42.742Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-git-diff-常规用法"><a href="#1-git-diff-常规用法" class="headerlink" title="1. git diff 常规用法"></a>1. git diff 常规用法</h3><p>git diff 可以用来比较在git仓库中的两次提交或两个文件的diff，常见用法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示当前代码与最新commit的代码之间的差别</span></span><br><span class="line">git diff</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示暂存（也就是已经git add 但还没有git commit）的代码提交</span></span><br><span class="line">git diff --staged</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示当前代码与&lt;commit-id&gt;时代码的区别</span></span><br><span class="line">git diff &lt;commit-id&gt; </span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示暂存代码与&lt;commit-id&gt;时代码的区别</span></span><br><span class="line">git diff --staged &lt;commit-id&gt; </span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示两次commit-id之间的代码区别</span></span><br><span class="line">git diff &lt;commit-id1&gt; &lt;commit-id2&gt;  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示当前分支与 branch1 分支上的代码区别</span></span><br><span class="line">git diff &lt;branch1&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示两个分支上的代码之间的区别</span></span><br><span class="line">git diff &lt;branch1&gt; &lt;branch2&gt;</span><br></pre></td></tr></table></figure><p>所有上述命令后面都可以加一个目录或文件路径来只显示这个目录或文件中的区别：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git diff /path/to/folder</span><br><span class="line"></span><br><span class="line">git diff /path/to/file.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可用git的参数终止符号--，避免文件名和参数重名时将文件名解析为参数</span></span><br><span class="line">git diff --  /path/to/file.py</span><br></pre></td></tr></table></figure><span id="more"></span><h3 id="2-git-diff-妙用"><a href="#2-git-diff-妙用" class="headerlink" title="2. git diff 妙用"></a>2. git diff 妙用</h3><p>git diff 有一个选项<code>--no-index</code> ，可以用来不在git仓库中的两个文件或目录。<br><code>--no-index</code>的git帮助文档中说明如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git diff [&lt;options&gt;] --no-index [--] &lt;path&gt; &lt;path&gt;</span><br><span class="line">This form is to compare the given two paths on the filesystem. You can omit the --no-index option when running the command in a working tree controlled by Git and at least one of the paths points outside the working tree, or when running the command outside a working tree controlled by Git. This form implies --exit-code.</span><br></pre></td></tr></table></figure><p>说明它可以用来比较两个给定的路径。</p><p>那为什么要用<code>git diff</code> 来比较非git仓库里面的两个路径呢，直接用Linux和Mac上自带的<code>diff</code> 命令不好吗？</p><p><code>git diff</code> 相比<code>diff</code> 的优势是它能生成以<code>+</code> 和<code>-</code> 开头的diff结果，红色表示删去，绿色表示添加，因此能很直观地看出增加和删除了哪些地方，而diff给出来的是黑色的代码差别，展示很不直观。</p><p>另外<code>git diff</code>的结果可以写入文件，粘贴到Markdown文件中，大部分 Markdown 渲染器都能够识别diff块，比较好地渲染出diff结果。</p><p>实际操作中，需要在一个git仓库目录中来执行<code>git diff --no-index</code>,例如比较两个文件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff --no-index ~/a.py ~/b.py</span><br></pre></td></tr></table></figure><p>比较两个目录:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff --no-index ~/folder-a ~/folder-b</span><br></pre></td></tr></table></figure><h3 id="One-More-Thing"><a href="#One-More-Thing" class="headerlink" title="One More Thing"></a>One More Thing</h3><p>其实我之前写过一个比较两个目录的Python工具<a href="https://github.com/vra/dompare">dompare</a>(名字含义是directory compare)，通过执行一条命令得到得到两个目录中文件的diff，并且保存到HTML网页中打开浏览器进行展示。感兴趣的小伙伴可以玩一玩。</p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;1-git-diff-常规用法&quot;&gt;&lt;a href=&quot;#1-git-diff-常规用法&quot; class=&quot;headerlink&quot; title=&quot;1. git diff 常规用法&quot;&gt;&lt;/a&gt;1. git diff 常规用法&lt;/h3&gt;&lt;p&gt;git diff 可以用来比较在git仓库中的两次提交或两个文件的diff，常见用法如下：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 显示当前代码与最新commit的代码之间的差别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 显示暂存（也就是已经git add 但还没有git commit）的代码提交&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff --staged&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 显示当前代码与&amp;lt;commit-id&amp;gt;时代码的区别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff &amp;lt;commit-id&amp;gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 显示暂存代码与&amp;lt;commit-id&amp;gt;时代码的区别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff --staged &amp;lt;commit-id&amp;gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 显示两次commit-id之间的代码区别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff &amp;lt;commit-id1&amp;gt; &amp;lt;commit-id2&amp;gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 显示当前分支与 branch1 分支上的代码区别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff &amp;lt;branch1&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 显示两个分支上的代码之间的区别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff &amp;lt;branch1&amp;gt; &amp;lt;branch2&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;所有上述命令后面都可以加一个目录或文件路径来只显示这个目录或文件中的区别：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git diff /path/to/folder&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff /path/to/file.py&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 也可用git的参数终止符号--，避免文件名和参数重名时将文件名解析为参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git diff --  /path/to/file.py&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    
    <category term="Git" scheme="http://vra.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>C++ std::optional 使用教程</title>
    <link href="http://vra.github.io/2023/06/30/cpp-optional-tutorial/"/>
    <id>http://vra.github.io/2023/06/30/cpp-optional-tutorial/</id>
    <published>2023-06-30T14:39:41.000Z</published>
    <updated>2023-06-30T14:40:50.994Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-std-optional-是什么"><a href="#1-std-optional-是什么" class="headerlink" title="1. std::optional 是什么"></a>1. std::optional 是什么</h3><p>C++ 17 引入了std::optional，表示一个可能有值的对象（没有值时就是默认的<code>std::nullopt</code>)，例如这个例子中，std::optional 对象 even_value，如果<code>is_even</code> 为真的话就是128，否则就是默认值<code>std::nullopt</code>: </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;optiona&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">bool</span> is_even = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 没有值的情况下 std::optional 对象的值为 std::nullopt</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; even_value = is_even ? std::optional&lt;<span class="keyword">int</span>&gt;(<span class="number">128</span>) : std::nullopt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可以用 std::optional 对象是否等于 std::nullopt 来判断 std::optional 对象是否有值</span></span><br><span class="line"><span class="keyword">if</span> (even_value != std::nullopt) &#123;</span><br><span class="line">    <span class="comment">// 采用.value 获取 std::optional 对象的值</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;has value, which is &quot;</span> &lt;&lt; even_value.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;no value&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实std::optional的作用和Python里面的<code>None</code>比较像，例如上面的例子用Python来写就是这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">is_even = <span class="literal">True</span></span><br><span class="line">even_value = <span class="number">128</span> <span class="keyword">if</span> is_even <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> even_value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;has value, which is&quot;</span>, even_value)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;no value&quot;</span>)</span><br></pre></td></tr></table></figure><span id="more"></span><h3 id="2-为什么要引入-std-optional"><a href="#2-为什么要引入-std-optional" class="headerlink" title="2. 为什么要引入 std::optional"></a>2. 为什么要引入 std::optional</h3><p>我觉得提出std::optional就是因为C++底层缺少<code>None</code> 这个表示，所以将std::nullopt和某种特定类型的变量合并在一起构造成一个<code>std::optional</code>对象，用以解决因为缺少之前<code>None</code>因而存在的一些不怎么直接的用法。</p><p>这里举个例子来说明前面提到的”不直接”的用法。这是一个寻找数组中的第一个非0元素的函数：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findFirstNonZero</span><span class="params">(<span class="keyword">int</span> arr[], <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (arr[i] != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> arr[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// 如果数组中没有非0元素，则返回-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，没找到元素时返回-1，所以当拿到-1时，没法判断是第一个非0元素为-1还是没找到非0元素。<br>改进方案是返回一个pair，第一个位置表示是否包含非0元素，第二个位置表示非0元素的值：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;utility&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">std::pair&lt;<span class="keyword">bool</span>, <span class="keyword">int</span>&gt; <span class="title">findFirstNonZero</span><span class="params">(<span class="keyword">int</span> arr[], <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (arr[i] != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> std::<span class="built_in">make_pair</span>(<span class="literal">true</span>, arr[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_pair</span>(<span class="literal">false</span>, <span class="number">-1</span>); <span class="comment">// 如果数组中没有非0元素，则返回false和-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但这样其实比较繁琐且不直观，两个变量的解析和使用成本还是有些高，如果能用一个变量来完成的话就更简洁了。</p><p>采用std::optional可以简化上面的代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;optional&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">std::optional&lt;<span class="keyword">int</span>&gt; <span class="title">findFirstNonZero</span><span class="params">(<span class="keyword">int</span> arr[], <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (arr[i] != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> arr[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> std::nullopt; <span class="comment">// 如果数组中没有非0元素，则返回std::nullopt</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里int类型的返回值可以隐式地转换为 std::optional 对象。</p><p>使用这个函数时也只需要判断一下返回值是否为<code>std::nullopt</code> 就可以。</p><p>总之可以将std::optional对象当作支持判断是否为NULL的对象的封装，在不确定对象是否存在的情况下，建议使用。</p><h3 id="3-std-optional-的构造"><a href="#3-std-optional-的构造" class="headerlink" title="3. std::optional 的构造"></a>3. std::optional 的构造</h3><p>空的 std::optional 对象可以用<code>std::nullopt</code> 或者<code>&#123;&#125;</code> 来构造，然后用<code>emplace</code> 函数来插入数值：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.0 采用 std::nullopt 初始化再调用 emplace 插入值</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val0 = std::nullopt;</span><br><span class="line">val0.<span class="built_in">emplace</span>(<span class="number">128</span>);</span><br><span class="line">std::cout &lt;&lt; val0.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.1 采用 &#123;&#125; 初始化再调用 emplace 插入值</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val1 = &#123;&#125;;</span><br><span class="line">val1.<span class="built_in">emplace</span>(<span class="number">128</span>);</span><br><span class="line">std::cout &lt;&lt; val1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><p>每次调用<code>emplace</code> 时，会清除掉之前的值，因此可以多次调用，且能保证每次都是最新的数值。</p><p>也可以用 <code>std::make_optional</code> 函数来构造：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.7 采用 std::make_optional&lt;T&gt;(val) 初始化</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val7 = std::make_optional&lt;<span class="keyword">int</span>&gt;(<span class="number">128</span>);</span><br><span class="line">std::cout &lt;&lt; val7.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.8 采用 std::make_optional(val) 初始化，自动推导变量类型</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val8 = std::<span class="built_in">make_optional</span>(<span class="number">128</span>);</span><br><span class="line">std::cout &lt;&lt; val8.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>除此之外还有很多种初始化 std::optional 对象的方法，都写在这个示例代码里面了，记得看注释：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.2 采用 std::optional&lt;T&gt;(val) 初始化</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val2 = std::optional&lt;<span class="keyword">int</span>&gt;(<span class="number">128</span>);</span><br><span class="line">std::cout &lt;&lt; val2.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.3 采用 std::optional(val) 初始化，自动推导变量类型</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val3 = std::<span class="built_in">optional</span>(<span class="number">128</span>);</span><br><span class="line">std::cout &lt;&lt; val3.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.4 采用 std::optional&lt;T&gt;&#123;val&#125; 初始化</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val4 = std::optional&lt;<span class="keyword">int</span>&gt;&#123;<span class="number">128</span>&#125;;</span><br><span class="line">std::cout &lt;&lt; val4.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.5 采用 std::optional&#123;val&#125; 初始化</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val5 = std::optional&#123;<span class="number">128</span>&#125;;</span><br><span class="line">std::cout &lt;&lt; val5.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.6 采用 &#123;val&#125; 初始化</span></span><br><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val6 = &#123;<span class="number">128</span>&#125;;</span><br><span class="line">std::cout &lt;&lt; val6.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4-std-optional-判断是否有值"><a href="#4-std-optional-判断是否有值" class="headerlink" title="4. std::optional 判断是否有值"></a>4. std::optional 判断是否有值</h3><p>判断 std::optional 对象是否有值可以用 <code>has_value</code>函数，或者判断是否不等于<code>std::nullopt</code>，或者直接用if语句对对象进行判断：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; result1 = <span class="built_in">find_the_first_postive_value</span>(pos_values);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (result1.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">    std::cout &lt;&lt; result1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (result1 != std::nullopt) &#123;</span><br><span class="line">    std::cout &lt;&lt; result1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (result1) &#123;</span><br><span class="line">    std::cout &lt;&lt; result1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-std-optional-获取值"><a href="#5-std-optional-获取值" class="headerlink" title="5. std::optional 获取值"></a>5. std::optional 获取值</h3><p>获取值的话可以用<code>.value()</code> 函数，或者<code>*</code> 运算符：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (result1) &#123;</span><br><span class="line">     std::cout &lt;&lt; result1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">if</span> (result1) &#123;</span><br><span class="line">     std::cout &lt;&lt; *result1 &lt;&lt; std::endl;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>如果想在std::optional对象为<code>std::nullopt</code>的情况下设置默认值的话，可以用<code>value_or</code> 函数：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val9 = std::nullopt;</span><br><span class="line">std::cout &lt;&lt; val9.<span class="built_in">value_or</span>(<span class="number">-1</span>) &lt;&lt; std::endl; <span class="comment">// 输出 -1</span></span><br><span class="line">val9.<span class="built_in">emplace</span>(<span class="number">128</span>);</span><br><span class="line">std::cout &lt;&lt; val9.<span class="built_in">value_or</span>(<span class="number">-1</span>) &lt;&lt; std::endl; <span class="comment">// 输出 128</span></span><br></pre></td></tr></table></figure><p>很明显，<code>value_or</code>函数中的默认值需要和optional对象的类型一致，否则会编译报错。</p><h3 id="6-没有值时的异常处理"><a href="#6-没有值时的异常处理" class="headerlink" title="6. 没有值时的异常处理"></a>6. 没有值时的异常处理</h3><p>如果在没有值的情况下调用<code>.value</code> 函数，会在运行时报错<code>std::bad_optional_access</code>:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val10 = std::nullopt;</span><br><span class="line">std::cout &lt;&lt; val10.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">libc++abi: terminating due to uncaught exception of type std::bad_optional_access: bad_optional_access</span><br></pre></td></tr></table></figure><p>所以建议使用<code>.value_or</code>来处理，如果要强行使用<code>.value</code>的话，需要使用 try-catch 语句：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">std::optional&lt;<span class="keyword">int</span>&gt; val11 = std::nullopt;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    std::cout &lt;&lt; val11.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125; <span class="built_in"><span class="keyword">catch</span></span> (<span class="keyword">const</span> std::bad_optional_access&amp; e) &#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;==&gt; error: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="7-示例代码"><a href="#7-示例代码" class="headerlink" title="7. 示例代码"></a>7. 示例代码</h3><p>上面的所有示例代码汇总：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;optional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">std::optional&lt;<span class="keyword">int</span>&gt; <span class="title">find_the_first_postive_value</span><span class="params">(<span class="keyword">const</span> std::vector&lt;<span class="keyword">int</span>&gt;&amp; values)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; val : values) &#123;</span><br><span class="line">        <span class="keyword">if</span> (val &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> std::optional&lt;<span class="keyword">int</span>&gt;(val);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> std::nullopt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::optional&lt;<span class="keyword">int</span>&gt; <span class="title">find_the_first_postive_value_v2</span><span class="params">(<span class="keyword">const</span> std::vector&lt;<span class="keyword">int</span>&gt;&amp; values)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> it = std::<span class="built_in">find_if</span>(values.<span class="built_in">begin</span>(), values.<span class="built_in">end</span>(), [](<span class="keyword">int</span> val) &#123; <span class="keyword">return</span> val &gt; <span class="number">0</span>; &#125;);</span><br><span class="line">    <span class="keyword">return</span> it != values.<span class="built_in">end</span>() ? std::<span class="built_in">make_optional</span>(*it) : std::nullopt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_backend</span><span class="params">(std::optional&lt;std::string&gt; backend)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (backend) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;==&gt; use set backend: &quot;</span> &lt;&lt; backend.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;==&gt; use default backend: CPU&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// std::optional 简单例子</span></span><br><span class="line">    <span class="keyword">bool</span> is_even = <span class="literal">true</span>;</span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; even_value = is_even ? std::optional&lt;<span class="keyword">int</span>&gt;(<span class="number">128</span>) : std::nullopt;</span><br><span class="line">    <span class="keyword">if</span> (even_value != std::nullopt) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;has value, which is &quot;</span> &lt;&lt; even_value.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;no value&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. std::optional 对象的构造</span></span><br><span class="line">    <span class="comment">// 1.0 采用 std::nullopt 初始化再调用 emplace 插入值</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val0 = std::nullopt;</span><br><span class="line">    val0.<span class="built_in">emplace</span>(<span class="number">128</span>);</span><br><span class="line">    val0.<span class="built_in">emplace</span>(<span class="number">129</span>);</span><br><span class="line">    std::cout &lt;&lt; val0.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.1 采用 &#123;&#125; 初始化再调用 emplace 插入值</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val1 = &#123;&#125;;</span><br><span class="line">    val1.<span class="built_in">emplace</span>(<span class="number">128</span>);</span><br><span class="line">    std::cout &lt;&lt; val1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.2 采用 std::optional&lt;T&gt;(val) 初始化</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val2 = std::optional&lt;<span class="keyword">int</span>&gt;(<span class="number">128</span>);</span><br><span class="line">    std::cout &lt;&lt; val2.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.3 采用 std::optional(val) 初始化，自动推导变量类型</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val3 = std::<span class="built_in">optional</span>(<span class="number">128</span>);</span><br><span class="line">    std::cout &lt;&lt; val3.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.4 采用 std::optional&lt;T&gt;&#123;val&#125; 初始化</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val4 = std::optional&lt;<span class="keyword">int</span>&gt;&#123;<span class="number">128</span>&#125;;</span><br><span class="line">    std::cout &lt;&lt; val4.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.5 采用 std::optional&#123;val&#125; 初始化</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val5 = std::optional&#123;<span class="number">128</span>&#125;;</span><br><span class="line">    std::cout &lt;&lt; val5.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.6 采用 &#123;val&#125; 初始化</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val6 = &#123;<span class="number">128</span>&#125;;</span><br><span class="line">    std::cout &lt;&lt; val6.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.7 采用 std::make_optional&lt;T&gt;(val) 初始化</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val7 = std::make_optional&lt;<span class="keyword">int</span>&gt;(<span class="number">128</span>);</span><br><span class="line">    std::cout &lt;&lt; val7.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.8 采用 std::make_optional(val) 初始化，自动推导变量类型</span></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val8 = std::<span class="built_in">make_optional</span>(<span class="number">128</span>);</span><br><span class="line">    std::cout &lt;&lt; val8.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val9 = std::nullopt;</span><br><span class="line">    std::cout &lt;&lt; val9.<span class="built_in">value_or</span>(<span class="number">-1</span>) &lt;&lt; std::endl;</span><br><span class="line">    val9.<span class="built_in">emplace</span>(<span class="number">128</span>);</span><br><span class="line">    std::cout &lt;&lt; val9.<span class="built_in">value_or</span>(<span class="number">-1</span>) &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    std::optional&lt;int&gt; val10 = std::nullopt;</span></span><br><span class="line">    <span class="comment">//    std::cout &lt;&lt; val10.value() &lt;&lt; std::endl;</span></span><br><span class="line"></span><br><span class="line">    std::optional&lt;<span class="keyword">int</span>&gt; val11 = std::nullopt;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        std::cout &lt;&lt; val11.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125; <span class="built_in"><span class="keyword">catch</span></span> (<span class="keyword">const</span> std::bad_optional_access&amp; e) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;==&gt; error: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 函数调用例子</span></span><br><span class="line">    std::vector&lt;<span class="keyword">int</span>&gt; neg_values = &#123;<span class="number">-1</span>, <span class="number">-3</span>, <span class="number">-5</span>&#125;;</span><br><span class="line">    std::vector&lt;<span class="keyword">int</span>&gt; pos_values = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> result1 = <span class="built_in">find_the_first_postive_value_v2</span>(pos_values);</span><br><span class="line">    <span class="keyword">if</span> (result1.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">        std::cout &lt;&lt; result1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (result1 != std::nullopt) &#123;</span><br><span class="line">        std::cout &lt;&lt; result1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (result1) &#123;</span><br><span class="line">        std::cout &lt;&lt; result1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (result1) &#123;</span><br><span class="line">        std::cout &lt;&lt; *result1 &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// try-catch 示例</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        std::cout &lt;&lt; result1.<span class="built_in">value</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125; <span class="built_in"><span class="keyword">catch</span></span> (<span class="keyword">const</span> std::bad_optional_access&amp; e) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;==&gt; error: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">show_backend</span>(std::nullopt);</span><br><span class="line">    <span class="built_in">show_backend</span>(std::<span class="built_in">make_optional</span>(<span class="string">&quot;CUDA&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> my_backend = std::optional&lt;std::string&gt;&#123;<span class="string">&quot;MPS&quot;</span>&#125;;</span><br><span class="line">    <span class="built_in">show_backend</span>(my_backend);</span><br><span class="line">    my_backend.<span class="built_in">emplace</span>(<span class="string">&quot;DSP&quot;</span>);</span><br><span class="line">    <span class="built_in">show_backend</span>(my_backend);</span><br><span class="line"></span><br><span class="line">    std::optional&lt;std::vector&lt;<span class="keyword">int</span>&gt;&gt; res = std::optional&lt;std::vector&lt;<span class="keyword">int</span>&gt;&gt;(&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;);</span><br><span class="line">    std::cout &lt;&lt; res.<span class="built_in">value</span>()[<span class="number">0</span>] &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以通过<code>g++ -std=c++17 main.cpp  &amp;&amp; ./a.out</code> 来编译运行。</p><h3 id="8-参考"><a href="#8-参考" class="headerlink" title="8. 参考"></a>8. 参考</h3><ol><li><a href="https://en.cppreference.com/w/cpp/utility/optional">https://en.cppreference.com/w/cpp/utility/optional</a></li><li><a href="https://devblogs.microsoft.com/cppblog/stdoptional-how-when-and-why">https://devblogs.microsoft.com/cppblog/stdoptional-how-when-and-why</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;1-std-optional-是什么&quot;&gt;&lt;a href=&quot;#1-std-optional-是什么&quot; class=&quot;headerlink&quot; title=&quot;1. std::optional 是什么&quot;&gt;&lt;/a&gt;1. std::optional 是什么&lt;/h3&gt;&lt;p&gt;C++ 17 引入了std::optional，表示一个可能有值的对象（没有值时就是默认的&lt;code&gt;std::nullopt&lt;/code&gt;)，例如这个例子中，std::optional 对象 even_value，如果&lt;code&gt;is_even&lt;/code&gt; 为真的话就是128，否则就是默认值&lt;code&gt;std::nullopt&lt;/code&gt;: &lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;meta-string&quot;&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;meta-string&quot;&gt;&amp;lt;optiona&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;bool&lt;/span&gt; is_even = &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// 在 没有值的情况下 std::optional 对象的值为 std::nullopt&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;std::optional&amp;lt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;&amp;gt; even_value = is_even ? std::optional&amp;lt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;&amp;gt;(&lt;span class=&quot;number&quot;&gt;128&lt;/span&gt;) : std::nullopt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// 可以用 std::optional 对象是否等于 std::nullopt 来判断 std::optional 对象是否有值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (even_value != std::nullopt) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;// 采用.value 获取 std::optional 对象的值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    std::cout &amp;lt;&amp;lt; &lt;span class=&quot;string&quot;&gt;&amp;quot;has value, which is &amp;quot;&lt;/span&gt; &amp;lt;&amp;lt; even_value.&lt;span class=&quot;built_in&quot;&gt;value&lt;/span&gt;() &amp;lt;&amp;lt; std::endl;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125; &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    std::cout &amp;lt;&amp;lt; &lt;span class=&quot;string&quot;&gt;&amp;quot;no value&amp;quot;&lt;/span&gt; &amp;lt;&amp;lt; std::endl;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;其实std::optional的作用和Python里面的&lt;code&gt;None&lt;/code&gt;比较像，例如上面的例子用Python来写就是这样：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;is_even = &lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;even_value = &lt;span class=&quot;number&quot;&gt;128&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; is_even &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; even_value &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&amp;quot;has value, which is&amp;quot;&lt;/span&gt;, even_value)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&amp;quot;no value&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://vra.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>libtorch系列教程3：优雅地训练MNIST分类模型</title>
    <link href="http://vra.github.io/2023/06/30/libtorch-tutorial3/"/>
    <id>http://vra.github.io/2023/06/30/libtorch-tutorial3/</id>
    <published>2023-06-30T14:38:16.000Z</published>
    <updated>2023-06-30T14:39:28.217Z</updated>
    
    <content type="html"><![CDATA[<p>在这篇文章中，我们对如何使用Libtorch进行MNIST分类模型的训练和测试进行详细描述。首先会浏览官方MNIST示例，然后对其进行模块化重构，为后续别的模型的训练提供 codebase。</p><p>由于Libtorch中包含很多和Pytorch中没有的类型，所以看Libtorch代码的时候时常会遇到不了解的函数或者类，这时候可以在<a href="https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/include/torch">这里</a>查找对应的类的实现，了解其作用。Libtorch C++ 代码中的注释虽然不多但基本够用了。</p><p>这里列举一些常见的类的代码路径，方便查询：</p><ul><li>Datasets: <a href="https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/datasets/base.h">https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/datasets/base.h</a></li><li>DataLoader:<a href="https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/include/torch/data/dataloader/base.h">https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/include/torch/data/dataloader/base.h</a></li><li>MNIST: <a href="https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/datasets/mnist.h">https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/datasets/mnist.h</a></li><li>Stack: <a href="https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/transforms/stack.h">https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/transforms/stack.h</a></li><li>RandomSampler:  <a href="https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/src/data/samplers/random.cpp">https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/src/data/samplers/random.cpp</a></li><li>SequentialSampler: <a href="https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/src/data/samplers/sequential.cpp">https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/src/data/samplers/sequential.cpp</a></li></ul><span id="more"></span><ul><li><h3 id="1-官方MNIST示例"><a href="#1-官方MNIST示例" class="headerlink" title="1. 官方MNIST示例"></a>1. 官方MNIST示例</h3>Libtorch官方的训练代码仓库在<a href="https://github.com/pytorch/examples/tree/main/cpp">这里</a>，拿里面的训练MNIST为例，代码如下：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstddef&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Where to find the MNIST dataset.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* kDataRoot = <span class="string">&quot;./data&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The batch size for training.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int64_t</span> kTrainBatchSize = <span class="number">64</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The batch size for testing.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int64_t</span> kTestBatchSize = <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The number of epochs to train.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int64_t</span> kNumberOfEpochs = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// After how many batches to log a new update with the loss value.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int64_t</span> kLogInterval = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Net</span> :</span> torch::nn::Module &#123;</span><br><span class="line">  <span class="built_in">Net</span>()</span><br><span class="line">      : <span class="built_in">conv1</span>(torch::nn::<span class="built_in">Conv2dOptions</span>(<span class="number">1</span>, <span class="number">10</span>, <span class="comment">/*kernel_size=*/</span><span class="number">5</span>)),</span><br><span class="line">        <span class="built_in">conv2</span>(torch::nn::<span class="built_in">Conv2dOptions</span>(<span class="number">10</span>, <span class="number">20</span>, <span class="comment">/*kernel_size=*/</span><span class="number">5</span>)),</span><br><span class="line">        <span class="built_in">fc1</span>(<span class="number">320</span>, <span class="number">50</span>),</span><br><span class="line">        <span class="built_in">fc2</span>(<span class="number">50</span>, <span class="number">10</span>) &#123;</span><br><span class="line">    <span class="built_in">register_module</span>(<span class="string">&quot;conv1&quot;</span>, conv1);</span><br><span class="line">    <span class="built_in">register_module</span>(<span class="string">&quot;conv2&quot;</span>, conv2);</span><br><span class="line">    <span class="built_in">register_module</span>(<span class="string">&quot;conv2_drop&quot;</span>, conv2_drop);</span><br><span class="line">    <span class="built_in">register_module</span>(<span class="string">&quot;fc1&quot;</span>, fc1);</span><br><span class="line">    <span class="built_in">register_module</span>(<span class="string">&quot;fc2&quot;</span>, fc2);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">torch::Tensor <span class="title">forward</span><span class="params">(torch::Tensor x)</span> </span>&#123;</span><br><span class="line">    x = torch::<span class="built_in">relu</span>(torch::<span class="built_in">max_pool2d</span>(conv1-&gt;forward(x), <span class="number">2</span>));</span><br><span class="line">    x = torch::<span class="built_in">relu</span>(</span><br><span class="line">        torch::<span class="built_in">max_pool2d</span>(conv2_drop-&gt;forward(conv2-&gt;forward(x)), <span class="number">2</span>));</span><br><span class="line">    x = x.<span class="built_in">view</span>(&#123;<span class="number">-1</span>, <span class="number">320</span>&#125;);</span><br><span class="line">    x = torch::<span class="built_in">relu</span>(fc1-&gt;forward(x));</span><br><span class="line">    x = torch::<span class="built_in">dropout</span>(x, <span class="comment">/*p=*/</span><span class="number">0.5</span>, <span class="comment">/*training=*/</span><span class="built_in">is_training</span>());</span><br><span class="line">    x = fc2-&gt;forward(x);</span><br><span class="line">    <span class="keyword">return</span> torch::<span class="built_in">log_softmax</span>(x, <span class="comment">/*dim=*/</span><span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  torch::nn::Conv2d conv1;</span><br><span class="line">  torch::nn::Conv2d conv2;</span><br><span class="line">  torch::nn::Dropout2d conv2_drop;</span><br><span class="line">  torch::nn::Linear fc1;</span><br><span class="line">  torch::nn::Linear fc2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataLoader&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">train</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">size_t</span> epoch,</span></span></span><br><span class="line"><span class="params"><span class="function">    Net&amp; model,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Device device,</span></span></span><br><span class="line"><span class="params"><span class="function">    DataLoader&amp; data_loader,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::optim::Optimizer&amp; optimizer,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">size_t</span> dataset_size)</span> </span>&#123;</span><br><span class="line">  model.<span class="built_in">train</span>();</span><br><span class="line">  <span class="keyword">size_t</span> batch_idx = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; batch : data_loader) &#123;</span><br><span class="line">    <span class="keyword">auto</span> data = batch.data.<span class="built_in">to</span>(device), targets = batch.target.<span class="built_in">to</span>(device);</span><br><span class="line">    optimizer.<span class="built_in">zero_grad</span>();</span><br><span class="line">    <span class="keyword">auto</span> output = model.forward(data);</span><br><span class="line">    <span class="keyword">auto</span> loss = torch::<span class="built_in">nll_loss</span>(output, targets);</span><br><span class="line">    <span class="built_in">AT_ASSERT</span>(!std::<span class="built_in">isnan</span>(loss.<span class="keyword">template</span> item&lt;<span class="keyword">float</span>&gt;()));</span><br><span class="line">    loss.<span class="built_in">backward</span>();</span><br><span class="line">    optimizer.<span class="built_in">step</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (batch_idx++ % kLogInterval == <span class="number">0</span>) &#123;</span><br><span class="line">      std::<span class="built_in">printf</span>(</span><br><span class="line">          <span class="string">&quot;\rTrain Epoch: %ld [%5ld/%5ld] Loss: %.4f&quot;</span>,</span><br><span class="line">          epoch,</span><br><span class="line">          batch_idx * batch.data.<span class="built_in">size</span>(<span class="number">0</span>),</span><br><span class="line">          dataset_size,</span><br><span class="line">          loss.<span class="keyword">template</span> item&lt;<span class="keyword">float</span>&gt;());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataLoader&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">test</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    Net&amp; model,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Device device,</span></span></span><br><span class="line"><span class="params"><span class="function">    DataLoader&amp; data_loader,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">size_t</span> dataset_size)</span> </span>&#123;</span><br><span class="line">  torch::NoGradGuard no_grad;</span><br><span class="line">  model.<span class="built_in">eval</span>();</span><br><span class="line">  <span class="keyword">double</span> test_loss = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int32_t</span> correct = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; batch : data_loader) &#123;</span><br><span class="line">    <span class="keyword">auto</span> data = batch.data.<span class="built_in">to</span>(device), targets = batch.target.<span class="built_in">to</span>(device);</span><br><span class="line">    <span class="keyword">auto</span> output = model.forward(data);</span><br><span class="line">    test_loss += torch::<span class="built_in">nll_loss</span>(</span><br><span class="line">                     output,</span><br><span class="line">                     targets,</span><br><span class="line">                     <span class="comment">/*weight=*/</span>&#123;&#125;,</span><br><span class="line">                     torch::Reduction::Sum)</span><br><span class="line">                     .<span class="keyword">template</span> item&lt;<span class="keyword">float</span>&gt;();</span><br><span class="line">    <span class="keyword">auto</span> pred = output.<span class="built_in">argmax</span>(<span class="number">1</span>);</span><br><span class="line">    correct += pred.<span class="built_in">eq</span>(targets).<span class="built_in">sum</span>().<span class="keyword">template</span> item&lt;<span class="keyword">int64_t</span>&gt;();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  test_loss /= dataset_size;</span><br><span class="line">  std::<span class="built_in">printf</span>(</span><br><span class="line">      <span class="string">&quot;\nTest set: Average loss: %.4f | Accuracy: %.3f\n&quot;</span>,</span><br><span class="line">      test_loss,</span><br><span class="line">      <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(correct) / dataset_size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">main</span><span class="params">()</span> -&gt; <span class="keyword">int</span> </span>&#123;</span><br><span class="line">  torch::<span class="built_in">manual_seed</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  torch::DeviceType device_type;</span><br><span class="line">  <span class="keyword">if</span> (torch::cuda::<span class="built_in">is_available</span>()) &#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;CUDA available! Training on GPU.&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    device_type = torch::kCUDA;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Training on CPU.&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    device_type = torch::kCPU;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function">torch::Device <span class="title">device</span><span class="params">(device_type)</span></span>;</span><br><span class="line"></span><br><span class="line">  Net model;</span><br><span class="line">  model.<span class="built_in">to</span>(device);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> train_dataset = torch::data::datasets::<span class="built_in">MNIST</span>(kDataRoot)</span><br><span class="line">                           .<span class="built_in">map</span>(torch::data::transforms::Normalize&lt;&gt;(<span class="number">0.1307</span>, <span class="number">0.3081</span>))</span><br><span class="line">                           .<span class="built_in">map</span>(torch::data::transforms::Stack&lt;&gt;());</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">size_t</span> train_dataset_size = train_dataset.<span class="built_in">size</span>().<span class="built_in">value</span>();</span><br><span class="line">  <span class="keyword">auto</span> train_loader =</span><br><span class="line">      torch::data::make_data_loader&lt;torch::data::samplers::SequentialSampler&gt;(</span><br><span class="line">          std::<span class="built_in">move</span>(train_dataset), kTrainBatchSize);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> test_dataset = torch::data::datasets::<span class="built_in">MNIST</span>(</span><br><span class="line">                          kDataRoot, torch::data::datasets::MNIST::Mode::kTest)</span><br><span class="line">                          .<span class="built_in">map</span>(torch::data::transforms::Normalize&lt;&gt;(<span class="number">0.1307</span>, <span class="number">0.3081</span>))</span><br><span class="line">                          .<span class="built_in">map</span>(torch::data::transforms::Stack&lt;&gt;());</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">size_t</span> test_dataset_size = test_dataset.<span class="built_in">size</span>().<span class="built_in">value</span>();</span><br><span class="line">  <span class="keyword">auto</span> test_loader =</span><br><span class="line">      torch::data::<span class="built_in">make_data_loader</span>(std::<span class="built_in">move</span>(test_dataset), kTestBatchSize);</span><br><span class="line"></span><br><span class="line">  torch::<span class="function">optim::SGD <span class="title">optimizer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      model.parameters(), torch::optim::SGDOptions(<span class="number">0.01</span>).momentum(<span class="number">0.5</span>))</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> epoch = <span class="number">1</span>; epoch &lt;= kNumberOfEpochs; ++epoch) &#123;</span><br><span class="line">    <span class="built_in">train</span>(epoch, model, device, *train_loader, optimizer, train_dataset_size);</span><br><span class="line">    <span class="built_in">test</span>(model, device, *test_loader, test_dataset_size);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>代码具体细节可以先不用理解，后文有一些说明。可以看到所有的模型搭建、数据读取、网络训练和测试代码都混在一个文件里面，别的几个例子里面也是类似的写法。</p><p>这样写当然是可以的，但对于习惯了Pytorch训练的我们来说，这样所有的代码在一个文件中的写法很不易读，<br>修改数据和网络都相互有影响，且不利用真正严肃地模型训练迭代。</p><h3 id="2-重构-MNIST-示例代码"><a href="#2-重构-MNIST-示例代码" class="headerlink" title="2. 重构 MNIST 示例代码"></a>2. 重构 MNIST 示例代码</h3><p>所以一个简单的想法是改进写法，将DataLoader, Model 和训练逻辑拆分出来，分别进行模块化，放到单独的文件中处理。</p><h4 id="2-1-简单拆分的问题"><a href="#2-1-简单拆分的问题" class="headerlink" title="2.1 简单拆分的问题"></a>2.1 简单拆分的问题</h4><p>第一次尝试是将Dataset和DataLoader放到一个模块中，网络定义放到一个模块中，训练和测试代码放到一个模块中。<br>但这样拆分遇到很大问题，核心原因是 Libtorch 的DataLoader类别太复杂了，对于我这种C++了解不深入的人来说改造难度太大。</p><p>举个例子，我们对MNIST Dataset类进行Normalize后Stack，然后构造一个DataLoader对象<code>train_loader</code>，代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> train_dataset = torch::data::datasets::<span class="built_in">MNIST</span>(data_root)</span><br><span class="line">                             .<span class="built_in">map</span>(torch::data::transforms::Normalize&lt;&gt;(<span class="number">0.1307</span>, <span class="number">0.3081</span>))</span><br><span class="line">                             .<span class="built_in">map</span>(torch::data::transforms::Stack&lt;&gt;());</span><br><span class="line"><span class="keyword">auto</span> train_loader =</span><br><span class="line">        torch::data::make_data_loader&lt;torch::data::samplers::SequentialSampler&gt;(std::<span class="built_in">move</span>(train_dataset), <span class="number">64</span>);</span><br></pre></td></tr></table></figure><p>生成的<code>train_loader</code>对象的类型是：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch::<span class="keyword">disable_if_t</span>&lt;MapDataset&lt;MapDataset&lt;MNIST, Normalize&lt;&gt;&gt;, Stack&lt;&gt;&gt;::is_stateful || !std::is_constructible&lt;SequentialSampler, <span class="keyword">size_t</span>&gt;::value, std::unique_ptr&lt;StatelessDataLoader&lt;MapDataset&lt;MapDataset&lt;MNIST, Normalize&lt;&gt;&gt;, Stack&lt;&gt;&gt;, SequentialSampler&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><p>这个类型太复杂了……</p><p>因为官方示例是所有代码在一个文件，因此可以通过<code>auto</code> 来让编译器自动判定类型，省去了写着一长串类型的问题。</p><p>但如果我们要拆分DataLoader到单独的类里面的话，就没法使用<code>auto</code>，需要显式的指出DataLoader的类型，然而即使是这样一长串的类型写上了，还是会有不知道是哪里的问题，导致编译报错。</p><p>当然也有可能有简单的方法来解决这个问题，欢迎C++高手讨论指导。</p><p>这次体验让我真正体会到了动态类型语言的简洁性，以及Python的所有类型转C++会存在哪些坑。</p><h4 id="2-2-一种比较简单的重构方案"><a href="#2-2-一种比较简单的重构方案" class="headerlink" title="2.2 一种比较简单的重构方案"></a>2.2 一种比较简单的重构方案</h4><p>最后给出了一个妥协的方案：DataSet在单独的类中定义里面，而DataLoader在训练逻辑中构造，避免繁琐的类型问题。</p><p>整体代码结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">├── CMakeLists.txt <span class="comment"># CMake配置文件</span></span><br><span class="line">├── main.cpp <span class="comment"># 主入口</span></span><br><span class="line">├── my_dataset.cpp <span class="comment"># 数据集实现</span></span><br><span class="line">├── my_dataset.h </span><br><span class="line">├── my_model.cpp <span class="comment"># 模型定义</span></span><br><span class="line">├── my_model.h</span><br><span class="line">├── my_trainer.cpp <span class="comment"># 训练和测试脚手架代码</span></span><br><span class="line">└── my_trainer.h</span><br></pre></td></tr></table></figure><h5 id="2-2-1-CMake-配置文件"><a href="#2-2-1-CMake-配置文件" class="headerlink" title="2.2.1 CMake 配置文件"></a>2.2.1 CMake 配置文件</h5><p>CMake 配置文件<code>CMakeLists.txt</code>中将几个实现文件加入到编译依赖即可，别的部分与前两篇文章中的类似。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.0</span> FATAL_ERROR)</span><br><span class="line"><span class="keyword">project</span>(mnist_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要找到Libtorch</span></span><br><span class="line"><span class="keyword">find_package</span>(Torch REQUIRED)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; $&#123;TORCH_CXX_FLAGS&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> main.cpp my_model.cpp my_dataset.cpp my_trainer.cpp)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> <span class="string">&quot;$&#123;TORCH_LIBRARIES&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Libtorch是基于C++14来实现的</span></span><br><span class="line"><span class="keyword">set_property</span>(<span class="keyword">TARGET</span> <span class="variable">$&#123;PROJECT_NAME&#125;</span> PROPERTY CXX_STANDARD <span class="number">14</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="2-2-2-主入口文件定义"><a href="#2-2-2-主入口文件定义" class="headerlink" title="2.2.2 主入口文件定义"></a>2.2.2 主入口文件定义</h5><p>主入口文件实现了超参数设置，网络和数据集初始化，以及调用Trainer进行训练和测试：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_dataset.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_model.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_trainer.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 超参数设置</span></span><br><span class="line">  std::string data_root = <span class="string">&quot;./data&quot;</span>;</span><br><span class="line">  <span class="keyword">int</span> train_batch_size = <span class="number">128</span>;</span><br><span class="line">  <span class="keyword">int</span> test_batch_size = <span class="number">1000</span>;</span><br><span class="line">  <span class="keyword">int</span> total_epoch_num = <span class="number">30</span>;</span><br><span class="line">  <span class="keyword">int</span> log_interval = <span class="number">10</span>;</span><br><span class="line">  <span class="keyword">int</span> num_workers = <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置随机数种子</span></span><br><span class="line">  torch::<span class="built_in">manual_seed</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取设备类型</span></span><br><span class="line">  torch::DeviceType device_type = torch::kCPU;</span><br><span class="line">  <span class="keyword">if</span> (torch::cuda::<span class="built_in">is_available</span>()) &#123;</span><br><span class="line">    device_type = torch::kCUDA;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function">torch::Device <span class="title">device</span><span class="params">(device_type)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造网络</span></span><br><span class="line">  MyModel model;</span><br><span class="line">  model.<span class="built_in">to</span>(device);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置优化器</span></span><br><span class="line">  torch::<span class="function">optim::SGD <span class="title">optimizer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      model.parameters(), torch::optim::SGDOptions(<span class="number">0.01</span>).momentum(<span class="number">0.5</span>))</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造训练和测试dataset</span></span><br><span class="line">  <span class="keyword">auto</span> train_dataset =</span><br><span class="line">      <span class="built_in">MyDataset</span>(data_root, torch::data::datasets::MNIST::Mode::kTrain);</span><br><span class="line">  <span class="keyword">auto</span> test_dataset =</span><br><span class="line">      <span class="built_in">MyDataset</span>(data_root, torch::data::datasets::MNIST::Mode::kTest);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Trainer初始化</span></span><br><span class="line">  <span class="keyword">auto</span> trainer = <span class="built_in">MyTrainer</span>(log_interval);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> epoch = <span class="number">1</span>; epoch &lt; total_epoch_num; ++epoch) &#123;</span><br><span class="line">   <span class="comment">// 运行训练</span></span><br><span class="line">    trainer.<span class="built_in">train</span>(</span><br><span class="line">        epoch,</span><br><span class="line">        model,</span><br><span class="line">        optimizer,</span><br><span class="line">        device,</span><br><span class="line">        train_dataset,</span><br><span class="line">        train_batch_size,</span><br><span class="line">        num_workers);</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 运行测试</span></span><br><span class="line">    trainer.<span class="built_in">test</span>(model, device, test_dataset, test_batch_size, num_workers);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-2-3-网络定义"><a href="#2-2-3-网络定义" class="headerlink" title="2.2.3 网络定义"></a>2.2.3 网络定义</h5><p>网络结构采用简单的LeNet，两个conv层和2个fc层。<br>头文件 my_model.h 内容:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span> :</span> <span class="keyword">public</span> torch::nn::Module &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">MyModel</span>();</span><br><span class="line">  <span class="function">torch::Tensor <span class="title">forward</span><span class="params">(torch::Tensor x)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  torch::nn::Conv2d conv1 = <span class="literal">nullptr</span>;</span><br><span class="line">  torch::nn::Conv2d conv2 = <span class="literal">nullptr</span>;</span><br><span class="line">  torch::nn::Dropout2d conv2_drop;</span><br><span class="line">  torch::nn::Linear fc1 = <span class="literal">nullptr</span>;</span><br><span class="line">  torch::nn::Linear fc2 = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>实现文件 my_model.cpp:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_model.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">MyModel::<span class="built_in">MyModel</span>() &#123;</span><br><span class="line">  conv1 = torch::nn::<span class="built_in">Conv2d</span>(torch::nn::<span class="built_in">Conv2dOptions</span>(<span class="number">1</span>, <span class="number">10</span>, <span class="number">5</span>));</span><br><span class="line">  conv2 = torch::nn::<span class="built_in">Conv2d</span>(torch::nn::<span class="built_in">Conv2dOptions</span>(<span class="number">10</span>, <span class="number">20</span>, <span class="number">5</span>));</span><br><span class="line">  fc1 = torch::nn::<span class="built_in">Linear</span>(<span class="number">320</span>, <span class="number">50</span>);</span><br><span class="line">  fc2 = torch::nn::<span class="built_in">Linear</span>(<span class="number">50</span>, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">register_module</span>(<span class="string">&quot;conv1&quot;</span>, conv1);</span><br><span class="line">  <span class="built_in">register_module</span>(<span class="string">&quot;conv2&quot;</span>, conv2);</span><br><span class="line">  <span class="built_in">register_module</span>(<span class="string">&quot;conv2_drop&quot;</span>, conv2_drop);</span><br><span class="line">  <span class="built_in">register_module</span>(<span class="string">&quot;fc1&quot;</span>, fc1);</span><br><span class="line">  <span class="built_in">register_module</span>(<span class="string">&quot;fc2&quot;</span>, fc2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">torch::Tensor <span class="title">MyModel::forward</span><span class="params">(torch::Tensor x)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// conv1</span></span><br><span class="line">  x = conv1-&gt;forward(x);</span><br><span class="line">  x = torch::<span class="built_in">max_pool2d</span>(x, <span class="number">2</span>);</span><br><span class="line">  x = torch::<span class="built_in">relu</span>(x);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// conv2</span></span><br><span class="line">  x = conv2-&gt;forward(x);</span><br><span class="line">  x = conv2_drop-&gt;forward(x);</span><br><span class="line">  x = torch::<span class="built_in">max_pool2d</span>(x, <span class="number">2</span>);</span><br><span class="line">  x = torch::<span class="built_in">relu</span>(x);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// fc1</span></span><br><span class="line">  x = x.<span class="built_in">view</span>(&#123;<span class="number">-1</span>, <span class="number">320</span>&#125;);</span><br><span class="line">  x = fc1-&gt;forward(x);</span><br><span class="line">  x = torch::<span class="built_in">relu</span>(x);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// dropout</span></span><br><span class="line">  x = torch::<span class="built_in">dropout</span>(x, <span class="number">0.5</span>, <span class="built_in">is_training</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// fc2</span></span><br><span class="line">  x = fc2-&gt;forward(x);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// log softmax</span></span><br><span class="line">  x = torch::<span class="built_in">log_softmax</span>(x, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到网络的定义还是比较简单直接，可以直接从Python 网络定义迁移过去，几个核心点：</p><ul><li>网络类的定义需要继承<code>torch::nn::Module</code> 类</li><li>实现<code>forward</code> 函数来进行网络前项运算，其中每个层需要显式地调用<code>forward</code> 函数</li></ul><h5 id="2-2-4-数据集定义"><a href="#2-2-4-数据集定义" class="headerlink" title="2.2.4 数据集定义"></a>2.2.4 数据集定义</h5><p>由于 Libtorch 自带 MNIST的实现，我们这里只是做了一个简单的封装，作为模块化的例子。<br>头文件<code>my_dataset.h</code> 内容：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">MyDataset</span>(</span><br><span class="line">      <span class="keyword">const</span> std::string&amp; data_root,</span><br><span class="line">      torch::data::datasets::MNIST::Mode phase);</span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  torch::data::datasets::MNIST mnist_dataset;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>实现文件<code>my_dataset.cpp</code> 内容：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_dataset.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">MyDataset::<span class="built_in">MyDataset</span>(</span><br><span class="line">    <span class="keyword">const</span> std::string&amp; data_root,</span><br><span class="line">    torch::data::datasets::MNIST::Mode phase)</span><br><span class="line">    : <span class="built_in">mnist_dataset</span>(torch::data::datasets::<span class="built_in">MNIST</span>(data_root, phase)) &#123;&#125;</span><br></pre></td></tr></table></figure><p>这里有一个需要注意的点，由于MNIST类本身没有默认构造函数，所以在<code>MyDataset</code> 类的初始化列表中就必须给成员变量<code>mnist_dataset</code>赋值，否则会报下面的错:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">constructor for &#x27;MyDataset&#x27; must explicitly initialize the member &#x27;mnist_dataset&#x27; which does not have a default constructor</span><br></pre></td></tr></table></figure><h5 id="2-2-5-Trainer定义"><a href="#2-2-5-Trainer定义" class="headerlink" title="2.2.5 Trainer定义"></a>2.2.5 Trainer定义</h5><p>Trainer 包含训练和测试的两个函数，对数据和网络，优化器等输入进行计算，得到输出，计算loss和准确率。<br>头文件<code>my_trainer.h</code>内容：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_dataset.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_model.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTrainer</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">MyTrainer</span>(<span class="keyword">int</span> log_interval) : <span class="built_in">log_interval_</span>(log_interval)&#123;&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">train</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="keyword">size_t</span> epoch,</span></span></span><br><span class="line"><span class="params"><span class="function">      MyModel&amp; model,</span></span></span><br><span class="line"><span class="params"><span class="function">      torch::optim::Optimizer&amp; optimizer,</span></span></span><br><span class="line"><span class="params"><span class="function">      torch::Device device,</span></span></span><br><span class="line"><span class="params"><span class="function">      MyDataset&amp; train_dataset,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="keyword">int</span> batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="keyword">int</span> num_workers)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">test</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      MyModel&amp; model,</span></span></span><br><span class="line"><span class="params"><span class="function">      torch::Device device,</span></span></span><br><span class="line"><span class="params"><span class="function">      MyDataset&amp; test_dataset,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="keyword">int</span> batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="keyword">int</span> num_workers)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">int</span> log_interval_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>实现文件<code>my_trainer.cpp</code> 内容：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_trainer.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">MyTrainer::train</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">size_t</span> epoch,</span></span></span><br><span class="line"><span class="params"><span class="function">    MyModel&amp; model,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::optim::Optimizer&amp; optimizer,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Device device,</span></span></span><br><span class="line"><span class="params"><span class="function">    MyDataset&amp; train_dataset,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">int</span> batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">int</span> num_workers)</span> </span>&#123;</span><br><span class="line">  model.<span class="built_in">train</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 对MNIST数据进行Normalize和Stack（将多个Tensor stack成一个Tensor)</span></span><br><span class="line">  <span class="keyword">auto</span> dataset = train_dataset.mnist_dataset</span><br><span class="line">                     .<span class="built_in">map</span>(torch::data::transforms::Normalize&lt;&gt;(<span class="number">0.1307</span>, <span class="number">0.3081</span>))</span><br><span class="line">                     .<span class="built_in">map</span>(torch::data::transforms::Stack&lt;&gt;());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造 DataLoader, 设置 batch size 和 worker 数目</span></span><br><span class="line">  <span class="keyword">auto</span> data_loader = torch::data::<span class="built_in">make_data_loader</span>(</span><br><span class="line">      dataset,</span><br><span class="line">      torch::data::<span class="built_in">DataLoaderOptions</span>()</span><br><span class="line">          .<span class="built_in">batch_size</span>(batch_size)</span><br><span class="line">          .<span class="built_in">workers</span>(num_workers));</span><br><span class="line">  <span class="keyword">auto</span> dataset_size = dataset.<span class="built_in">size</span>().<span class="built_in">value</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">size_t</span> batch_idx = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 网络训练</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; batch : *data_loader) &#123;</span><br><span class="line">    <span class="comment">// 获取数据和label</span></span><br><span class="line">    <span class="keyword">auto</span> data = batch.data.<span class="built_in">to</span>(device);</span><br><span class="line">    <span class="keyword">auto</span> targets = batch.target.<span class="built_in">to</span>(device);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 优化器 梯度清零</span></span><br><span class="line">    optimizer.<span class="built_in">zero_grad</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 模型前向操作，得到预测输出</span></span><br><span class="line">    <span class="keyword">auto</span> output = model.forward(data);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算loss</span></span><br><span class="line">    <span class="keyword">auto</span> loss = torch::<span class="built_in">nll_loss</span>(output, targets);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// loss 反传</span></span><br><span class="line">    loss.<span class="built_in">backward</span>();</span><br><span class="line">    optimizer.<span class="built_in">step</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印log信息</span></span><br><span class="line">    <span class="keyword">if</span> (batch_idx++ % log_interval_ == <span class="number">0</span>) &#123;</span><br><span class="line">      std::<span class="built_in">printf</span>(</span><br><span class="line">          <span class="string">&quot;\rTrain Epoch: %ld [%5llu/%5ld] Loss: %.4f&quot;</span>,</span><br><span class="line">          epoch,</span><br><span class="line">          batch_idx * batch.data.<span class="built_in">size</span>(<span class="number">0</span>),</span><br><span class="line">          dataset_size,</span><br><span class="line">          loss.<span class="keyword">template</span> item&lt;<span class="keyword">float</span>&gt;());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">MyTrainer::test</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    MyModel&amp; model,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Device device,</span></span></span><br><span class="line"><span class="params"><span class="function">    MyDataset&amp; test_dataset,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">int</span> batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">int</span> num_workers)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 测试时要将模型置为eval模式</span></span><br><span class="line">  model.<span class="built_in">eval</span>();</span><br><span class="line">  <span class="keyword">double</span> test_loss = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int32_t</span> correct = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 对MNIST数据进行Normalize和Stack（将多个Tensor stack成一个Tensor)</span></span><br><span class="line">  <span class="keyword">auto</span> dataset = test_dataset.mnist_dataset</span><br><span class="line">                     .<span class="built_in">map</span>(torch::data::transforms::Normalize&lt;&gt;(<span class="number">0.1307</span>, <span class="number">0.3081</span>))</span><br><span class="line">                     .<span class="built_in">map</span>(torch::data::transforms::Stack&lt;&gt;());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造 DataLoader, 设置 batch size 和 worker 数目</span></span><br><span class="line">  <span class="keyword">auto</span> data_loader = torch::data::<span class="built_in">make_data_loader</span>(</span><br><span class="line">      dataset,</span><br><span class="line">      torch::data::<span class="built_in">DataLoaderOptions</span>()</span><br><span class="line">          .<span class="built_in">batch_size</span>(batch_size)</span><br><span class="line">          .<span class="built_in">workers</span>(num_workers));</span><br><span class="line">  <span class="keyword">auto</span> dataset_size = dataset.<span class="built_in">size</span>().<span class="built_in">value</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; batch : *data_loader) &#123;</span><br><span class="line">    <span class="comment">// 获取数据和label</span></span><br><span class="line">    <span class="keyword">auto</span> data = batch.data.<span class="built_in">to</span>(device);</span><br><span class="line">    <span class="keyword">auto</span> targets = batch.target.<span class="built_in">to</span>(device);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 模型前向操作，得到预测输出</span></span><br><span class="line">    <span class="keyword">auto</span> output = model.forward(data);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算测试时的 loss</span></span><br><span class="line">    test_loss += torch::<span class="built_in">nll_loss</span>(</span><br><span class="line">                     output,</span><br><span class="line">                     targets,</span><br><span class="line">                     <span class="comment">/*weight=*/</span>&#123;&#125;,</span><br><span class="line">                     torch::Reduction::Sum)</span><br><span class="line">                     .item&lt;<span class="keyword">float</span>&gt;();</span><br><span class="line">    <span class="keyword">auto</span> pred = output.<span class="built_in">argmax</span>(<span class="number">1</span>);</span><br><span class="line">    correct += pred.<span class="built_in">eq</span>(targets).<span class="built_in">sum</span>().<span class="keyword">template</span> item&lt;<span class="keyword">int64_t</span>&gt;();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  test_loss /= dataset_size;</span><br><span class="line">  std::<span class="built_in">printf</span>(</span><br><span class="line">      <span class="string">&quot;\nTest set: Average loss: %.4f | Accuracy: %.3f\n&quot;</span>,</span><br><span class="line">      test_loss,</span><br><span class="line">      <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(correct) / dataset_size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-2-6-编译和运行方式"><a href="#2-2-6-编译和运行方式" class="headerlink" title="2.2.6 编译和运行方式"></a>2.2.6 编译和运行方式</h5><p>我们基于CMake 编译上面的代码，同时下载MNIST数据集，完整的执行命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..  -DCMAKE_PREFIX_PATH=`python -c <span class="string">&#x27;import torch;print(torch.utils.cmake_prefix_path)&#x27;</span>`</span><br><span class="line">make -j8</span><br><span class="line"><span class="comment"># 下载MNIST数据</span></span><br><span class="line">mkdir data &amp;&amp; <span class="built_in">cd</span> data</span><br><span class="line">wget <span class="string">&quot;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&quot;</span> &amp;&amp; gunzip train-images-idx3-ubyte.gz</span><br><span class="line">wget <span class="string">&quot;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&quot;</span> &amp;&amp; gunzip train-labels-idx1-ubyte.gz</span><br><span class="line">wget <span class="string">&quot;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&quot;</span> &amp;&amp; gunzip t10k-images-idx3-ubyte.gz</span><br><span class="line">wget <span class="string">&quot;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&quot;</span> &amp;&amp; gunzip t10k-labels-idx1-ubyte.gz</span><br><span class="line"><span class="built_in">cd</span> ../</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行可执行文件</span></span><br><span class="line">./mnist_train</span><br></pre></td></tr></table></figure><p>训练和测试输出如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Train Epoch: 1 [59008/60000] Loss: 0.6824</span><br><span class="line">Test set: Average loss: 0.3265 | Accuracy: 0.910</span><br><span class="line">Train Epoch: 2 [59008/60000] Loss: 0.5521</span><br><span class="line">Test set: Average loss: 0.2018 | Accuracy: 0.941</span><br><span class="line">Train Epoch: 3 [59008/60000] Loss: 0.3403</span><br><span class="line">Test set: Average loss: 0.1523 | Accuracy: 0.954</span><br><span class="line">Train Epoch: 4 [59008/60000] Loss: 0.3885</span><br><span class="line">Test set: Average loss: 0.1236 | Accuracy: 0.965</span><br><span class="line">Train Epoch: 5 [59008/60000] Loss: 0.3502</span><br><span class="line">Test set: Average loss: 0.1083 | Accuracy: 0.967</span><br><span class="line">Train Epoch: 6 [59008/60000] Loss: 0.1389</span><br><span class="line">Test set: Average loss: 0.0961 | Accuracy: 0.970</span><br><span class="line">Train Epoch: 7 [59008/60000] Loss: 0.3550</span><br><span class="line">Test set: Average loss: 0.0899 | Accuracy: 0.972</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以看到准确率在逐渐提升。</p><p>这篇文章的内容主要就是这些，后面会根据训练一个实际一些的例子，比如nanoGPT，将在本文的codebase基础上，主要覆盖下面的内容：</p><ul><li>自定义数据集的Dataset类的搭建</li><li>复杂网络的定义(如ResNet, Transformer)</li><li>模型checkpoint的保存和读取</li></ul><p>欢迎点赞和关注！</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在这篇文章中，我们对如何使用Libtorch进行MNIST分类模型的训练和测试进行详细描述。首先会浏览官方MNIST示例，然后对其进行模块化重构，为后续别的模型的训练提供 codebase。&lt;/p&gt;
&lt;p&gt;由于Libtorch中包含很多和Pytorch中没有的类型，所以看Libtorch代码的时候时常会遇到不了解的函数或者类，这时候可以在&lt;a href=&quot;https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/include/torch&quot;&gt;这里&lt;/a&gt;查找对应的类的实现，了解其作用。Libtorch C++ 代码中的注释虽然不多但基本够用了。&lt;/p&gt;
&lt;p&gt;这里列举一些常见的类的代码路径，方便查询：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Datasets: &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/datasets/base.h&quot;&gt;https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/datasets/base.h&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;DataLoader:&lt;a href=&quot;https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/include/torch/data/dataloader/base.h&quot;&gt;https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/include/torch/data/dataloader/base.h&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MNIST: &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/datasets/mnist.h&quot;&gt;https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/datasets/mnist.h&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stack: &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/transforms/stack.h&quot;&gt;https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/data/transforms/stack.h&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;RandomSampler:  &lt;a href=&quot;https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/src/data/samplers/random.cpp&quot;&gt;https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/src/data/samplers/random.cpp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SequentialSampler: &lt;a href=&quot;https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/src/data/samplers/sequential.cpp&quot;&gt;https://github.com/pytorch/pytorch/tree/main/torch/csrc/api/src/data/samplers/sequential.cpp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
    <category term="C++" scheme="http://vra.github.io/tags/C/"/>
    
    <category term="Pytorch" scheme="http://vra.github.io/tags/Pytorch/"/>
    
    <category term="Libtorch" scheme="http://vra.github.io/tags/Libtorch/"/>
    
  </entry>
  
  <entry>
    <title>NeoVim 代码格式化教程</title>
    <link href="http://vra.github.io/2023/06/17/neoformat-python-cpp/"/>
    <id>http://vra.github.io/2023/06/17/neoformat-python-cpp/</id>
    <published>2023-06-17T01:54:45.000Z</published>
    <updated>2023-06-17T03:20:33.226Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h3><p><a href="https://github.com/sbdchd/neoformat">neoformat</a> 是 (Neo)Vim 的代码格式化插件，支持多种语言的格式化。这篇文章覆盖 Neoformat 对 Python 和 C++ 进行格式化的配置，以及如何在保存代码时自动进行格式化，可以直接应用的配置代码段在文章最后。</p><span id="more"></span><h3 id="2-neoformat安装"><a href="#2-neoformat安装" class="headerlink" title="2. neoformat安装"></a>2. neoformat安装</h3><p>采用 <a href="https://github.com/junegunn/vim-plug">Vim-Plug</a> 进行插件管理，在<code>~/.config/nvim/init.vim</code> 中添加下面的插件:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plug &#x27;sbdchd/neoformat&#x27;</span><br></pre></td></tr></table></figure><p>然后用<code>:PlugInstall</code> 命令来安装插件。由于插件源码在 GitHub 上，国内访问时断时续，一次执行可能安装不成功，可以多执行几次这个命令，直到输出窗口显示安装成功。</p><h3 id="3-neoformat-格式化-Python-代码"><a href="#3-neoformat-格式化-Python-代码" class="headerlink" title="3. neoformat 格式化 Python 代码"></a>3. neoformat 格式化 Python 代码</h3><h4 id="3-1-安装格式化工具"><a href="#3-1-安装格式化工具" class="headerlink" title="3.1 安装格式化工具"></a>3.1 安装格式化工具</h4><p>neoformat本 身不会安装格式化工具，它只会调用系统已经安装好的格式化工具来进行代码格式化，所以你还需要自己手动在系统上安装格式化工具。</p><p>以 Python 格式化为例，我们采用 black 来格式化代码，那么需要先用<code>pip</code> 命令来安装black:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install black</span><br></pre></td></tr></table></figure><p>然后需要确保在命令行执行<code>black --version</code> 命令能正常输出，neoformat 才能找到black:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ black --version</span><br><span class="line">black, 23.3.0 (compiled: yes)</span><br><span class="line">Python (CPython) 3.8.16</span><br></pre></td></tr></table></figure><h4 id="3-2-格式化配置"><a href="#3-2-格式化配置" class="headerlink" title="3.2 格式化配置"></a>3.2 格式化配置</h4><p>安装好以后，我们就可以在<code>~/.config/nvim/init.vim</code> 文件中进行 neoformat 配置:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">let g:neoformat_python_black = &#123;</span><br><span class="line">            \ &#x27;exe&#x27;: &#x27;black&#x27;,</span><br><span class="line">            \ &#x27;args&#x27;: [&#x27;-q&#x27;, &#x27;-&#x27;],</span><br><span class="line">            \ &#x27;stdin&#x27;: 1,</span><br><span class="line">            \ &#125;</span><br><span class="line"></span><br><span class="line">let g:neoformat_enabled_python = [&#x27;black&#x27;]</span><br></pre></td></tr></table></figure><p>这是 VimScript 的语法，<code>let g:neoformat_python_black</code> 是创建一个全局变量<code>neoformat_python_black</code>, 全局变量的特点是所有打开的窗口和缓冲区都可以访问该变量。</p><p>注意这个变量的命名方式，<code>neoformat_&lt;Language&gt;_&lt;formatter&gt;</code>，表示针对某个语言的某一个格式化工具，这个格式化工具的名字会被注册，在下面的enable语句中使用到。</p><p>全局变量的值的含义如下：</p><ul><li><code>exe</code> 表示格式化运行需要执行的程序名，就跟我们在命令行访问某个程序一样的机制，需要知道它叫什么才能来执行。</li><li><code>args</code> 表示程序执行时需要的参数。这里<code>-q</code>是black命令的参数项，表示静默执行，不打印输出；<code>-</code> 表示从标准输入读取内容来格式化</li><li><code>stdin</code>: 这个参数表示是否从标准输入来读取内容来格式化。标准输入对应的是文件的内容，除了标准输入外还有缓存区</li></ul><p>所有的可配置参数参考 <a href="https://github.com/sbdchd/neoformat#config-optional">neoformat 文档</a>。这里我们配置这几个参数项就可以了。</p><p>下面还有一条语句，创建全局变量<code>neoformat_enabled_python</code>，表示针对 Python 启用的格式化工具，这里我们使用上面创建变量后注册的<code>black</code>。</p><h4 id="3-3-执行格式化"><a href="#3-3-执行格式化" class="headerlink" title="3.3 执行格式化"></a>3.3 执行格式化</h4><p>加了上面的 VimScript 配置后，我们在编辑文件时，就可以使用 <code>:Neoformat</code> 命令来格式化代码了。</p><p>如果想要使用特定的格式化工具，可以使用<code>:Neoformat &lt;formater&gt;</code> 来操作。</p><h4 id="3-4-保存文件时自动格式化"><a href="#3-4-保存文件时自动格式化" class="headerlink" title="3.4 保存文件时自动格式化"></a>3.4 保存文件时自动格式化</h4><p>前面的配置我们还需要手动执行<code>:Neoformat</code> 命令来格式化，下面我们添加一些配置到<code>~/.config/nvim/init.vim</code>，在保存文件时自动地进行格式化。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">augroup fmt</span><br><span class="line">  autocmd!</span><br><span class="line">  autocmd BufWritePre * Neoformat</span><br><span class="line">augroup END</span><br></pre></td></tr></table></figure><p>这段代码创建了一个自动化组并命名为<code>fmt</code>，用于将一组命令放在一起，方便管理。</p><p>我们首先使用<code>autocmd!</code>清空这个自动化组中的所有自动化命令，避免影响后面的命令设置。</p><p>然后用<code>autocmd BufWritePre * Neoformat</code>来完成在写buffer之前，对所有类型的文件都执行<code>Neoformat</code>命令。<code>autocmd</code>表示这是一条自动化命令。<code>BufWritePre</code>表示是在Write Buffer之前执行的操作,<code>*</code>表示匹配任意的文件，如果是<code>*.py</code>则只匹配后缀为<code>.py</code>的文件。<code>Neoformat</code> 表示要执行的命令。</p><p>这样，在保存文件时，就可以自动执行代码格式化了。</p><h4 id="3-5-调试命令"><a href="#3-5-调试命令" class="headerlink" title="3.5 调试命令"></a>3.5 调试命令</h4><p>如果出现格式化错误，或者格式化不生效，可以设置 <code>:set verbose=1</code> 来打开 NeoVim 的 log 显示，查看报错信息。实际测试发现这个命令真的很有用，很多信息打印出来后，对于定位问题帮助很大。</p><h3 id="4-neoformat-格式化-C-C-代码"><a href="#4-neoformat-格式化-C-C-代码" class="headerlink" title="4. neoformat 格式化 C/C++ 代码"></a>4. neoformat 格式化 C/C++ 代码</h3><p>对 C/C++代码的格式化与 Python 是类似的，只不过使用的格式化工具不同而已。这里以 <a href="https://clang.llvm.org/docs/ClangFormat.html">clang-format</a> 为例，记录需要执行的步骤。</p><h4 id="4-1-安装格式化工具"><a href="#4-1-安装格式化工具" class="headerlink" title="4.1 安装格式化工具"></a>4.1 安装格式化工具</h4><p>Ubuntu:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install clang-format</span><br></pre></td></tr></table></figure><p>Mac:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install clang-format</span><br></pre></td></tr></table></figure><h4 id="4-2-格式化配置"><a href="#4-2-格式化配置" class="headerlink" title="4.2 格式化配置"></a>4.2 格式化配置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">let g:neoformat_c_clangformat = &#123;</span><br><span class="line">            \ &#x27;exe&#x27;: &#x27;clang-format&#x27;,</span><br><span class="line">\ &#x27;args&#x27;: [&#x27;-assume-filename=%:p&#x27;],</span><br><span class="line">            \ &#x27;stdin&#x27;: 1,</span><br><span class="line">            \ &#125;</span><br><span class="line"></span><br><span class="line">let g:neoformat_enabled_c = [&#x27;clangformat&#x27;]</span><br></pre></td></tr></table></figure><p>与 Python black 的配置类似，语言修改为<code>c</code>, formatter 修改为 <code>clangformat</code>，参数有所不同，<code>-assume-filename=%:p</code> 表示将当前编辑的文件名传递给 clang-format，以便它可以正确地处理预编译指令等特殊情况。</p><h4 id="4-3-自定义格式化文件"><a href="#4-3-自定义格式化文件" class="headerlink" title="4.3 自定义格式化文件"></a>4.3 自定义格式化文件</h4><p>如果不想用默认的 clang-format 格式化配置，可以通过下面的方式来生成格式化文件，并通过<code>args</code> 参数传递给Neoformat来使用。</p><p>首先生成一个默认的配置文件，例如选择以google的风格来生成:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clang-format -style=google -dump-config &gt; /Users/name/.clang-format</span><br></pre></td></tr></table></figure><p>然后编辑生成的文件，修改为你想要的格式。例如我想修改默认的2空格缩进为4空格，那么去掉默认文件中的<code># BasedOnStyle:  Google</code>的注释，继承google风格的默认配置，删除后面所有的内容，只修改<code>IndentWidth</code> 项：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">Language:        Cpp</span><br><span class="line">BasedOnStyle:  Google</span><br><span class="line">IndentWidth:     4</span><br></pre></td></tr></table></figure><p>然后用<code>--style=/path/to/.clang-format</code>来代码规范文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">let g:neoformat_c_clangformat = &#123;</span><br><span class="line">            \ &#x27;exe&#x27;: &#x27;clang-format&#x27;,</span><br><span class="line">\ &#x27;args&#x27;: [&#x27;-assume-filename=%:p&#x27;, &#x27;--styel=/Users/name/.clang-format&#x27;],</span><br><span class="line">            \ &#x27;stdin&#x27;: 1,</span><br><span class="line">            \ &#125;</span><br><span class="line"></span><br><span class="line">let g:neoformat_enabled_c = [&#x27;clangformat&#x27;]</span><br></pre></td></tr></table></figure><h4 id="4-4-保存文件时自动格式化"><a href="#4-4-保存文件时自动格式化" class="headerlink" title="4.4 保存文件时自动格式化"></a>4.4 保存文件时自动格式化</h4><p>上面 3.4 部分的代码已经开启了保存时自动格式化代码，这里不需要额外增加配置了。</p><h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h3><p>总结下来，涉及到的需要增加在<code>~/.config/nvim/init.vim</code>中的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">call plug#begin(&quot;~/.nvim/bundle&quot;)</span><br><span class="line">...</span><br><span class="line">&quot; 增加neoformat</span><br><span class="line">Plug &#x27;sbdchd/neoformat&#x27;</span><br><span class="line">...</span><br><span class="line">call plug#end()</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&quot; code format</span><br><span class="line">augroup fmt</span><br><span class="line">  autocmd!</span><br><span class="line">&quot;  autocmd BufWritePre * undojoin | Neoformat</span><br><span class="line">  autocmd BufWritePre * Neoformat</span><br><span class="line">augroup END</span><br><span class="line"></span><br><span class="line">&quot; format python</span><br><span class="line">let g:neoformat_python_black = &#123;</span><br><span class="line">            \ &#x27;exe&#x27;: &#x27;black&#x27;,</span><br><span class="line">            \ &#x27;args&#x27;: [&#x27;-q&#x27;, &#x27;-&#x27;],</span><br><span class="line">            \ &#x27;stdin&#x27;: 1,</span><br><span class="line">            \ &#125;</span><br><span class="line"></span><br><span class="line">let g:neoformat_enabled_python = [&#x27;black&#x27;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot; format c/c++</span><br><span class="line">let g:neoformat_c_clangformat = &#123;</span><br><span class="line">            \ &#x27;exe&#x27;: &#x27;clang-format&#x27;,</span><br><span class="line">\ &#x27;args&#x27;: [&#x27;-assume-filename=%:p&#x27;],</span><br><span class="line">            \ &#x27;stdin&#x27;: 1,</span><br><span class="line">            \ &#125;</span><br><span class="line"></span><br><span class="line">let g:neoformat_enabled_c = [&#x27;clangformat&#x27;]</span><br></pre></td></tr></table></figure><p>格式化工具需要单独通过命令行来安装:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install black</span><br><span class="line">brew install clang-format</span><br></pre></td></tr></table></figure><p>通过 <code>:set verbose=1</code> 来打开 log 信息，对于定位问题很有帮助。</p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/sbdchd/neoformat&quot;&gt;neoformat&lt;/a&gt; 是 (Neo)Vim 的代码格式化插件，支持多种语言的格式化。这篇文章覆盖 Neoformat 对 Python 和 C++ 进行格式化的配置，以及如何在保存代码时自动进行格式化，可以直接应用的配置代码段在文章最后。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
    <category term="C++" scheme="http://vra.github.io/tags/C/"/>
    
    <category term="Vim" scheme="http://vra.github.io/tags/Vim/"/>
    
    <category term="NeoVim" scheme="http://vra.github.io/tags/NeoVim/"/>
    
    <category term="black" scheme="http://vra.github.io/tags/black/"/>
    
    <category term="clang-format" scheme="http://vra.github.io/tags/clang-format/"/>
    
  </entry>
  
  <entry>
    <title>homebrew禁止执行install命令时自动更新</title>
    <link href="http://vra.github.io/2023/06/08/homebrew-disable-auto-update/"/>
    <id>http://vra.github.io/2023/06/08/homebrew-disable-auto-update/</id>
    <published>2023-06-08T14:02:49.000Z</published>
    <updated>2023-06-08T14:13:49.420Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://brew.sh/">Homebrew</a> 是 macOS 下的默认的包管理器，不需要sudo权限就可以安装包，比较好用。</p><p>不过用<code>brew install</code>安装包时有个问题，它默认会先执行<code>brew update</code>来更新brew的版本。但由于brew 的源国内访问比较慢，常常<code>brew update</code>执行耗时比较久，影响每次安装包的体验。</p><p>解决办法是设置<code>HOMEBREW_NO_AUTO_UPDATE</code>环境变量为1，这样每次<code>brew install</code>时跳过更新brew的步骤，实际体验安装包速度提升明显。</p><p>可以添加下面的语句到你的.bashrc或.zshrc中，重启shell即生效:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HOMEBREW_NO_AUTO_UPDATE=1</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://brew.sh/&quot;&gt;Homebrew&lt;/a&gt; 是 macOS 下的默认的包管理器，不需要sudo权限就可以安装包，比较好用。&lt;/p&gt;
&lt;p&gt;不过用&lt;code&gt;brew install&lt;/code&gt;安装包时有个问题，它默认会先执行&lt;code&gt;</summary>
      
    
    
    
    
    <category term="Homebrew" scheme="http://vra.github.io/tags/Homebrew/"/>
    
    <category term="macOS" scheme="http://vra.github.io/tags/macOS/"/>
    
  </entry>
  
  <entry>
    <title>Python 命令补全神器 argcomplete</title>
    <link href="http://vra.github.io/2023/05/28/python-autocomplete-with-argcomplete/"/>
    <id>http://vra.github.io/2023/05/28/python-autocomplete-with-argcomplete/</id>
    <published>2023-05-28T02:33:12.000Z</published>
    <updated>2023-06-09T15:44:59.896Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>在使用Python 命令或者 Python的命令行工具的时候，一个痛点是没有补全。比如<code>python -m</code>后面输入包名字，就没有提示，每次想运行一个http server的时候，都需要搜索一下http服务的包名。另外，像pip，pipx等命令也没有提示，使用不太方便。</p><p>偶然看到<a href="https://github.com/kislyuk/argcomplete">argcomplete</a>这个库，按tab键就可以给Python的命令行添加自动补全，简直是使用Python的一个神器。</p><p>具体来说，argcomplete有下面的特点</p><ul><li>官方支持支持bash和zsh两种shell，对tcsh和fish有第三方贡献者提供的支持（不好意思Windows用户这里又被当做二等公民了😂）</li><li>可以对python命令和pip命令进行补全</li><li>其他任何以argparse解析的第三方包的命令都可以用自动补全，添加argcomplete的几行代码就行</li></ul><p>下面具体展开怎么对已有的工具启用自动补全，以及如何让自己的Python包支持argcomplete。</p><span id="more"></span><h2 id="2-对Python和pip启用自动补全"><a href="#2-对Python和pip启用自动补全" class="headerlink" title="2. 对Python和pip启用自动补全"></a>2. 对Python和pip启用自动补全</h2><p>首先通过<code>pip</code>命令来安装argcomplete:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install argcomplete</span><br></pre></td></tr></table></figure><p>然后执行下面的语句来启用对Python和pip的自动补全:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate-global-python-argcomplete</span><br></pre></td></tr></table></figure><p>重启Shell，试试输入<code>pip</code>然后按tab，发现就会列出所有的命令选项。</p><h2 id="3-如何对别的第三方库启用自动补全"><a href="#3-如何对别的第三方库启用自动补全" class="headerlink" title="3. 如何对别的第三方库启用自动补全"></a>3. 如何对别的第三方库启用自动补全</h2><p>有些库的命令行程序是已经支持argcomplete补全，只需要用下面的命令来激活：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(register-python-argcomplete &lt;python-app-name&gt;)</span>&quot;</span></span><br></pre></td></tr></table></figure><p>例如 pipx 包安装后会在系统安装一个命令行程序pipx，且pipx已经支持argcomplete，我们就可以用下面的命令来激活自动补全:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(register-python-argcomplete pipx)</span>&quot;</span></span><br></pre></td></tr></table></figure><p>激活后输入<code>pipx in</code> 按tab键，就可以列出pipx所有以<code>in</code>开头的命令，再按tab键会在各个候选命令之间切换。</p><p>⚠️注意：这个激活命令是只对哪些代码中已经支持了argcomplete语句的程序才生效，如果代码中无这些语句，那是不生效的。</p><h2 id="4-如何让自己的Python库支持自动补全"><a href="#4-如何让自己的Python库支持自动补全" class="headerlink" title="4. 如何让自己的Python库支持自动补全"></a>4. 如何让自己的Python库支持自动补全</h2><p>只需要增加下面几行代码，就能让你的库的命令行支持自动补全:</p><pre><code class="python"># 在ArgumentParser对象初始化前增加这两行# PYTHON_ARGCOMPLETE_OKimport argcomplete, argparse# 原有代码parser = argparse.ArgumentParser()...# 在调用parse_args()函数前增加这一行argcomplete.autocomplete(parser)# 原有代码args = parser.parse_args()...</code></pre><p>然后你的包安装后，对应的命令行程序就可以用<code>eval &quot;$(register-python-argcomplete &lt;app-name&gt;)&quot;</code>来补全了。</p><p>⚠️注意：如果程序执行到<code>argcomplete.autocomplete()</code> 被调用的地方耗时很久的话，用户按tab就会有明显的延迟感。所以尽量将一些比较耗时的操作放在<code>argcomplete.autocomplete()</code> 语句后面，比如一些<code>import</code>语句，常常比较耗时，可以往后放。</p><p>希望这个程序能让你的Python开发变得舒服一些。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h2&gt;&lt;p&gt;在使用Python 命令或者 Python的命令行工具的时候，一个痛点是没有补全。比如&lt;code&gt;python -m&lt;/code&gt;后面输入包名字，就没有提示，每次想运行一个http server的时候，都需要搜索一下http服务的包名。另外，像pip，pipx等命令也没有提示，使用不太方便。&lt;/p&gt;
&lt;p&gt;偶然看到&lt;a href=&quot;https://github.com/kislyuk/argcomplete&quot;&gt;argcomplete&lt;/a&gt;这个库，按tab键就可以给Python的命令行添加自动补全，简直是使用Python的一个神器。&lt;/p&gt;
&lt;p&gt;具体来说，argcomplete有下面的特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;官方支持支持bash和zsh两种shell，对tcsh和fish有第三方贡献者提供的支持（不好意思Windows用户这里又被当做二等公民了😂）&lt;/li&gt;
&lt;li&gt;可以对python命令和pip命令进行补全&lt;/li&gt;
&lt;li&gt;其他任何以argparse解析的第三方包的命令都可以用自动补全，添加argcomplete的几行代码就行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面具体展开怎么对已有的工具启用自动补全，以及如何让自己的Python包支持argcomplete。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>talkGPT4All 2.0</title>
    <link href="http://vra.github.io/2023/05/27/talkgpt4all-2-0/"/>
    <id>http://vra.github.io/2023/05/27/talkgpt4all-2-0/</id>
    <published>2023-05-27T06:49:45.000Z</published>
    <updated>2023-05-27T06:58:57.916Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h3><p><a href="https://github.com/vra/talkGPT4All">talkGPT4All</a>是基于<a href="https://gpt4all.io/index.html">GPT4All</a>的一个语音聊天程序，运行在本地CPU上，支持Linux，Mac和Windows。它利用OpenAI的Whisper模型将用户输入的语音转换为文本，再调用GPT4All的语言模型得到回答文本，最后利用文本转语音(TTS)的程序将回答文本朗读出来。</p><p>关于 talkGPT4All 1.0的介绍在<a href="https://juejin.cn/post/7217112585802498107">这篇文章</a>。</p><p>talkGPT4All 1.0的<a href="https://www.zhihu.com/zvideo/1625779747656515584">视频效果</a>。</p><p>由于GPT4All一直在迭代，相比上一篇文章发布时(2023-04-10)已经有较大的更新，今天将GPT4All的一些更新同步到talkGPT4All，由于支持的模型和运行模式都有较大的变化，因此发布 talkGPT4All 2.0。</p><p>具体来说，2.0版本相比1.0有下面的更新。</p><p>首先是GPT4All框架支持的语言模型从1个增加到8个，并且可以一键切换模型。具体的模型是</p><ul><li>  Vicuna-7B-1.1-q4_2</li><li>  Vicuna-7B-1.2-q4_2</li><li>  wizardLM-7B.q4_2</li><li>  GPT4All</li><li>  GPT4All-J</li><li>  GPT4All-J-v1.1</li><li>  GPT4All-J-v1.2</li><li>  GPT4All-J-v1.3</li></ul><p>可以看到除了GPT4All系列的模型，这个框架也支持Vicuna和Wizard的模型了。更多模型因为证书和格式的问题，还在集成中。</p><p>根据GPT4All的<a href="https://gpt4all.io/index.html">文档</a>，不同模型在benchmark上的结果：</p><p><img data-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/988ae9ef513049d68d790e742f9e2139~tplv-k3u1fbpfcp-zoom-1.image"></p><p>可以看到GPT4All系列的模型的指标还是比较高的。</p><p>另一个重要更新是GPT4All发布了更成熟的Python包，可以直接通过pip 来安装，因此1.0中集成的不同平台不同的GPT4All二进制包也不需要了。集成PyPI包的好处多多，既可以查看源码学习内部的实现，又更方便定位问题（之前的二进制包没法调试内部代码），且保证了不同平台安装命令一致（之前不同平台二进制包不同）。</p><p>还有一个变化是GPT4All会自动按需下载模型，因此用户不需要手动下载和维护模型路径。同时将模型统一放置到<a href="https://gpt4all.io/models/">https://gpt4all.io/models/</a> 目录下，测试国内模型下载速度也很快，大家玩起来也会更舒服。</p><p>核心的更新内容就这些，下面对talkGPT4All的安装和使用进行说明，后面有空会添加一些多个语言模型效果的对比视频。</p><span id="more"></span><h3 id="2-安装与使用"><a href="#2-安装与使用" class="headerlink" title="2. 安装与使用"></a>2. 安装与使用</h3><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><p>由于GPT4All, OpenAI Whisper 和TTS工具都是PyPI的包，因此所有的依赖都可以用pip 命令来安装。</p><p>流程大致上就是clone代码，创建Python虚拟环境，安装依赖，开始聊天：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/vra/talkGPT4All.git</span><br><span class="line"><span class="built_in">cd</span> talkGPT4All</span><br><span class="line">python -m venv talkgpt4all-env</span><br><span class="line"><span class="built_in">source</span> talkgpt4all-env/bin/activate</span><br><span class="line">pip install -U pip</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>如果在Linux环境下使用，还需要安装 TTS 工具 pyttsx3 的一些前置依赖，例如在Ubuntu下，可以这么安装（别的发行版切换apt 为对应的包管理命令应该就可以）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update &amp;&amp; sudo apt install -y espeak ffmpeg libespeak1</span><br></pre></td></tr></table></figure><p>依赖安装完后即刻开始聊天：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python chat.py</span><br></pre></td></tr></table></figure><p>语音输入问题，Whisper会识别语音到文字，第一次需要下载模型Whisper的模型，可能耗时会比较久。Whisper 模型默认存储地址是<code>~/.cache/whisper/</code>。</p><p>文字识别后，输入到语言模型部分后会下载语言模型文件，文件默认存储到<code>~/.cache/gpt4all</code> 目录。</p><h3 id="2-2-切换不同的LLM"><a href="#2-2-切换不同的LLM" class="headerlink" title="2.2 切换不同的LLM"></a>2.2 切换不同的LLM</h3><p>默认的语言模型是GPT4All-J-v1.3,，可以通过命令行选项–gpt-model-name来切换模型，所有的选项是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;ggml-gpt4all-j-v1.3-groovy&quot;</span></span><br><span class="line"><span class="string">&quot;ggml-gpt4all-j-v1.2-jazzy&quot;</span></span><br><span class="line"><span class="string">&quot;ggml-gpt4all-j-v1.1-breezy&quot;</span></span><br><span class="line"><span class="string">&quot;ggml-gpt4all-j&quot;</span></span><br><span class="line"><span class="string">&quot;ggml-gpt4all-l13b-snoozy&quot;</span></span><br><span class="line"><span class="string">&quot;ggml-vicuna-7b-1.1-q4_2&quot;</span></span><br><span class="line"><span class="string">&quot;ggml-vicuna-13b-1.1-q4_2&quot;</span></span><br><span class="line"><span class="string">&quot;ggml-wizardLM-7B.q4_2&quot;</span></span><br></pre></td></tr></table></figure><p>例如可以这样使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python chat.py --gpt-model-name ggml-wizardLM-7B.q4_2</span><br></pre></td></tr></table></figure><p>如果模型未下载过，会进行下载。</p><p>这里有个小问题，GPT4All工具貌似没有对模型的完整性进行校验，所以如果之前模型下载没完成就退出，再次进入后会加载不完整的文件，造成报错。所以需要手动删除不完整的文件再次完整下载后使用。</p><h3 id="2-3-切换不同大小的Whisper模型"><a href="#2-3-切换不同大小的Whisper模型" class="headerlink" title="2.3 切换不同大小的Whisper模型"></a>2.3 切换不同大小的Whisper模型</h3><p>OpenAI Whisper 也有一系列的模型，模型越大识别结果应该是越准。talkGPT4All默认使用的是base模型，也提供了命令行参数–whisper-model-type 来修改，所有的可选项是:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;tiny.en&quot;</span></span><br><span class="line"><span class="string">&quot;tiny&quot;</span></span><br><span class="line"><span class="string">&quot;base.en&quot;</span></span><br><span class="line"><span class="string">&quot;base&quot;</span></span><br><span class="line"><span class="string">&quot;small.en&quot;</span></span><br><span class="line"><span class="string">&quot;small&quot;</span></span><br><span class="line"><span class="string">&quot;medium.en&quot;</span></span><br><span class="line"><span class="string">&quot;medium&quot;</span></span><br><span class="line"><span class="string">&quot;large-v1&quot;</span></span><br><span class="line"><span class="string">&quot;large-v2&quot;</span></span><br><span class="line"><span class="string">&quot;large&quot;</span></span><br></pre></td></tr></table></figure><p>例如可以这样使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python chat.py --whisper-model-type large</span><br></pre></td></tr></table></figure><h3 id="2-4-调整声音语速"><a href="#2-4-调整声音语速" class="headerlink" title="2.4 调整声音语速"></a>2.4 调整声音语速</h3><p>talkGPT4All也提供了一个参数–voice rate 来调整 TTS发音的速度，默认是165，设置越大速度越快:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python chat.py --voice-rate 200</span><br></pre></td></tr></table></figure><h3 id="3-缺陷和改进思考"><a href="#3-缺陷和改进思考" class="headerlink" title="3. 缺陷和改进思考"></a>3. 缺陷和改进思考</h3><p>其实talkGPT4All一直以来的缺陷是比较明显的：</p><ol><li> 大模型在CPU上出词太慢</li><li> 离线的文本转语音的程序太生硬</li></ol><p>针对第一个问题，我的思考是这样，要在非Nvidia GPU设备上流畅运行基于Transformer结构的大语言模型，除了4比特量化、fp16这种 low-hang fruit外，必须要做很多底层的AI工程的优化，这个我觉得我自己是没有能力来完成的，甚至我猜测，可能GPT4All背后的Nomic AI团队也没有这方面的积累来解决这个问题。</p><p>可喜的是最近看到了<a href="https://github.com/mlc-ai/mlc-llm">MLC LLM</a>这个工作，是TVM 团队利用TVM Unity来优化语言模型，成功地将Vicuna-7B运行到了<a href="https://github.com/mlc-ai/mlc-llm/blob/main/android/README.md">Android</a>和<a href="https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md">iOS</a>手机上，我自己用小米12 Pro测试每秒能输出3～4个token，体验算是比较好的。这也是我第一次在自己手机上运行大语言模型，也意识到真正要提高大语言模型的覆盖设备，一个极致优化的底层AI工具是必不可少的。</p><p>所以对talkGPT4All这个项目感兴趣的朋友也可以了解一下MLC LLM这个工作，我认为在未来这个项目会促进LLM的真正落地。</p><p>针对第二个问题，说实话还没有找到比较自然的离线 TTS Python工具，如果看到这篇文章的你有这方面的经验，欢迎评论交流～</p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/vra/talkGPT4All&quot;&gt;talkGPT4All&lt;/a&gt;是基于&lt;a href=&quot;https://gpt4all.io/index.html&quot;&gt;GPT4All&lt;/a&gt;的一个语音聊天程序，运行在本地CPU上，支持Linux，Mac和Windows。它利用OpenAI的Whisper模型将用户输入的语音转换为文本，再调用GPT4All的语言模型得到回答文本，最后利用文本转语音(TTS)的程序将回答文本朗读出来。&lt;/p&gt;
&lt;p&gt;关于 talkGPT4All 1.0的介绍在&lt;a href=&quot;https://juejin.cn/post/7217112585802498107&quot;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;talkGPT4All 1.0的&lt;a href=&quot;https://www.zhihu.com/zvideo/1625779747656515584&quot;&gt;视频效果&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;由于GPT4All一直在迭代，相比上一篇文章发布时(2023-04-10)已经有较大的更新，今天将GPT4All的一些更新同步到talkGPT4All，由于支持的模型和运行模式都有较大的变化，因此发布 talkGPT4All 2.0。&lt;/p&gt;
&lt;p&gt;具体来说，2.0版本相比1.0有下面的更新。&lt;/p&gt;
&lt;p&gt;首先是GPT4All框架支持的语言模型从1个增加到8个，并且可以一键切换模型。具体的模型是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;  Vicuna-7B-1.1-q4_2&lt;/li&gt;
&lt;li&gt;  Vicuna-7B-1.2-q4_2&lt;/li&gt;
&lt;li&gt;  wizardLM-7B.q4_2&lt;/li&gt;
&lt;li&gt;  GPT4All&lt;/li&gt;
&lt;li&gt;  GPT4All-J&lt;/li&gt;
&lt;li&gt;  GPT4All-J-v1.1&lt;/li&gt;
&lt;li&gt;  GPT4All-J-v1.2&lt;/li&gt;
&lt;li&gt;  GPT4All-J-v1.3&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到除了GPT4All系列的模型，这个框架也支持Vicuna和Wizard的模型了。更多模型因为证书和格式的问题，还在集成中。&lt;/p&gt;
&lt;p&gt;根据GPT4All的&lt;a href=&quot;https://gpt4all.io/index.html&quot;&gt;文档&lt;/a&gt;，不同模型在benchmark上的结果：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/988ae9ef513049d68d790e742f9e2139~tplv-k3u1fbpfcp-zoom-1.image&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到GPT4All系列的模型的指标还是比较高的。&lt;/p&gt;
&lt;p&gt;另一个重要更新是GPT4All发布了更成熟的Python包，可以直接通过pip 来安装，因此1.0中集成的不同平台不同的GPT4All二进制包也不需要了。集成PyPI包的好处多多，既可以查看源码学习内部的实现，又更方便定位问题（之前的二进制包没法调试内部代码），且保证了不同平台安装命令一致（之前不同平台二进制包不同）。&lt;/p&gt;
&lt;p&gt;还有一个变化是GPT4All会自动按需下载模型，因此用户不需要手动下载和维护模型路径。同时将模型统一放置到&lt;a href=&quot;https://gpt4all.io/models/&quot;&gt;https://gpt4all.io/models/&lt;/a&gt; 目录下，测试国内模型下载速度也很快，大家玩起来也会更舒服。&lt;/p&gt;
&lt;p&gt;核心的更新内容就这些，下面对talkGPT4All的安装和使用进行说明，后面有空会添加一些多个语言模型效果的对比视频。&lt;/p&gt;</summary>
    
    
    
    
    <category term="GPT" scheme="http://vra.github.io/tags/GPT/"/>
    
    <category term="GPT4All" scheme="http://vra.github.io/tags/GPT4All/"/>
    
    <category term="LLM" scheme="http://vra.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>mac 编译问题解决——building for macOS-x86_64 but attempting to link with file built for xxx</title>
    <link href="http://vra.github.io/2023/05/27/mac-ranlib-issue/"/>
    <id>http://vra.github.io/2023/05/27/mac-ranlib-issue/</id>
    <published>2023-05-26T17:17:15.000Z</published>
    <updated>2023-05-26T17:19:20.646Z</updated>
    
    <content type="html"><![CDATA[<p>在编译TVM的一个<a href="https://github.com/mlc-ai/relax">fork版本</a>时，遇到下面的报错：</p><blockquote><p>ld: warning: ignoring file libbacktrace/lib/libbacktrace.a, building for macOS-x86_64 but attempting to link with file built for unknown-unsupported file format ( 0x21 0x3C 0x61 0x72 0x63 0x68 0x3E 0x0A<br> 0x2F 0x20 0x20 0x20 0x20 0x20 0x20 0x20 )<br>Undefined symbols for architecture x86_64:<br>  “_backtrace_create_state”, referenced from:<br>      __GLOBAL__sub_I_logging.cc in logging.cc.o<br>  “_backtrace_full”, referenced from:<br>      tvm::runtime::Backtrace() in logging.cc.o<br>  “_backtrace_syminfo”, referenced from:<br>      tvm::runtime::(anonymous namespace)::BacktraceFullCallback(void*, unsigned long, char const*, int, char const*) in logging.cc.o<br>ld: symbol(s) not found for architecture x86_64<br>clang: error: linker command failed with exit code 1 (use -v to see invocation)<br>make[3]: *** [libtvm_runtime.dylib] Error 1<br>make[2]: *** [CMakeFiles/tvm_runtime.dir/all] Error 2<br>make[2]: *** Waiting for unfinished jobs….</p></blockquote><p>搜索了一下，发现核心原因是Mac下ranlib命令采用了GNU版本，而非Apple版本导致的，下面详细展开报错原因和解决办法。</p><span id="more"></span><p>在Mac下，有两套编译工具链，GNU的和Apple（通过Xcode安装）的，GNU的以<code>gcc</code>为代表，而Apple的则以<code>clang</code>为代表，在这两个核心编译工具周围，又有很多别的小的编译工具。</p><p>通过log输出发现，编译工具用的是<code>/usr/bin/cc</code>, 执行<code>/usr/bin/cc --version</code> 命令，输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/bin/cc --version</span><br><span class="line">Apple clang version 14.0.0 (clang-1400.0.29.202)</span><br><span class="line">Target: x86_64-apple-darwin22.2.0</span><br><span class="line">Thread model: posix</span><br><span class="line">InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin</span><br></pre></td></tr></table></figure><p>可以看到是Apple的编译工具链Apple clang。</p><p>在编译过程中，发现log中有下面的输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ibtool: install: ranlib /path/to/relax/build/libbacktrace/lib/libbacktrace.a</span><br></pre></td></tr></table></figure><p>可以看到调用了<code>ranlib</code>命令来生成<code>libbacktrace.a</code>。</p><p>通过<code>which ranlib</code> 验证ranlib的路径：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">which</span> ranlib</span><br><span class="line">/usr/<span class="built_in">local</span>/opt/binutils/bin/ranlib</span><br><span class="line"></span><br><span class="line">$ ranlib --version</span><br><span class="line">GNU ranlib (GNU Binutils) 2.40</span><br><span class="line">Copyright (C) 2023 Free Software Foundation, Inc.</span><br><span class="line">This program is free software; you may redistribute it under the terms of</span><br><span class="line">the GNU General Public License version 3 or (at your option) any later version.</span><br><span class="line">This program has absolutely no warranty.</span><br></pre></td></tr></table></figure><p>可以看到，找到的是GPN版本的ranlib，而不是跟编译工具匹配的Apple的ranlib（路径是<code>/usr/bin/ranlib</code>)。</p><p>如果是Apple的ranlib工具的话，<code>ranlib --version</code>输出应该是下面这样：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ranlib</span> --version</span><br><span class="line">error: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: unknown option character `-<span class="string">&#x27; in: --version</span></span><br><span class="line"><span class="string">Usage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib [-sactfqLT] [-] archive [...]</span></span><br></pre></td></tr></table></figure><p>那为什么会有两套工具链混合使用导致出错的问题？这是因为路径设置优先级的原因，在PATH中，<code>/usr/local/opt/binutils/bin</code>在<code>/usr/bin</code>的前面：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="variable">$PATH</span></span><br><span class="line">...:/usr/<span class="built_in">local</span>/opt/binutils/bin:/usr/bin:...</span><br></pre></td></tr></table></figure><p>所以在搜索可执行文件时，先找到了GNU的ranlib，而这个又与Apple的编译工具链不兼容。导致编译出错。</p><p>那<code>ranlib</code>是干什么用的呢？根据ChatGPT， ranlib功能如下：</p><blockquote><p>ranlib是一个命令行工具，用于在静态库中创建索引（也称为符号表）。索引提供静态库中所有符号（函数、变量等）的列表。它帮助编译器和链接器在链接时更快地查找和解析符号。当一个程序需要链接静态库时，链接器会使用ranlib创建的索引来确定静态库中包含的符号，以便正确地链接程序。</p></blockquote><p>可以看到，ranlib对于编译静态库来说，是必不可少的（与<code>ar -s</code>完全等效）。</p><p>其实我不记得在PATH中添加过<code>/usr/local/opt/binutils/bin</code>这个目录，应该是安装某些包后自动更新的。</p><p>那这个问题该怎么解决呢？通过上面的分析，我们也能发现其实解决办法也比较直观，总体来说有两种，一种是修改PATH中两个目录的寻找优先级，保证先找到的是Apple的工具，也就是<code>/usr/bin</code>目录在<code>/usr/local/opt</code> 前面；另一种是直接卸载GNU的工具<code>binutils</code>，这样就不会有冲突。</p><p>在这里我选择执行第二种，具体命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew uninstall binutils</span><br></pre></td></tr></table></figure><p>然后再检查<code>ranlib --version</code> 命令的输出，确认是Apple的工具链后再<code>make clean</code>，重新编译即可。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol><li><a href="https://stackoverflow.com/a/72904009">https://stackoverflow.com/a/72904009</a></li><li><a href="https://github.com/bitcoin/bitcoin/issues/20825#issuecomment-753444519">https://github.com/bitcoin/bitcoin/issues/20825#issuecomment-753444519</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;在编译TVM的一个&lt;a href=&quot;https://github.com/mlc-ai/relax&quot;&gt;fork版本&lt;/a&gt;时，遇到下面的报错：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ld: warning: ignoring file libbacktrace/lib/libbacktrace.a, building for macOS-x86_64 but attempting to link with file built for unknown-unsupported file format ( 0x21 0x3C 0x61 0x72 0x63 0x68 0x3E 0x0A&lt;br&gt; 0x2F 0x20 0x20 0x20 0x20 0x20 0x20 0x20 )&lt;br&gt;Undefined symbols for architecture x86_64:&lt;br&gt;  “_backtrace_create_state”, referenced from:&lt;br&gt;      __GLOBAL__sub_I_logging.cc in logging.cc.o&lt;br&gt;  “_backtrace_full”, referenced from:&lt;br&gt;      tvm::runtime::Backtrace() in logging.cc.o&lt;br&gt;  “_backtrace_syminfo”, referenced from:&lt;br&gt;      tvm::runtime::(anonymous namespace)::BacktraceFullCallback(void*, unsigned long, char const*, int, char const*) in logging.cc.o&lt;br&gt;ld: symbol(s) not found for architecture x86_64&lt;br&gt;clang: error: linker command failed with exit code 1 (use -v to see invocation)&lt;br&gt;make[3]: *** [libtvm_runtime.dylib] Error 1&lt;br&gt;make[2]: *** [CMakeFiles/tvm_runtime.dir/all] Error 2&lt;br&gt;make[2]: *** Waiting for unfinished jobs….&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;搜索了一下，发现核心原因是Mac下ranlib命令采用了GNU版本，而非Apple版本导致的，下面详细展开报错原因和解决办法。&lt;/p&gt;</summary>
    
    
    
    
    <category term="总结" scheme="http://vra.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
    <category term="macOS" scheme="http://vra.github.io/tags/macOS/"/>
    
    <category term="GNU" scheme="http://vra.github.io/tags/GNU/"/>
    
    <category term="Apple" scheme="http://vra.github.io/tags/Apple/"/>
    
    <category term="XCode" scheme="http://vra.github.io/tags/XCode/"/>
    
    <category term="ranlib" scheme="http://vra.github.io/tags/ranlib/"/>
    
    <category term="binutils" scheme="http://vra.github.io/tags/binutils/"/>
    
    <category term="TVM" scheme="http://vra.github.io/tags/TVM/"/>
    
  </entry>
  
  <entry>
    <title>用 Material for MkDocs 来生成专业的技术文档</title>
    <link href="http://vra.github.io/2023/05/17/mkdocs-material-tutorial/"/>
    <id>http://vra.github.io/2023/05/17/mkdocs-material-tutorial/</id>
    <published>2023-05-17T11:31:37.000Z</published>
    <updated>2023-05-17T11:37:34.893Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>对于程序员来说，写技术文档是一项必备的技能。由于GitHub和Markdown格式的普及，很多时候我们可以用markdown来简便地写出技术文档，并且 通过GitHub Pages等工具快速地进行技术文档的部署。</p><p>虽然GItHub Pages默认支持静态文档框架<a href="https://jekyllrb.com/">Jekyll</a>，也包含一些简单的<a href="https://pages.github.com/themes/">主题</a>，但对于文档和教程比较多的项目来说，使用GitHub Pages的默认部署工具还不够用，主要体现在下面几个方面：</p><ul><li>Markdown本身支持的语法比较简单，一些复杂的像Warning等提示没法直接用Pages的默认主题来实现</li><li>Pages 默认显示的是单页文档，没有侧边栏、导航栏等工具</li><li>Pages 默认主题无法搜索文档内容</li><li>Pages 不支持选择<code>Linux</code>或<code>Windows</code> 后显示不同执行语句的功能</li><li>…</li></ul><p><a href="https://squidfunk.github.io/mkdocs-material/">Material for MkDocs</a> 是 <a href="https://www.mkdocs.org/">MkDocs</a>的一个主题配置，同时也是一个功能齐全的静态网站生成工具，能够解决上面提到的GitHub Pages的问题。</p><p>Material for MkDocs 使用广泛，下面是一些大公司和知名开源项目的使用例子：</p><ul><li><a href="https://aws.github.io/copilot-cli/">AWS Copilot CLI </a></li><li><a href="https://google.github.io/accompanist/">Google Accompanist</a></li><li><a href="https://microsoft.github.io/code-with-engineering-playbook/">MicroSoft Code With Engineering Playbook</a></li><li><a href="https://mozillafoundation.github.io/engineering-handbook/">Mozilla Foundation Engineering Handbook</a></li><li><a href="https://netflix.github.io/titus/">Netflix Titus</a></li><li><a href="https://docs.infra.centos.org/">CentOS Infra docs</a></li><li><a href="https://www.electron.build/">electron-builder</a></li><li><a href="https://kops.sigs.k8s.io/">Kubernetes</a></li></ul><p>虽然我还没有比较复杂的开源项目需要用mkdocs-material来管理文档，但看到GitHub Pages的一些限制，最近有空还是学了一下这个工具，以备后续项目中使用。这里做一些简单记录，方便以后查找。</p><p>需要说明的是，Material for MkDocs 是一个比较复杂的工具，很多配置项这里没有提到，根据需要在官方<a href="https://squidfunk.github.io/mkdocs-material/setup/">Setup</a>文档中查看使用说明。</p><p>另外一种学习配置的方式是直接查看上面提到的开源项目源码根目录下的<code>mkdocs.yml</code>文件，复制这个文件过去，就能得到类似的布局效果。</p><p>这个教程里面的示例页面：<a href="https://vra.github.io/mkdocs-material-example/">https://vra.github.io/mkdocs-material-example/</a><br>示例页面的配置文件：<a href="https://github.com/vra/mkdocs-material-example/blob/main/mkdocs.yml">https://github.com/vra/mkdocs-material-example/blob/main/mkdocs.yml</a></p><span id="more"></span><h2 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h2><p>可以直接使用 <code>pip</code> 来安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mkdocs-material</span><br></pre></td></tr></table></figure><p>使用下面的命令测试是否安装成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdocs -h</span><br></pre></td></tr></table></figure><p>其他从docker安装、从GitHub安装的方式参考<a href="https://squidfunk.github.io/mkdocs-material/getting-started/#with-docker">官方文档</a>。</p><h3 id="2-2-使用"><a href="#2-2-使用" class="headerlink" title="2.2 使用"></a>2.2 使用</h3><p>mkdocs-material 的使用命令比较简单，概括来说就是三板斧：</p><ol><li><code>mkdocs new .</code>： 在当前目录生成<code>docs</code>目录和<code>mkdocs.yml</code> 配置文件</li><li><code>mkdocs serve</code>： 在本地运行文档生成服务，可在浏览器中访问<code>localhost:8000</code>查看文档的效果</li><li><code>mkdocs build</code>： 非必需，在<code>sites</code> 目录中生成最终的HTML文件</li></ol><p>由于命令比较简单，没有什么太多东西，因而核心要做的事情其实是：</p><ul><li>写markdown 格式的文档文件</li><li>修改配置文件<code>mkdocs.yml</code></li></ul><p>在<code>mkdocs serve</code> 运行的过程中，更新完 <code>mkdocs.yml</code>配置文件后，文档生成效果实时更新。</p><h3 id="2-3-上传文档到-GitHub-Pages"><a href="#2-3-上传文档到-GitHub-Pages" class="headerlink" title="2.3 上传文档到 GitHub Pages"></a>2.3 上传文档到 GitHub Pages</h3><p>mkdocs-material 一个很棒的特性是可以一键将代码部署到GIthub Pages上，并且通过GitHub Actions配置，Push 代码时自动更新文档。<br>假如你的GitHub 仓库地址是<code>https://github.com/user/repo</code>，那完成配置后你就可以在<code>https://user.github.io/repo</code> 网址查看你的mkdocs-material 文档了。</p><p>具体来说，假设你已经创建了一个Git 仓库，需要做下面的事情：</p><ol><li>将<code>mkdocs.yml</code> 和<code>docs</code> 目录提交到Git仓库</li><li>增加GitHub Action 配置文件<code>.github/workflows/ci.yml</code>，写入下面的内容并提交到GitHub:<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">ci</span> </span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="attr">branches:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">master</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">main</span></span><br><span class="line"><span class="attr">permissions:</span></span><br><span class="line">  <span class="attr">contents:</span> <span class="string">write</span></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">deploy:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v3</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/setup-python@v4</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">python-version:</span> <span class="number">3.</span><span class="string">x</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">run:</span> <span class="string">echo</span> <span class="string">&quot;cache_id=$(date --utc &#x27;+%V&#x27;)&quot;</span> <span class="string">&gt;&gt;</span> <span class="string">$GITHUB_ENV</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/cache@v3</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">key:</span> <span class="string">mkdocs-material-$&#123;&#123;</span> <span class="string">env.cache_id</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">.cache</span></span><br><span class="line">          <span class="attr">restore-keys:</span> <span class="string">|</span></span><br><span class="line"><span class="string">            mkdocs-material-</span></span><br><span class="line"><span class="string"></span>      <span class="bullet">-</span> <span class="attr">run:</span> <span class="string">pip</span> <span class="string">install</span> <span class="string">mkdocs-material</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="attr">run:</span> <span class="string">mkdocs</span> <span class="string">gh-deploy</span> <span class="string">--force</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>在GitHub仓库的<code>Settings</code> -&gt; <code>Pages</code> -&gt; <code>Build and deployment</code> 部分，Source 选项选择”Deploy from a branch”, Branch 选择<code>gh-pages</code>, folder选择<code>/(root)</code><br>经过这个配置后，每次向<code>master</code> 或<code>main</code> 分支push代码，会自动更新<code>user.github.io/repo</code>下的文档。</li></ol>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h2&gt;&lt;p&gt;对于程序员来说，写技术文档是一项必备的技能。由于GitHub和Markdown格式的普及，很多时候我们可以用markdown来简便地写出技术文档，并且 通过GitHub Pages等工具快速地进行技术文档的部署。&lt;/p&gt;
&lt;p&gt;虽然GItHub Pages默认支持静态文档框架&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt;，也包含一些简单的&lt;a href=&quot;https://pages.github.com/themes/&quot;&gt;主题&lt;/a&gt;，但对于文档和教程比较多的项目来说，使用GitHub Pages的默认部署工具还不够用，主要体现在下面几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Markdown本身支持的语法比较简单，一些复杂的像Warning等提示没法直接用Pages的默认主题来实现&lt;/li&gt;
&lt;li&gt;Pages 默认显示的是单页文档，没有侧边栏、导航栏等工具&lt;/li&gt;
&lt;li&gt;Pages 默认主题无法搜索文档内容&lt;/li&gt;
&lt;li&gt;Pages 不支持选择&lt;code&gt;Linux&lt;/code&gt;或&lt;code&gt;Windows&lt;/code&gt; 后显示不同执行语句的功能&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://squidfunk.github.io/mkdocs-material/&quot;&gt;Material for MkDocs&lt;/a&gt; 是 &lt;a href=&quot;https://www.mkdocs.org/&quot;&gt;MkDocs&lt;/a&gt;的一个主题配置，同时也是一个功能齐全的静态网站生成工具，能够解决上面提到的GitHub Pages的问题。&lt;/p&gt;
&lt;p&gt;Material for MkDocs 使用广泛，下面是一些大公司和知名开源项目的使用例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://aws.github.io/copilot-cli/&quot;&gt;AWS Copilot CLI &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://google.github.io/accompanist/&quot;&gt;Google Accompanist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://microsoft.github.io/code-with-engineering-playbook/&quot;&gt;MicroSoft Code With Engineering Playbook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://mozillafoundation.github.io/engineering-handbook/&quot;&gt;Mozilla Foundation Engineering Handbook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://netflix.github.io/titus/&quot;&gt;Netflix Titus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.infra.centos.org/&quot;&gt;CentOS Infra docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.electron.build/&quot;&gt;electron-builder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://kops.sigs.k8s.io/&quot;&gt;Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然我还没有比较复杂的开源项目需要用mkdocs-material来管理文档，但看到GitHub Pages的一些限制，最近有空还是学了一下这个工具，以备后续项目中使用。这里做一些简单记录，方便以后查找。&lt;/p&gt;
&lt;p&gt;需要说明的是，Material for MkDocs 是一个比较复杂的工具，很多配置项这里没有提到，根据需要在官方&lt;a href=&quot;https://squidfunk.github.io/mkdocs-material/setup/&quot;&gt;Setup&lt;/a&gt;文档中查看使用说明。&lt;/p&gt;
&lt;p&gt;另外一种学习配置的方式是直接查看上面提到的开源项目源码根目录下的&lt;code&gt;mkdocs.yml&lt;/code&gt;文件，复制这个文件过去，就能得到类似的布局效果。&lt;/p&gt;
&lt;p&gt;这个教程里面的示例页面：&lt;a href=&quot;https://vra.github.io/mkdocs-material-example/&quot;&gt;https://vra.github.io/mkdocs-material-example/&lt;/a&gt;&lt;br&gt;示例页面的配置文件：&lt;a href=&quot;https://github.com/vra/mkdocs-material-example/blob/main/mkdocs.yml&quot;&gt;https://github.com/vra/mkdocs-material-example/blob/main/mkdocs.yml&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="Docs" scheme="http://vra.github.io/tags/Docs/"/>
    
    <category term="Markdown" scheme="http://vra.github.io/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>Rye:一个实验性质的Python包管理系统</title>
    <link href="http://vra.github.io/2023/05/17/rye-intro/"/>
    <id>http://vra.github.io/2023/05/17/rye-intro/</id>
    <published>2023-05-17T02:08:32.000Z</published>
    <updated>2023-05-17T02:17:20.438Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://mitsuhiko.github.io/rye/">Rye</a> 是<a href="https://flask.palletsprojects.com/en/2.3.x/">Flask</a>的作者<a href="https://github.com/mitsuhiko">Armin Ronacher</a>最近推出的一个实验性质的Python包管理系统，目的是解决Python包管理目前面临的工具链碎片化的问题。</p><p>大家知道，Python目前的包管理系统很多，包括 poetry, pip, pipenv, pyenv, venv, virtualenv, pdm, hatch 等等，它们都是优秀的工具，提出时都是解决了一定的问题，但没有哪个工具能够做到主流，因此也增加了系统的碎片化程度。</p><p>另一方面，conda等工具能提供不同版本的 Python，管理不同的环境，但每个环境的 Python 不是共享的，环境创建一多，环境目录就变得很大，且内部机制很不透明，有时也会遇到冲突没法解决的问题。</p><p>另一方面，Python 在Linux/macOS上的安装也面临一些问题，例如用包管理器安装的  Python和用户手动安装的 Python 有的时候会混淆，导致一些混乱，例如在 Fedora 上，用<code>pip install</code> 安装包可能会导致系统的包管理命令<code>dnf</code> 出错。<a href="https://peps.python.org/pep-0668">PEP 668</a>尝试对这些问题给出一个解决方案，但也需要不同的系统来支持，目前看还任重道远。</p><p>由于Armin也是一个Rust 开发者，而Rust基于标准化的<code>rustup</code>和<code>cargo</code>两个工具，配合配置文件来进行包管理，目前做的比较好，没有Python面临的碎片化问题。受Rust的启发，作者提出了Rye，并且期望能够启发Python社区提出类似Rust的标准包管理工具。</p><p>具体来说，Rye 提出了一些解决这些问题的思路：</p><ul><li>提出一个workspace的概念，workspace类似一个项目目录，或者一个git仓库，一个workspace下只有一个Python版本，不同workspace Python版本相互隔离，每个项目采用<code>pyproject.toml</code>来进行配置</li><li>不使用系统自带的Python，相反地，在每个项目目录的中下载一个standalone的python，解决不同版本的冲突问题</li><li>不暴露pip命令，通过<code>rye add</code> + <code>rye sync</code> 来管理包的依赖，避免包A和包B依赖不同版本的包C而导致的不兼容问题</li><li>区分开发环境和正式环境，因为一些包在开发时会用到一些调试工具，但作为第三方库被引入的时候并不需要</li><li>支持import本地workspace作为第三方库包</li></ul><p>但同时也有一个问题：rye会不会是另一个做不到主流的Python包管理系统，从而进一步增加Python包管理的碎片化呢？作者也有这个考虑，因此写了一个讨论帖 <a href="https://github.com/mitsuhiko/rye/discussions/6">Should Rye Exist?</a>来讨论这个问题，同时关于Rye的设计初衷，可以参考<a href="https://mitsuhiko.github.io/rye/philosophy/">这里</a>作者的思考。</p><p>个人观点：Rye的出现给Python社区引入了一些新鲜的解决现有问题的思路。使用Rye一段时间后，发现至少使用standalone 的Python版本是一个解决冲突的好的方式。通过几个简单的命令来解决版本管理的问题是比较直观的，提出Rye应该是利大于弊的，也就是有益程度大于碎片化增加的程度。</p><p>总之不管是<a href="https://peps.python.org/pep-0668">PEP 668</a>中标记版本管理是系统的还是Python的，还是<a href="https://peps.python.org/pep-0711/">PEP 711</a>来单独下发Python解释器二进制文件，还是Rye的出现，都是Python社区意识到Python包管理问题的严重性，进而做出的一些有益尝试。期待在未来，有更标准化的工具，Python的开发也更容易。</p><p>下面将对Rye的安装和使用进行简单介绍。</p><span id="more"></span><h3 id="2-1-安装rustup"><a href="#2-1-安装rustup" class="headerlink" title="2.1 安装rustup"></a>2.1 安装rustup</h3><p>Rye是基于Rust 开发的，而Rust 有标准的包安装工具<code>cargo</code>，Rust编译器和<code>cargo</code>都需要用<code>rustup</code>来安装，因此安装预编译的Rye包需要先安装<code>rustup</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl --proto <span class="string">&#x27;=https&#x27;</span> --tlsv1.2 -sSf https://sh.rustup.rs | sh</span><br></pre></td></tr></table></figure><p>执行完后，重启Shell，输入<code>cargo -V</code>，如果不报错，说明安装成功。</p><h3 id="2-2-安装Rye"><a href="#2-2-安装Rye" class="headerlink" title="2.2 安装Rye"></a>2.2 安装Rye</h3><p>有了cargo后，使用下面的命令安装Rye:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cargo install --git https://github.com/mitsuhiko/rye rye</span><br></pre></td></tr></table></figure><p>通过命令行执行<code>rye -h</code> 来判断 Rye是否安装成功。</p><p>同时可以将<code>$HOME/.rye/shims</code> 添加到环境变量<code>PATH</code> 中，这样打开Shell后运行<code>python</code> 就用的是Rye安装到standalone Python，否则你需要用<code>rye run python</code> 来启用Rye的Python解释器。</p><p>更新Rye到最新版：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rye self update</span><br></pre></td></tr></table></figure><p>删除Rye:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cargo uninstall rye</span><br></pre></td></tr></table></figure><h3 id="2-3-初始化一个Rye项目"><a href="#2-3-初始化一个Rye项目" class="headerlink" title="2.3 初始化一个Rye项目"></a>2.3 初始化一个Rye项目</h3><p>使用<code>rye init project-name</code> 来创建一个Rye项目目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rye init test_rye</span><br><span class="line"><span class="built_in">cd</span> test_rye</span><br><span class="line">tree</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">├── .git</span><br><span class="line">├── .gitignore</span><br><span class="line">├── .python-version</span><br><span class="line">├── README.md</span><br><span class="line">├── pyproject.toml</span><br><span class="line">└── src</span><br><span class="line">    └── test_rye</span><br><span class="line">        └── __init__.py</span><br></pre></td></tr></table></figure><p>可以看到创建了.git 目录， .gitignore 文件，README.md，配置文件<code>pyproject.toml</code> 和一个示例的源码文件<code>src/test_rye/__init__.py</code>。</p><h3 id="2-4-Python-版本管理"><a href="#2-4-Python-版本管理" class="headerlink" title="2.4 Python 版本管理"></a>2.4 Python 版本管理</h3><p>为了固定开发环境，我们可以利用<code>rye pin python-version</code> 来固定Python的版本，例如<code>rye pin cpython@3.10.11</code> 会将Python版本固定为3.10.11。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cpython@可以省略</span></span><br><span class="line">rye pin cpython@3.10.11</span><br><span class="line">rye pin 3.10.11</span><br></pre></td></tr></table></figure><p>由于默认使用的Python版本是Cpython的，因此在执行rye命令时可以将<code>Cpython@</code> 前缀省去。</p><p>注意 <code>rye pin</code>命令并不立即改变Python的版本，只是修改配置文件<code>.python-version</code>，在<code>rye sync</code> 执行时才进行实际的修改。</p><p>可以多次执行<code>rye pin</code> 来调整Python的版本。</p><p>然后执行<code>rye sync</code> 来同步配置，具体来说，第一次执行这个命令的时候，Rye会下载一个单独的Python解释器，放置到<code>$HOME/.rye/py</code>目录下，链接到项目的<code>.venv</code> 目录下，因此同一个Python版本在磁盘上只有一份，这与conda是不同的。</p><p>更一般地，可以使用<code>rye toolchain</code> 来查看、拉取和删除Python版本。</p><p><code>rye toolchain list</code> 用来显示所有已经安装的Python版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rye toolcahin list</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cpython@3.11.3 (/Users/yunfeng/.rye/py/cpython@3.11.3/install/bin/python3)</span><br><span class="line">cpython@3.11.1 (/Users/yunfeng/.rye/py/cpython@3.11.1/install/bin/python3)</span><br><span class="line">cpython@3.10.11 (/Users/yunfeng/.rye/py/cpython@3.10.11/install/bin/python3)</span><br><span class="line">cpython@3.10.9 (/Users/yunfeng/.rye/py/cpython@3.10.9/install/bin/python3)</span><br></pre></td></tr></table></figure><p><code>rye toolchain list --include-downloadable</code> 会列出所有可以下载的Python版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`rye toolchain list --include-downloadable` </span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cpython@3.10.8 (downloadable)</span><br><span class="line">cpython@3.10.7 (downloadable)</span><br><span class="line">cpython@3.10.6 (downloadable)</span><br><span class="line">cpython@3.10.5 (downloadable)</span><br><span class="line">cpython@3.10.4 (downloadable)</span><br><span class="line">cpython@3.10.3 (downloadable)</span><br><span class="line">cpython@3.10.2 (downloadable)</span><br><span class="line">cpython@3.10.0 (downloadable)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>注意已经下载的Python版本不在这个输出中。</p><p><code>rye toolchain fetch</code>（简写为<code>rye fetch</code>) 可以直接拉取某个Python版本:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rye toolchain fetch 3.8.16</span><br></pre></td></tr></table></figure><p><code>rye toolchain remove</code> 可以删除某个Python版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rye toolchain remove 3.8.16</span><br></pre></td></tr></table></figure><h3 id="2-5-添加依赖包"><a href="#2-5-添加依赖包" class="headerlink" title="2.5 添加依赖包"></a>2.5 添加依赖包</h3><p>可以通过<code>rye add package-name</code> 来安装像numpy等第三方，这个命令支持安装GitHub和本地的包，一些示例的用法如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">rye add numpy</span><br><span class="line"><span class="comment"># 同时安装几个包</span></span><br><span class="line">rye add six easydict</span><br><span class="line"><span class="comment"># 设置安装包的版本</span></span><br><span class="line">rye add <span class="string">&quot;Flask&gt;=2.0&quot;</span></span><br><span class="line"><span class="comment"># 只在development环境添加包</span></span><br><span class="line">rye add --dev black</span><br><span class="line"><span class="comment"># 添加github上的包</span></span><br><span class="line">rye add Flask --git=https://github.com/pallets/flask</span><br><span class="line"><span class="comment"># 添加本地目录的包</span></span><br><span class="line">rye add My-Utility --path ./my-utility</span><br></pre></td></tr></table></figure><p>同样的，<code>rye add</code>并不会实际安装包，只会修改配置文件<code>pyproject.toml</code> 中的<code>dependencies</code> 项，等执行<code>rye sync</code>的时候才真正安装。</p><h3 id="2-6-Rye工作流"><a href="#2-6-Rye工作流" class="headerlink" title="2.6 Rye工作流"></a>2.6 Rye工作流</h3><p>我自己探索的Rye工作流大概是这样：</p><ol><li><code>rye init project-name</code> 来初始化项目目录</li><li><code>git add</code> 和<code>git commit</code> 来提交初始状态的代码，方便定位后续代码和配置文件的更新</li><li><code>rye pin</code> 指定Python版本</li><li>修改代码，<code>rye add package-name</code> 来增加代码依赖的包</li><li><code>rye sync</code>来安装Python，安装依赖包，更新配置文件</li><li><code>rye run python</code> 执行代码测试</li><li>可选：<code>rye build</code> 来生成可发布的wheel文件</li><li>可选：<code>rye publish</code> 上传包到pypi</li></ol><p>需要注意的是，Rye只负责依赖管理，具体的调试代码工作，还需要自己来进行，使用你熟悉的代码测试方式就可以了。</p><p>额外补充一下，可以使用<code>rye shell</code> 来打开一个新的启用了Rye Python的Shell来进行代码调试。</p><h3 id="2-7-安装可执行的-global-Python工具"><a href="#2-7-安装可执行的-global-Python工具" class="headerlink" title="2.7 安装可执行的 global Python工具"></a>2.7 安装可执行的 global Python工具</h3><p>某些python包除了包含Python源码外，还包含一些命令行工具，Rye称这些工具为<code>global tool</code> ，因为它们不是在某个环境中才能使用，而是全局可使用的。这些工具可以用<code>rye install package-name</code>来安装，例如:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rye install black</span><br></pre></td></tr></table></figure><p>使用方式为<code>rye run tool-name</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rye run black -h</span><br></pre></td></tr></table></figure><p>这些包都存放在<code>$HOME/.rye/shims</code> 目录下。<br>如果要删除 global tool，可以使用<code>rye uninstall</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rye uninstall black</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://mitsuhiko.github.io/rye/&quot;&gt;Rye&lt;/a&gt; 是&lt;a href=&quot;https://flask.palletsprojects.com/en/2.3.x/&quot;&gt;Flask&lt;/a&gt;的作者&lt;a href=&quot;https://github.com/mitsuhiko&quot;&gt;Armin Ronacher&lt;/a&gt;最近推出的一个实验性质的Python包管理系统，目的是解决Python包管理目前面临的工具链碎片化的问题。&lt;/p&gt;
&lt;p&gt;大家知道，Python目前的包管理系统很多，包括 poetry, pip, pipenv, pyenv, venv, virtualenv, pdm, hatch 等等，它们都是优秀的工具，提出时都是解决了一定的问题，但没有哪个工具能够做到主流，因此也增加了系统的碎片化程度。&lt;/p&gt;
&lt;p&gt;另一方面，conda等工具能提供不同版本的 Python，管理不同的环境，但每个环境的 Python 不是共享的，环境创建一多，环境目录就变得很大，且内部机制很不透明，有时也会遇到冲突没法解决的问题。&lt;/p&gt;
&lt;p&gt;另一方面，Python 在Linux/macOS上的安装也面临一些问题，例如用包管理器安装的  Python和用户手动安装的 Python 有的时候会混淆，导致一些混乱，例如在 Fedora 上，用&lt;code&gt;pip install&lt;/code&gt; 安装包可能会导致系统的包管理命令&lt;code&gt;dnf&lt;/code&gt; 出错。&lt;a href=&quot;https://peps.python.org/pep-0668&quot;&gt;PEP 668&lt;/a&gt;尝试对这些问题给出一个解决方案，但也需要不同的系统来支持，目前看还任重道远。&lt;/p&gt;
&lt;p&gt;由于Armin也是一个Rust 开发者，而Rust基于标准化的&lt;code&gt;rustup&lt;/code&gt;和&lt;code&gt;cargo&lt;/code&gt;两个工具，配合配置文件来进行包管理，目前做的比较好，没有Python面临的碎片化问题。受Rust的启发，作者提出了Rye，并且期望能够启发Python社区提出类似Rust的标准包管理工具。&lt;/p&gt;
&lt;p&gt;具体来说，Rye 提出了一些解决这些问题的思路：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出一个workspace的概念，workspace类似一个项目目录，或者一个git仓库，一个workspace下只有一个Python版本，不同workspace Python版本相互隔离，每个项目采用&lt;code&gt;pyproject.toml&lt;/code&gt;来进行配置&lt;/li&gt;
&lt;li&gt;不使用系统自带的Python，相反地，在每个项目目录的中下载一个standalone的python，解决不同版本的冲突问题&lt;/li&gt;
&lt;li&gt;不暴露pip命令，通过&lt;code&gt;rye add&lt;/code&gt; + &lt;code&gt;rye sync&lt;/code&gt; 来管理包的依赖，避免包A和包B依赖不同版本的包C而导致的不兼容问题&lt;/li&gt;
&lt;li&gt;区分开发环境和正式环境，因为一些包在开发时会用到一些调试工具，但作为第三方库被引入的时候并不需要&lt;/li&gt;
&lt;li&gt;支持import本地workspace作为第三方库包&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但同时也有一个问题：rye会不会是另一个做不到主流的Python包管理系统，从而进一步增加Python包管理的碎片化呢？作者也有这个考虑，因此写了一个讨论帖 &lt;a href=&quot;https://github.com/mitsuhiko/rye/discussions/6&quot;&gt;Should Rye Exist?&lt;/a&gt;来讨论这个问题，同时关于Rye的设计初衷，可以参考&lt;a href=&quot;https://mitsuhiko.github.io/rye/philosophy/&quot;&gt;这里&lt;/a&gt;作者的思考。&lt;/p&gt;
&lt;p&gt;个人观点：Rye的出现给Python社区引入了一些新鲜的解决现有问题的思路。使用Rye一段时间后，发现至少使用standalone 的Python版本是一个解决冲突的好的方式。通过几个简单的命令来解决版本管理的问题是比较直观的，提出Rye应该是利大于弊的，也就是有益程度大于碎片化增加的程度。&lt;/p&gt;
&lt;p&gt;总之不管是&lt;a href=&quot;https://peps.python.org/pep-0668&quot;&gt;PEP 668&lt;/a&gt;中标记版本管理是系统的还是Python的，还是&lt;a href=&quot;https://peps.python.org/pep-0711/&quot;&gt;PEP 711&lt;/a&gt;来单独下发Python解释器二进制文件，还是Rye的出现，都是Python社区意识到Python包管理问题的严重性，进而做出的一些有益尝试。期待在未来，有更标准化的工具，Python的开发也更容易。&lt;/p&gt;
&lt;p&gt;下面将对Rye的安装和使用进行简单介绍。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
    <category term="Rust" scheme="http://vra.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>git 回滚代码并保留提交历史</title>
    <link href="http://vra.github.io/2023/05/16/git-roll-back-code-and-save-commit-history/"/>
    <id>http://vra.github.io/2023/05/16/git-roll-back-code-and-save-commit-history/</id>
    <published>2023-05-16T07:55:28.000Z</published>
    <updated>2023-05-16T07:56:23.905Z</updated>
    
    <content type="html"><![CDATA[<p>在使用git时，有时候需要回退最新代码到之前的某次提交或某个tag，将中间的所有代码提交去掉。同时保持中间的提交记录。实际应用时发现这个动作没有比较好的实现方式。</p><p>例如，如果使用<code>git revert commit-id</code>, 那么只会会退<code>commit-id</code> 对应的那次提交，之后的提交不受影响，仍然存在，不是我们想要的效果。</p><p>如果使用<code>git reset</code>, 那操作就比较麻烦，需要使用<code>--hard</code> 和<code>--force</code> 等比较危险的命令，具体如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard commit-id</span><br><span class="line">git push --force</span><br></pre></td></tr></table></figure><p>这样做除了使用比较危险的命令选项外，还有个问题是没法保留中间的提交历史，这不是我们想要的。</p><p>搜索发现，利用git diff和git apply可以来比较清晰的完成这个需求，整体的思路是：</p><ol><li>得到当前最新提交到回退提交之间的代码diff，将diff保存为文件</li><li>利用<code>git apply</code> 将diff作用到代码上，回到之前的代码状态</li><li>提交代码</li></ol><p>具体来说，假设当前最新提交就在分支<code>current-branch</code>上，回退提交为<code>prev-commit</code>,这个回退提交可以是一次commit id，也可以是一个tag，也可以是一个分支名。执行命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git checkout prev-commit</span><br><span class="line">git diff current-branch &gt; ~/diff.patch</span><br><span class="line">git checkout current-branch</span><br><span class="line">cat ~/diff.patch | git apply</span><br><span class="line">git commit -am <span class="string">&quot;roll back to prev-commit&quot;</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><p>这样就能既回退代码，又保留提交历史。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="https://stackoverflow.com/a/33890073">https://stackoverflow.com/a/33890073</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在使用git时，有时候需要回退最新代码到之前的某次提交或某个tag，将中间的所有代码提交去掉。同时保持中间的提交记录。实际应用时发现这个动作没有比较好的实现方式。&lt;/p&gt;
&lt;p&gt;例如，如果使用&lt;code&gt;git revert commit-id&lt;/code&gt;, 那么只会会退</summary>
      
    
    
    
    
    <category term="Git" scheme="http://vra.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>talkGPT4All</title>
    <link href="http://vra.github.io/2023/04/02/chatbot4all/"/>
    <id>http://vra.github.io/2023/04/02/chatbot4all/</id>
    <published>2023-04-01T22:11:54.000Z</published>
    <updated>2023-04-02T00:45:18.594Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>TL;DR: talkGPT4All 是一个在PC本地运行的基于talkGPT和GPT4All的语音聊天程序，通过OpenAI Whisper将输入语音转文本，再将输入文本传给GPT4All获取回答文本，最后利用发音程序将文本读出来，构建了完整的语音交互聊天过程。</p><p>实际使用效果<a href="https://www.zhihu.com/zvideo/1625779747656515584">视频</a>。</p><p>实际上，它只是几个工具的简易组合，没有什么创新的地方（甚至不支持多轮聊天，只支持英文），但 talkGPT4All 有下面几个比较好的特点</p><ul><li>所有算法本地运行，不涉及API的调用，避免了国内无法访问OpenAI API的问题</li><li>CPU 运行，无须 GPU 显卡</li><li>占内存小，实测8G内存就可以跑起来</li><li>速度还可以，测试8G Windows 一轮聊天小于1分钟， 16G Mac 一轮聊天小于30秒</li><li>集成的AI还算智能，至少答能对题，回答看起来是符合英语语法的</li></ul><p>目前支持平台和验证的情况如下:</p><ul><li>Mac M1，已经验证可用</li><li>Windows，已经验证可用</li><li>Mac intel，未验证</li><li>Linux，未验证<br>如果有对应机器的朋友感兴趣的话，可以帮忙验证一下，有问题可以提PR和issue。</li></ul><p>想体验的朋友可以参考 GitHub README进行快速安装，也可以在这篇文章中跟着我一步步来进行。</p><span id="more"></span><h2 id="2-为什么造这个轮子"><a href="#2-为什么造这个轮子" class="headerlink" title="2. 为什么造这个轮子"></a>2. 为什么造这个轮子</h2><p>聊天机器人是我比较喜欢的一个应用，机器+人类的思维是一个很有意思的场景。另一方面，通过一个智能机器人来练习英语口语，也是一个很实际的应用。</p><p>一直以来，想要做一个含有智能的聊天机器人应用都是难度很大的，尤其是智能化的程度，受学术研究进展的制约，没法做到很高。然而近期的AI LLM大爆发，让开发一个真正智能的AI聊天机器人越来越容易。</p><p>最早看到的是基于<a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a>的<a href="https://github.com/ggerganov/whisper.cpp/tree/master/examples/talk.wasm">talk.wasm</a>, 一个基于Whisper+GPT-2的浏览器对话机器人，实际测试后发现GPT-2还不够智能，回答很多时候都答非所问。</p><p>然后是在ChatGPT出来后，我在想能不能做一个Whisper + ChatGPT的智能聊天机器人呢，搜索后发现whisper.cpp的讨论区已经有人在<a href="https://github.com/ggerganov/whisper.cpp/discussions/167#discussioncomment-4334628">讨论</a>这个事情，不过没看到成品。</p><p>在ChatGPT 开放API后，有人做了一个MacOS上的基于OpenAI API的语音聊天机器人<a href="https://github.com/chenyukang/talkGPT">talkGPT</a>，简单好用，唯一的问题是需要借助OpenAI API，目前国内是不太好访问的。</p><p>再然后是<a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>，通过量化和大量工程优化，让原本参数量很大的<a href="https://github.com/facebookresearch/llama">LLaMA</a>模型可以跑在普通的笔记本上（现在甚至支持在Android上运行！)，但实际测试经过量化后 LLaMA 7B 模型智能程度不太高，有时候会出错，而 更大的LLaMA 15B 和 30B 在8GB内存的Windows 机器上跑起来就比较难了（最新进展：大小20GB的30B模型可以在8G的系统上运行了，参见这个<a href="https://github.com/ggerganov/llama.cpp/pull/613">优化</a>和这里的<a href="https://github.com/ggerganov/llama.cpp/discussions/638">讨论</a>)。</p><p>这周又出现了<a href="https://github.com/nomic-ai/gpt4all">gpt4all</a>，基于 LLaMA 7B模型，采集近80万的GPT-3.5-Turbo对话数据进行finetune，效果看起来比 LLaMA 7B 要好。作者发布了他们训练好的经过量化的模型，大小3.9G，以及可以直接在PC上运行的二进制聊天程序，可以直接在各个平台运行。</p><p>然后长久以来的TODO 可以实现了，在缝合了talkGPT和GPT4All后，就有了talkGPT4All。简单来说，是把talkGPT的OpenAI API 换成了 GPT4All提供的本地可以运行的量化模型，也可以说是在GPT4All的基础上添加了语音转文本和文本转语音的功能。</p><p>那下面我们来看看怎么安装和运行这个缝合怪吧。</p><h2 id="3-构建环境"><a href="#3-构建环境" class="headerlink" title="3. 构建环境"></a>3. 构建环境</h2><p>由于整个程序设计到 Python 代码环境的搭建、Whisper 语音转文本模型的下载、GPT4All 语言模型的下载、GPT4All 聊天程序的下载、文本转语音程序的下载，整体链路略长，下面分步骤分平台分别进行详细说明。</p><h3 id="3-1-Python环境的搭建"><a href="#3-1-Python环境的搭建" class="headerlink" title="3.1 Python环境的搭建"></a>3.1 Python环境的搭建</h3><p>在不同平台 Python 代码环境的搭建是一致的。</p><p>推荐使用&gt;= 3.8的Python版本，因为新版本的Python有一定的速度提升。低版本可能一些功能不支持。<br>首先clone代码:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/vra/talkGPT4All.git</span><br></pre></td></tr></table></figure><p>后面假设代码仓库的根目录为<code>&lt;ROOT&gt;</code>来进行命令说明。</p><p>基于 Python自带的 venv 来搭建隔离的环境，并进行依赖安装:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;ROOT&gt;</span><br><span class="line">python -m venv talkgpt4all</span><br><span class="line"><span class="built_in">source</span> talkgpt4all/bin/activate</span><br><span class="line">pip install -U pip</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h3 id="3-2-Whisper-语音转文本模型下载"><a href="#3-2-Whisper-语音转文本模型下载" class="headerlink" title="3.2 Whisper 语音转文本模型下载"></a>3.2 Whisper 语音转文本模型下载</h3><p>Whisper 模型在调用时会自动下载，但有时候在命令行下载速度比较慢，我们可以在浏览器中提前下载后放置到对应目录，解决这个问题。<br>Whisper 的所有模型地址参见<a href="https://github.com/openai/whisper/blob/b80bcf610d89960bc658b61af9c333fc6d978d78/whisper/__init__.py#L18-L29">这里</a>，我们用的是<code>base.pt</code>，地址是<a href="https://openaipublic.azureedge.net/main/whisper/models/ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e/base.pt">https://openaipublic.azureedge.net/main/whisper/models/ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e/base.pt</a>，放置的目录是<code>$HOME/.cache/whisper</code>（Windows上是<code>C:\Users\username\.cache\whisper</code>),通过浏览器或 wget 下载<code>base.pt</code>到这个目录就行。</p><h3 id="3-3-GPT4All-语言模型的下载"><a href="#3-3-GPT4All-语言模型的下载" class="headerlink" title="3.3 GPT4All 语言模型的下载"></a>3.3 GPT4All 语言模型的下载</h3><p>语言模型放置目录是<code>&lt;ROOT&gt;/models</code>，根据 GPT4All <a href="https://github.com/nomic-ai/gpt4all#try-it-yourself">文档</a>，下载方式包括</p><ul><li><a href="https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-quantized.bin">链接</a>直接下载</li><li><a href="https://tinyurl.com/gpt4all-lora-quantized">torrent</a>下载</li></ul><p>选择其中一种方式，将下载后的模型放置到<code>&lt;ROOT&gt;/models</code>目录下。</p><h3 id="3-3-GPT4All-聊天程序下载"><a href="#3-3-GPT4All-聊天程序下载" class="headerlink" title="3.3 GPT4All 聊天程序下载"></a>3.3 GPT4All 聊天程序下载</h3><p>GPT4All 的作者打包了多平台的二进制聊天程序，可以下载后直接使用，不用从源码编译 C++ 文件。</p><p>聊天程序的放置目录是<code>&lt;ROOT&gt;/bin</code>，不同平台的下载地址如下：</p><ul><li>Mac M1: <a href="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/chat/gpt4all-lora-quantized-OSX-m1">https://raw.githubusercontent.com/nomic-ai/gpt4all/main/chat/gpt4all-lora-quantized-OSX-m1</a></li><li>Mac Intel : <a href="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/chat/gpt4all-lora-quantized-OSX-Intel">https://raw.githubusercontent.com/nomic-ai/gpt4all/main/chat/gpt4all-lora-quantized-OSX-Intel</a></li><li>Linux : <a href="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/chat/gpt4all-lora-quantized-linux-x86">https://raw.githubusercontent.com/nomic-ai/gpt4all/main/chat/gpt4all-lora-quantized-linux-x86</a></li><li>Windows : <a href="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/chat/gpt4all-lora-quantized-win64.exe">https://raw.githubusercontent.com/nomic-ai/gpt4all/main/chat/gpt4all-lora-quantized-win64.exe</a></li></ul><p>下载你的平台的文件，放置到<code>&lt;ROOT&gt;/bin</code>。</p><h3 id="3-4-文本转语音程序下载"><a href="#3-4-文本转语音程序下载" class="headerlink" title="3.4 文本转语音程序下载"></a>3.4 文本转语音程序下载</h3><p>在 Mac 下，自带<a href="https://ss64.com/osx/say.html">say命令</a>，可以将文本转语音，因此不需要额外安装工具。</p><p>在 Linux 下，有<a href="https://espeak.sourceforge.net/">espeak</a>命令可以来完成文本转语音，但需要额外安装，Ubuntu下的安装命令为<code>sudo apt install espeak</code>，别的发行版也可以用包管理安装。如果不行的话，尝试<a href="https://espeak.sourceforge.net/download.html">下载源码</a>自行编译安装。</p><p>Windows 下有一个 say 命令的替代 <a href="https://github.com/p-groarke/wsay">wsay</a>, 可以在<a href="https://github.com/p-groarke/wsay/releases/tag/v1.5.0">这里</a>下载 wsay.exe，放置到<code>&lt;ROOT&gt;/bin</code>目录下。</p><h3 id="4-使用"><a href="#4-使用" class="headerlink" title="4. 使用"></a>4. 使用</h3><p>安装完成后，进入<code>&lt;ROOT&gt;</code>目录，启用虚拟环境，使用<code>python chat.py --platform &lt;platform&gt;</code>运行程序，<code>&lt;platform&gt;</code>分别是<code>mac-m1</code>, <code>mac-intel</code>, <code>linux</code>, <code>windows</code>。</p><p>Mac M1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python chat.py --platform mac-m1</span><br></pre></td></tr></table></figure><p>Mac Intel:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python chat.py --platform mac-intel</span><br></pre></td></tr></table></figure><p>Linux:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python chat.py --platform linux</span><br></pre></td></tr></table></figure><p>Windows:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python chat.py --platform windows</span><br></pre></td></tr></table></figure><p>⚠️注意：目前只测试过 Mac M1 和 Windows，别的平台未测试，如有问题，欢迎提 <a href="https://github.com/vra/talkGPT4All/issues">issue</a> 和 <a href="https://github.com/vra/talkGPT4All/pulls">PR</a> 。</p><p>在 Mac 上使用效果如下:<br><img data-src="/imgs/talkgpt4all-mac-m1.jpg"></p><p>也可以参见本文开头的视频或<a href="https://www.zhihu.com/zvideo/1625779747656515584">这里</a>。</p><h3 id="5-后续改进思路"><a href="#5-后续改进思路" class="headerlink" title="5. 后续改进思路"></a>5. 后续改进思路</h3><p>目前实现还是比较粗糙，计划后续会增加下面的功能（按实现难度从低到高排列）：</p><ul><li>验证 Linux，Mac Intel 和 WSL2 下能否正常运行</li><li>增加多轮对话支持</li><li>增加中文支持</li><li>去掉编译好的二进制程序，包含 llama.cpp 源码，自行编译，支持更灵活的使用</li><li>更多效果更好模型的添加</li></ul><p>欢迎基于这个仓库进行修改和代码分发，期待创造出更有新意、更有应用价值的东西～</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h2&gt;&lt;p&gt;TL;DR: talkGPT4All 是一个在PC本地运行的基于talkGPT和GPT4All的语音聊天程序，通过OpenAI Whisper将输入语音转文本，再将输入文本传给GPT4All获取回答文本，最后利用发音程序将文本读出来，构建了完整的语音交互聊天过程。&lt;/p&gt;
&lt;p&gt;实际使用效果&lt;a href=&quot;https://www.zhihu.com/zvideo/1625779747656515584&quot;&gt;视频&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;实际上，它只是几个工具的简易组合，没有什么创新的地方（甚至不支持多轮聊天，只支持英文），但 talkGPT4All 有下面几个比较好的特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所有算法本地运行，不涉及API的调用，避免了国内无法访问OpenAI API的问题&lt;/li&gt;
&lt;li&gt;CPU 运行，无须 GPU 显卡&lt;/li&gt;
&lt;li&gt;占内存小，实测8G内存就可以跑起来&lt;/li&gt;
&lt;li&gt;速度还可以，测试8G Windows 一轮聊天小于1分钟， 16G Mac 一轮聊天小于30秒&lt;/li&gt;
&lt;li&gt;集成的AI还算智能，至少答能对题，回答看起来是符合英语语法的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前支持平台和验证的情况如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mac M1，已经验证可用&lt;/li&gt;
&lt;li&gt;Windows，已经验证可用&lt;/li&gt;
&lt;li&gt;Mac intel，未验证&lt;/li&gt;
&lt;li&gt;Linux，未验证&lt;br&gt;如果有对应机器的朋友感兴趣的话，可以帮忙验证一下，有问题可以提PR和issue。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;想体验的朋友可以参考 GitHub README进行快速安装，也可以在这篇文章中跟着我一步步来进行。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="http://vra.github.io/tags/Linux/"/>
    
    <category term="AI" scheme="http://vra.github.io/tags/AI/"/>
    
    <category term="ChatBot" scheme="http://vra.github.io/tags/ChatBot/"/>
    
    <category term="GPT" scheme="http://vra.github.io/tags/GPT/"/>
    
    <category term="Whisper" scheme="http://vra.github.io/tags/Whisper/"/>
    
    <category term="Mac" scheme="http://vra.github.io/tags/Mac/"/>
    
    <category term="Windows" scheme="http://vra.github.io/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>neovim telescope 插件简要教程</title>
    <link href="http://vra.github.io/2023/03/28/neovim-telescope/"/>
    <id>http://vra.github.io/2023/03/28/neovim-telescope/</id>
    <published>2023-03-28T15:44:37.000Z</published>
    <updated>2023-03-28T16:23:19.254Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p><a href="https://github.com/nvim-telescope/telescope.nvim/">telescope</a> 是一款强大的 neovim 插件，可以在 neovim 中提供文件名搜索和文本内容搜索的功能，以及更多复杂的功能，具体的show case可以看<a href="https://github.com/nvim-telescope/telescope.nvim/wiki/Showcase">这里</a>。我安装 telescope 主要是想利用它在大型项目中的文件名搜索和文本内容搜索能力，这里记录一下安装流程和使用概要。</p><span id="more"></span><h2 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h2><p>首先需要安装 neovim。具体步骤可以看<a href="https://github.com/neovim/neovim/wiki/Installing-Neovim">这里</a>。</p><p>注意 telescope 需要nvim 0.7.0及以后的版本，因此如果你neovim 版本本身比较低的话，需要升级。</p><p>安装 neovim 后还需要进行配置。我的 neovim 配置是复制的这个<a href="https://github.com/bigeagle/neovim-config">仓库</a>，按照README来进行操作，可以快速地安装好，这里不赘述。</p><p>telescope 支持多种插件系统，我使用的 vim-plug，在<code>~/.config/nvim/init.vim</code> 添加下面两行：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Plug <span class="string">&#x27;nvim-lua/plenary.nvim&#x27;</span></span><br><span class="line">Plug <span class="string">&#x27;nvim-telescope/telescope.nvim&#x27;</span>, &#123; <span class="string">&#x27;tag&#x27;</span>: <span class="string">&#x27;0.1.1&#x27;</span> &#125;</span><br></pre></td></tr></table></figure><p>然后在nvim中输入<code>:PlugInstall</code> 来安装插件。</p><p>由于插件是在GitHub上下载的，有时候可能安装会卡住，需要多尝试几次，即多次执行<code>:PlugInstall</code>命令。</p><p>安装完成后，执行<code>:Telescope find_files</code>来验证安装是否正确。如果能弹出输入框，说明安装成功了。</p><p>这个命令用来模糊匹配当前目录下的所有文件名，对于快速切换编辑文件非常方便。</p><h2 id="3-live-grep-功能"><a href="#3-live-grep-功能" class="headerlink" title="3. live_grep 功能"></a>3. <code>live_grep</code> 功能</h2><p>除了<code>find_files</code>命令，<code>live_grep</code>也是一个很有用的命令，可以快速搜索某些代码，把含搜索代码的文件打开。</p><p>这个功能需要依赖<a href="https://github.com/BurntSushi/ripgrep">ripgrep</a>，因此要先安装它，具体安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mac</span></span><br><span class="line">brew install ripgrep</span><br><span class="line"></span><br><span class="line"><span class="comment"># debian/ubuntu</span></span><br><span class="line">sudo apt-get install ripgrep</span><br><span class="line"></span><br><span class="line"><span class="comment"># arch</span></span><br><span class="line">pacman -S ripgrep</span><br><span class="line"></span><br><span class="line"><span class="comment"># centos</span></span><br><span class="line">sudo yum-config-manager --add-repo=https://copr.fedorainfracloud.org/coprs/carlwgeorge/ripgrep/repo/epel-7/carlwgeorge-ripgrep-epel-7.repo</span><br><span class="line">sudo yum install ripgrep</span><br><span class="line"></span><br><span class="line"><span class="comment"># windows </span></span><br><span class="line">scoop install ripgrep</span><br></pre></td></tr></table></figure><p>安装完后在命令行输入<code>ag -h</code> 验证安装是否成功。</p><p>ag 安装完成后，在nvim输入<code>:Telescope live_grep</code> 就可以搜索你想要的代码了。</p><h2 id="4-快捷键"><a href="#4-快捷键" class="headerlink" title="4. 快捷键"></a>4. 快捷键</h2><p>上面的两个常用功能输入都比较繁琐，有没有什么快捷键可以快速打开呢？是有的，官方GitHub给出了几行代码，加入到<code>~/.config/nvim/init.vim</code>的最后：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&quot; Find files using Telescope command-line sugar.</span></span><br><span class="line"><span class="keyword">nnoremap</span> <span class="symbol">&lt;leader&gt;</span>ff <span class="symbol">&lt;cmd&gt;</span>Telescope find_files<span class="symbol">&lt;cr&gt;</span></span><br><span class="line"><span class="keyword">nnoremap</span> <span class="symbol">&lt;leader&gt;</span>fg <span class="symbol">&lt;cmd&gt;</span>Telescope live_grep<span class="symbol">&lt;cr&gt;</span></span><br><span class="line"><span class="keyword">nnoremap</span> <span class="symbol">&lt;leader&gt;</span>fb <span class="symbol">&lt;cmd&gt;</span>Telescope <span class="keyword">buffers</span><span class="symbol">&lt;cr&gt;</span></span><br><span class="line"><span class="keyword">nnoremap</span> <span class="symbol">&lt;leader&gt;</span>fh <span class="symbol">&lt;cmd&gt;</span>Telescope help_tags<span class="symbol">&lt;cr&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&quot; Using Lua functions</span></span><br><span class="line"><span class="keyword">nnoremap</span> <span class="symbol">&lt;leader&gt;</span>ff <span class="symbol">&lt;cmd&gt;</span><span class="keyword">lua</span> require(<span class="string">&#x27;telescope.builtin&#x27;</span>).find_files()<span class="symbol">&lt;cr&gt;</span></span><br><span class="line"><span class="keyword">nnoremap</span> <span class="symbol">&lt;leader&gt;</span>fg <span class="symbol">&lt;cmd&gt;</span><span class="keyword">lua</span> require(<span class="string">&#x27;telescope.builtin&#x27;</span>).live_grep()<span class="symbol">&lt;cr&gt;</span></span><br><span class="line"><span class="keyword">nnoremap</span> <span class="symbol">&lt;leader&gt;</span>fb <span class="symbol">&lt;cmd&gt;</span><span class="keyword">lua</span> require(<span class="string">&#x27;telescope.builtin&#x27;</span>).<span class="keyword">buffers</span>()<span class="symbol">&lt;cr&gt;</span></span><br><span class="line"><span class="keyword">nnoremap</span> <span class="symbol">&lt;leader&gt;</span>fh <span class="symbol">&lt;cmd&gt;</span><span class="keyword">lua</span> require(<span class="string">&#x27;telescope.builtin&#x27;</span>).help_tags()<span class="symbol">&lt;cr&gt;</span></span><br></pre></td></tr></table></figure><p>然后在Normal模式输入<code>\ff</code>就可以打开<code>find_files</code>命令窗口，输入<code>\fg</code>就可以打开<code>live_grep</code>窗口了。</p><p>更多详细命令和功能参见GitHub 页面。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/nvim-telescope/telescope.nvim/&quot;&gt;telescope&lt;/a&gt; 是一款强大的 neovim 插件，可以在 neovim 中提供文件名搜索和文本内容搜索的功能，以及更多复杂的功能，具体的show case可以看&lt;a href=&quot;https://github.com/nvim-telescope/telescope.nvim/wiki/Showcase&quot;&gt;这里&lt;/a&gt;。我安装 telescope 主要是想利用它在大型项目中的文件名搜索和文本内容搜索能力，这里记录一下安装流程和使用概要。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="http://vra.github.io/tags/Linux/"/>
    
    <category term="Vim" scheme="http://vra.github.io/tags/Vim/"/>
    
    <category term="NeoVim" scheme="http://vra.github.io/tags/NeoVim/"/>
    
  </entry>
  
  <entry>
    <title>libtorch系列教程2：torch::Tensor的使用</title>
    <link href="http://vra.github.io/2023/02/25/libtorch-tutorial2/"/>
    <id>http://vra.github.io/2023/02/25/libtorch-tutorial2/</id>
    <published>2023-02-25T09:15:46.000Z</published>
    <updated>2023-02-27T04:48:49.191Z</updated>
    
    <content type="html"><![CDATA[<p>系列教程列表：</p><ul><li><a href="https://vra.github.io/2023/02/25/libtorch-tutorial1/">Libtorch系列教程1：一个丝滑的C++ Tensor库</a> </li><li><a href="https://vra.github.io/2023/02/25/libtorch-tutorial2/">Libtorch系列教程2：torch::Tensor的使用</a> </li></ul><p>这篇文章中，我们暂时忽略网络训练和推理，详细展开Libtorch中Tensor对象的使用，看看将Libtorch当作一个纯粹的Tensor库来使用时，有哪些注意事项。如有未涉及的内容，请访问Libtorch<a href="https://pytorch.org/cppdocs/">官方文档</a>，通过搜索框获取更多的信息。Libtorch的环境搭建参考<a href="https://vra.github.io/2023/02/25/libtorch-tutorial1/">上一篇文章</a>。</p><span id="more"></span><h2 id="1-torch-Tensor基本操作"><a href="#1-torch-Tensor基本操作" class="headerlink" title="1. torch::Tensor基本操作"></a>1. torch::Tensor基本操作</h2><p>Libtorch中的Tensor是与Pytorch中的Tensor对应的，使用方式上很类似，只在一些Python语法C++不支持的时候有些不同，例如slice操作。<br>使用Libtorch前需要包含 Libtorch 的头文件<code>torch/torch.h</code>:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br></pre></td></tr></table></figure><p>这篇文章用到的所有函数都在此头文件中声明，而且所有的函数namespace都是<code>torch</code>，因此都可以以<code>torch::xxx</code>的形式来调用。</p><h3 id="1-1-Tensor创建"><a href="#1-1-Tensor创建" class="headerlink" title="1.1 Tensor创建"></a>1.1 Tensor创建</h3><p>Tensor 创建的方式比较多，包括从字面量创建，从C++ 原生的数组创建，从vector创建，从Libtorch自带的函数创建等。</p><p>从字面量创建:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch::Tensor foo = torch::<span class="built_in">tensor</span>(&#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>&#125;);</span><br></pre></td></tr></table></figure><p>从C++ 原生的float数组创建，使用<code>from_blob</code>函数:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> arr[] = &#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>&#125;;</span><br><span class="line"><span class="comment">// 第二个参数表示创建的Tensor shape，会自动对原生数组进行reshape</span></span><br><span class="line">torch::Tensor bar = torch::<span class="built_in">from_blob</span>(arr, &#123;<span class="number">1</span>, <span class="number">4</span>&#125;); <span class="comment">// shape是[1, 4]</span></span><br><span class="line">bar = torch::<span class="built_in">from_blob</span>(arr, &#123;<span class="number">2</span>, <span class="number">2</span>&#125;); <span class="comment">// shape是[2, 2]</span></span><br></pre></td></tr></table></figure><p>其中第二个参数表示创建的Tensor shape，会自动对原生数组进行reshape。</p><p>从vector 创建，使用<code>from_blob</code>函数:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">float</span>&gt; v = &#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>&#125;;</span><br><span class="line">bar = torch::<span class="built_in">from_blob</span>(v.<span class="built_in">data</span>(), &#123;<span class="number">2</span>, <span class="number">2</span>&#125;);</span><br></pre></td></tr></table></figure><p>还可以用Libtorch的函数创建，跟Numpy和Pytorch类似:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">foo = torch::<span class="built_in">arange</span>(<span class="number">4</span>);</span><br><span class="line">foo = torch::<span class="built_in">eye</span>(<span class="number">2</span>);</span><br><span class="line">foo = torch::<span class="built_in">ones</span>(<span class="number">2</span>);</span><br><span class="line">bar = torch::<span class="built_in">ones_like</span>(foo);</span><br><span class="line">foo = torch::<span class="built_in">rand</span>(<span class="number">4</span>);</span><br><span class="line">foo = torch::<span class="built_in">randn</span>(<span class="number">4</span>);</span><br><span class="line">foo = torch::<span class="built_in">zeros</span>(<span class="number">2</span>);</span><br><span class="line">bar = torch::<span class="built_in">zeros_like</span>(foo);</span><br></pre></td></tr></table></figure><p>创建好以后，Tensor对应可以直接用<code>std::cout</code>来输出:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch::Tensor foo = torch::<span class="built_in">tensor</span>(&#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>&#125;);</span><br><span class="line">std::cout &lt;&lt;<span class="string">&quot;==&gt; foo is:\n&quot;</span> &lt;&lt; foo &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">==&gt; foo is:</span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[ CPUFloatType&#123;4&#125; ]</span><br></pre></td></tr></table></figure><p>可以看到最后打印了Tensor的类型。</p><h3 id="1-2-Tensor对象的属性函数"><a href="#1-2-Tensor对象的属性函数" class="headerlink" title="1.2 Tensor对象的属性函数"></a>1.2 Tensor对象的属性函数</h3><p>创建Tensor后，我们还需要看到它的一些属性，判断是否跟预期相符。注意Libtorch的Tensor是没有公开可访问的属性attribute的，Tensor信息需要属性函数来获取。常见的属性函数包括:</p><ul><li>dim(): Tensor的维度</li><li>sizes(): 跟Pytorch中的shape属性一样</li><li>size(n): 第N个维度的shape</li><li>numel(): 总的元素数目，sizes中的每个元素相乘</li><li>dtype(): 数据类型</li><li>device(): Tensor所在的设备类型，CPU, CUDA, MPS等。</li></ul><p>使用方式如下:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Tensor 属性函数</span></span><br><span class="line">torch::Tensor foo = torch::<span class="built_in">randn</span>(&#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>&#125;);</span><br><span class="line"><span class="keyword">auto</span> dim = foo.<span class="built_in">dim</span>(); <span class="comment">// 4</span></span><br><span class="line"><span class="keyword">auto</span> sizes = foo.<span class="built_in">sizes</span>(); <span class="comment">// [1, 3, 224, 224]</span></span><br><span class="line"><span class="keyword">auto</span> size_0 = foo.<span class="built_in">size</span>(<span class="number">0</span>); <span class="comment">// 1</span></span><br><span class="line"><span class="keyword">auto</span> numel = foo.<span class="built_in">numel</span>(); <span class="comment">// 150528</span></span><br><span class="line"><span class="keyword">auto</span> dtype = foo.<span class="built_in">dtype</span>(); <span class="comment">// float</span></span><br><span class="line"><span class="keyword">auto</span> scalar_type = foo.<span class="built_in">scalar_type</span>(); <span class="comment">// Float</span></span><br><span class="line"><span class="keyword">auto</span> device = foo.<span class="built_in">device</span>(); <span class="comment">// cpu</span></span><br></pre></td></tr></table></figure><h3 id="1-3-Tensor对象的索引"><a href="#1-3-Tensor对象的索引" class="headerlink" title="1.3 Tensor对象的索引"></a>1.3 Tensor对象的索引</h3><p>Tensor 默认是支持<code>[]</code>操作符的，因此可以使用这样的方式来获取元素：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> foo = torch::<span class="built_in">randn</span>(&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;);</span><br><span class="line"><span class="keyword">float</span> value = foo[<span class="number">0</span>][<span class="number">1</span>][<span class="number">2</span>][<span class="number">2</span>];</span><br></pre></td></tr></table></figure><p>另一种方式是用Tensor对象的<code>index</code>函数，它的优势是支持slice。<br>对于单个元素，可以类似Pytorch中，直接用<code>index(&#123;i, j, k&#125;)</code>的方式来索引：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> foo = torch::<span class="built_in">randn</span>(&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;);</span><br><span class="line"><span class="keyword">float</span> value = foo.<span class="built_in">index</span>(&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>&#125;);</span><br></pre></td></tr></table></figure><p>那么python中很常用的slice呢？例如<code>foo[..., :2, 1:, :-1]</code>，该怎么在Libtorch中表示？<br>这里需要用到<code>torch::indexing::Slice</code> 对象，来实现Python中的Slice，看看下面的例子你就明白了：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> torch::indexing;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> foo = torch::<span class="built_in">randn</span>(&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;);</span><br><span class="line"><span class="comment">// 等效于Python中的foo[:, 0:1, 2:, :-1]</span></span><br><span class="line"><span class="keyword">auto</span> bar = foo.<span class="built_in">index</span>(&#123;<span class="built_in">Slice</span>(), <span class="built_in">Slice</span>(<span class="number">0</span>, <span class="number">1</span>), <span class="built_in">Slice</span>(<span class="number">2</span>, None), <span class="built_in">Slice</span>(None, <span class="number">-1</span>)&#125;);</span><br></pre></td></tr></table></figure><p>应该是能满足Python中slice同样的使用场景。</p><h3 id="1-4-更新Tensor中元素的值"><a href="#1-4-更新Tensor中元素的值" class="headerlink" title="1.4 更新Tensor中元素的值"></a>1.4 更新Tensor中元素的值</h3><p>有了索引之后，我们就可以更新Tensor的值了：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch::Tensor foo = torch::<span class="built_in">tensor</span>(&#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>&#125;);</span><br><span class="line">foo[<span class="number">0</span>] = <span class="number">10.0</span>;</span><br><span class="line">foo.<span class="built_in">index</span>(&#123;<span class="number">0</span>&#125;) = <span class="number">2.0</span>;</span><br></pre></td></tr></table></figure><p>但还没找到用给部分Tensor元素赋值的方法，类似Python中的<code>foo[:2] = bar</code>，欢迎补充。</p><h3 id="1-5-获取Tensor中的数据"><a href="#1-5-获取Tensor中的数据" class="headerlink" title="1.5 获取Tensor中的数据"></a>1.5 获取Tensor中的数据</h3><p>Tensor是一个Libtorch的对象，那怎么把它中的数据拿出来保存到文件中或传给别的函数呢？<br>使用<code>data_ptr</code>函数就可以:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch::Tensor foo = torch::<span class="built_in">randn</span>(&#123;<span class="number">3</span>, <span class="number">3</span>&#125;);</span><br><span class="line"><span class="keyword">float</span>* data = foo.data_ptr&lt;<span class="keyword">float</span>&gt;();</span><br></pre></td></tr></table></figure><p>对于单个元素的Tensor，还可以用<code>item</code>函数得到具体的数值:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch::Tensor one_element_tensor = foo.<span class="built_in">index</span>(&#123;<span class="built_in">Slice</span>(), <span class="built_in">Slice</span>(<span class="number">0</span>, <span class="number">1</span>), <span class="built_in">Slice</span>(<span class="number">0</span>, <span class="number">1</span>), <span class="built_in">Slice</span>(<span class="number">0</span>, <span class="number">1</span>)&#125;);</span><br><span class="line"><span class="keyword">float</span> value = one_element_tensor.item&lt;<span class="keyword">float</span>&gt;();</span><br></pre></td></tr></table></figure><h3 id="1-6-数据类型"><a href="#1-6-数据类型" class="headerlink" title="1.6 数据类型"></a>1.6 数据类型</h3><p>Libtorch中支持float16, float32, float64, int8, int16, int32, uint8这几类的Tensor数据类型，可以用<code>to</code>函数来进行类型转换：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 数据类型, 参见 https://pytorch.org/cppdocs/api/file_torch_csrc_api_include_torch_types.h.html#variables</span></span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kF16);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kF32);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kF64);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kFloat16);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kFloat32);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kFloat64);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kI8);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kI16);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kI32);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kI64);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kInt8);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kInt16);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kInt32);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kInt64);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kU8);</span><br><span class="line">bar = foo.<span class="built_in">to</span>(torch::kUInt8);</span><br></pre></td></tr></table></figure><p>全部数据类型，参见官方文档的<a href="https://pytorch.org/cppdocs/api/file_torch_csrc_api_include_torch_types.h.html#variables">数据类型页面</a>。</p><h3 id="1-7-设备类型"><a href="#1-7-设备类型" class="headerlink" title="1.7 设备类型"></a>1.7 设备类型</h3><p>设备类型是Tensor保存的设备的种类。由于Libtorch不仅仅支持CPU，还支持各种类型的GPU，因此有很多设备类型。</p><p>所有的设备类型参见<a href="https://pytorch.org/cppdocs/api/file_c10_core_DeviceType.h.html#variables">这里</a>。<br>需要注意的是，设备是跟编译时的配置，机器是否支持强相关的，而且某些设备支持并不好，例如我想用下面的代码将CPU上的Tensor转移到MPS上：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> foo = torch::<span class="built_in">randn</span>(&#123;<span class="number">3</span>, <span class="number">3</span>&#125;);</span><br><span class="line"><span class="keyword">auto</span> bar = foo.<span class="built_in">to</span>(torch::kMPS);</span><br></pre></td></tr></table></figure><p>编译是没有问题的，但运行时会报下面的错:</p><blockquote><p>libc++abi: terminating with uncaught exception of type c10::TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn’t support float64. Please use float32 instead.</p></blockquote><p>提示说MPS不支持float64，但我打印<code>foo</code>的类型，它其实是float32，本身报错比较奇怪，搜了一圈也没找到怎么解决。</p><h3 id="1-8-Tensor-变形函数"><a href="#1-8-Tensor-变形函数" class="headerlink" title="1.8 Tensor 变形函数"></a>1.8 Tensor 变形函数</h3><p>很多时候我们需要将Tensor进行形状的修改，这方面Libtorch支持的比较好，这些操作都支持:</p><ul><li>reshape</li><li>flatten</li><li>squeeze</li><li>unsqueeze</li><li>transpose</li><li>cat/concat/concatenate</li></ul><p>而且支持<code>torch::reshape</code>这种静态函数和<code>tensor.reshape</code>这种对象函数。下面是一些例子:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 变形操作</span></span><br><span class="line">bar = foo.<span class="built_in">reshape</span>(&#123;<span class="number">2</span>, <span class="number">-1</span>&#125;);</span><br><span class="line">bar = foo.<span class="built_in">flatten</span>();</span><br><span class="line">bar = foo.<span class="built_in">squeeze</span>();</span><br><span class="line">bar = foo.<span class="built_in">unsqueeze</span>(<span class="number">0</span>);</span><br><span class="line">bar = torch::<span class="built_in">unsqueeze</span>(foo, <span class="number">-1</span>);</span><br><span class="line">bar = foo.<span class="built_in">transpose</span>(<span class="number">0</span>, <span class="number">1</span>).<span class="built_in">transpose</span>(<span class="number">2</span>, <span class="number">3</span>).<span class="built_in">transpose</span>(<span class="number">3</span>, <span class="number">1</span>);</span><br><span class="line">bar = torch::<span class="built_in">transpose</span>(foo, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">bar = torch::<span class="built_in">cat</span>(&#123;foo, foo&#125;, <span class="number">2</span>);</span><br></pre></td></tr></table></figure><p>一个比较特殊的地方是transpose只支持两个轴的交换，多个轴的交换需要调用多次来实现。</p><h3 id="1-9-Tensor之间的操作函数"><a href="#1-9-Tensor之间的操作函数" class="headerlink" title="1.9 Tensor之间的操作函数"></a>1.9 Tensor之间的操作函数</h3><p>Tensor库中，Tensor和Tensor之间的操作是很常见的，比如求矩阵相乘，内积外积等，有内置的函数支持能避免很多额外的开发工作。这里是一些例子:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">foo = torch::<span class="built_in">randn</span>(&#123;<span class="number">3</span>, <span class="number">3</span>&#125;);</span><br><span class="line">bar = torch::<span class="built_in">matmul</span>(foo, foo);</span><br><span class="line">bar = foo.<span class="built_in">matmul</span>(foo);</span><br><span class="line">bar = torch::<span class="built_in">cross</span>(foo, foo);</span><br><span class="line">bar = torch::<span class="built_in">mul</span>(foo, foo);</span><br></pre></td></tr></table></figure><h3 id="1-10-线性代数相关函数"><a href="#1-10-线性代数相关函数" class="headerlink" title="1.10 线性代数相关函数"></a>1.10 线性代数相关函数</h3><p><code>torch::linalg</code> namespace中包含常见的线性代数操作，几个简单的使用例子:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bar = torch::linalg::<span class="built_in">inv</span>(foo);</span><br><span class="line">bar = torch::linalg::<span class="built_in">norm</span>(foo, <span class="number">2</span>, &#123;<span class="number">0</span>, <span class="number">1</span>&#125;, <span class="literal">false</span>, torch::nullopt);</span><br></pre></td></tr></table></figure><p>所有支持的函数详见<a href="https://pytorch.org/cppdocs/api/file_torch_csrc_api_include_torch_linalg.h.html#file-torch-csrc-api-include-torch-linalg-h">官方文档</a></p><h3 id="1-11-神经网络相关函数"><a href="#1-11-神经网络相关函数" class="headerlink" title="1.11 神经网络相关函数"></a>1.11 神经网络相关函数</h3><p>神经网络是torch的核心模块，常见的一些激活函数，卷积层都可以以函数的形式作用在Tensor上，这里写几个简单的例子：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bar = torch::<span class="built_in">softmax</span>(foo, <span class="number">-1</span>);</span><br><span class="line">bar = torch::<span class="built_in">sigmoid</span>(foo);</span><br><span class="line">bar = torch::<span class="built_in">relu</span>(foo);</span><br><span class="line">bar = torch::<span class="built_in">gelu</span>(foo);</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;系列教程列表：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://vra.github.io/2023/02/25/libtorch-tutorial1/&quot;&gt;Libtorch系列教程1：一个丝滑的C++ Tensor库&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://vra.github.io/2023/02/25/libtorch-tutorial2/&quot;&gt;Libtorch系列教程2：torch::Tensor的使用&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这篇文章中，我们暂时忽略网络训练和推理，详细展开Libtorch中Tensor对象的使用，看看将Libtorch当作一个纯粹的Tensor库来使用时，有哪些注意事项。如有未涉及的内容，请访问Libtorch&lt;a href=&quot;https://pytorch.org/cppdocs/&quot;&gt;官方文档&lt;/a&gt;，通过搜索框获取更多的信息。Libtorch的环境搭建参考&lt;a href=&quot;https://vra.github.io/2023/02/25/libtorch-tutorial1/&quot;&gt;上一篇文章&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
    <category term="C++" scheme="http://vra.github.io/tags/C/"/>
    
    <category term="Pytorch" scheme="http://vra.github.io/tags/Pytorch/"/>
    
    <category term="Libtorch" scheme="http://vra.github.io/tags/Libtorch/"/>
    
  </entry>
  
  <entry>
    <title>Libtorch系列教程1：一个丝滑的C++ Tensor库</title>
    <link href="http://vra.github.io/2023/02/25/libtorch-tutorial1/"/>
    <id>http://vra.github.io/2023/02/25/libtorch-tutorial1/</id>
    <published>2023-02-24T19:03:51.000Z</published>
    <updated>2023-02-27T00:32:59.543Z</updated>
    
    <content type="html"><![CDATA[<p>系列教程列表：</p><ul><li><a href="https://vra.github.io/2023/02/25/libtorch-tutorial1/">Libtorch系列教程1：一个丝滑的C++ Tensor库</a> </li><li><a href="https://vra.github.io/2023/02/25/libtorch-tutorial2/">Libtorch系列教程2：torch::Tensor的使用</a> </li></ul><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p><a href="https://pytorch.org/cppdocs/installing.html">Libtorch</a>是Pytorch的C++接口，实现了在C++中进行网络训练、网络推理的功能。</p><p>除此之外，由于Libtorch中的大部份接口都是与Pytorch一致的，所以Libtorch还是一个很强大的张量库，有着类似Pytorch的清晰接口，这在C++中很难得的。如果你用过C++ Tensor库，就会发现写法比较复杂，学习成本。因为强类型的限制和通用容器类型的缺失，C++相比Python天然更复杂，库设计者因为语言使用习惯，以及为了性能等因素，设计的接口一般都是高效但难用的。而Libtorch采用了与Pytorch类似的函数接口，如果你使用过Pytorch的话，使用Libtorch学习成本很低，后面会看到具体的例子。</p><p>另一个问题是，很多Python库中基础的操作，例如<code>numpy.einsum</code>函数，在C++中没有合适的替代，看看<a href="https://stackoverflow.com/questions/65347170/numpy-einsum-equivalent-for-xtensor-c">这些</a>搜索你就知道了。Libtorch解决了这个问题，Pytorch中有的它都有，所以在C++中可以简单地用<code>torch::einsum</code>来使用einsum函数，简直是C++开发者的福音。</p><p>此外Libtorch 是支持GPU的，主要用于模型的推理过程，但我猜测使用GPU的话，Libtorch的Tensor操作在速度上相比别的C++ Tensor 库可能有优势，具体速度需要测试对比。当然使用C++代码的话速度不是瓶颈，本身CPU代码就够快了。</p><p>Libtorch另一个优势是编译简单，只要你安装了Pytorch，Libtorch就可以直接使用，省去了复杂的安装和配置，一分钟内就能跑起来一个简单的的示例程序。</p><p>总结来说，Libtorch有以下很吸引人的特性：</p><ul><li>强大如Numpy和Pytorch的C++ Tensor库，写法优雅丝滑，并且是支持GPU的。</li><li>可以训练神经网络</li><li>可以推理神经网络模型，用在C++环境的模型部署场景</li><li>编译简单</li></ul><p>由于Pytorch开发团队是以Python优先的思路来进行Pytorch的开发的，因此我感觉Libtorch的重视程度不是很高，文档和教程也比较少，官网的示例也几乎没有，因此写一个比较完善的教程是比较有意义的。</p><p>这个系列文章中，我会对Libtorch 的Tensor库和推理神经网络过程进行介绍，因为这些内容在实际对于用Libtorch来进行网络训练的部分进行跳过，因为这部分使用的场景不是很多（用Python训练网络比C++香多了)。</p><p>本篇以Mac下的操作为例，对Libtorch的安装和简单使用进行介绍，后续内容近期会更新，敬请关注。</p><span id="more"></span><h2 id="2-Libtorch-安装"><a href="#2-Libtorch-安装" class="headerlink" title="2. Libtorch 安装"></a>2. Libtorch 安装</h2><p>如果你已经安装过Pytorch，那么就不用额外安装Libtorch了，因为Pytorch自带了Libtorch的CMake config 文件，使用<code>torch.utils.cmake_prefix_path</code>语句就能打印出来，可以直接被CMake使用，编译时添加如下的选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-DCMAKE_PREFIX_PATH=`python -c <span class="string">&#x27;import torch;print(torch.utils.cmake_prefix_path)&#x27;</span></span><br></pre></td></tr></table></figure><p>如果没有安装过Pytorch，那直接去<a href="https://pytorch.org/">Pytorch官网</a>下载Libtorch 压缩包，解压到本地目录即可，后面使用CMake来指向这里的路径就行。假如解压到<code>LIBTORCH_ROOT</code>目录，编译时添加下面的选项:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-DCMAKE_PREFIX_PATH=&lt;LIBTORCH_ROOT&gt;</span><br></pre></td></tr></table></figure><h2 id="3-使用CMake-编译一个简单例子"><a href="#3-使用CMake-编译一个简单例子" class="headerlink" title="3. 使用CMake 编译一个简单例子"></a>3. 使用CMake 编译一个简单例子</h2><p>这里写一个简单的Libtorch例子，创建一个5x5的矩阵，然后调用<code>einsum</code>函数来计算矩阵的迹（对角线元素的和）：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 引入Torch头文件，Tensor类在此头文件中，别的类会在另外的头文件中</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 使用arange构造一个一维向量，再用reshape变换到5x5的矩阵</span></span><br><span class="line">  torch::Tensor foo = torch::<span class="built_in">arange</span>(<span class="number">25</span>).<span class="built_in">reshape</span>(&#123;<span class="number">5</span>, <span class="number">5</span>&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 计算矩阵的迹</span></span><br><span class="line">  torch::Tensor bar  = torch::<span class="built_in">einsum</span>(<span class="string">&quot;ii&quot;</span>, foo);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 输出矩阵和对应的迹</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;==&gt; matrix is:\n &quot;</span> &lt;&lt; foo &lt;&lt; std::endl;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;==&gt; trace of it is:\n &quot;</span> &lt;&lt; bar &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意reshape中需要用花括号，因为C++没有tuple类型，Python中的<code>(5,5)</code>需要在C++中改写为<code>&#123;5, 5&#125;</code>。除此之外，是不是跟Python代码很相似？</p><p>记得保存上面的代码为<code>libtorch_trace.cpp</code>，因为CMake配置中需要写文件名。</p><p>然后在同级目录编写<code>CMakeLists.txt</code>文件:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.0</span> FATAL_ERROR)</span><br><span class="line"><span class="keyword">project</span>(libtorch_trace)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要找到Libtorch</span></span><br><span class="line"><span class="keyword">find_package</span>(Torch REQUIRED)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; $&#123;TORCH_CXX_FLAGS&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> libtorch_trace.cpp)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> <span class="string">&quot;$&#123;TORCH_LIBRARIES&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Libtorch是基于C++14来实现的</span></span><br><span class="line"><span class="keyword">set_property</span>(<span class="keyword">TARGET</span> <span class="variable">$&#123;PROJECT_NAME&#125;</span> PROPERTY CXX_STANDARD <span class="number">14</span>)</span><br></pre></td></tr></table></figure><p>然后执行下面的命令来编译:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line"><span class="comment"># 如果是通过Pytorch</span></span><br><span class="line">cmake -DCMAKE_PREFIX_PATH=`python -c <span class="string">&#x27;import torch;print(torch.utils.cmake_prefix_path)&#x27;</span>` ..</span><br><span class="line"><span class="comment">#下载的单独Libtorch</span></span><br><span class="line"><span class="comment"># cmake -DCMAKE_PREFIX_PATH=&lt;LIBTORCH_ROOT&gt; ..</span></span><br><span class="line">make -j8</span><br></pre></td></tr></table></figure><p>编译完成后使用下面的命令来执行可执行文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./libtorch_trace</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">==&gt; matrix is:</span><br><span class="line">   0   1   2   3   4</span><br><span class="line">  5   6   7   8   9</span><br><span class="line"> 10  11  12  13  14</span><br><span class="line"> 15  16  17  18  19</span><br><span class="line"> 20  21  22  23  24</span><br><span class="line">[ CPULongType&#123;5,5&#125; ]</span><br><span class="line">==&gt; trace of it is:</span><br><span class="line"> 60</span><br><span class="line">[ CPULongType&#123;&#125; ]</span><br></pre></td></tr></table></figure><p>那么我们的第一个例子就完成了。</p><h2 id="4-参考"><a href="#4-参考" class="headerlink" title="4. 参考"></a>4. 参考</h2><ul><li><a href="https://pytorch.org/cppdocs/installing.html">https://pytorch.org/cppdocs/installing.html</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;系列教程列表：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://vra.github.io/2023/02/25/libtorch-tutorial1/&quot;&gt;Libtorch系列教程1：一个丝滑的C++ Tensor库&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://vra.github.io/2023/02/25/libtorch-tutorial2/&quot;&gt;Libtorch系列教程2：torch::Tensor的使用&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://pytorch.org/cppdocs/installing.html&quot;&gt;Libtorch&lt;/a&gt;是Pytorch的C++接口，实现了在C++中进行网络训练、网络推理的功能。&lt;/p&gt;
&lt;p&gt;除此之外，由于Libtorch中的大部份接口都是与Pytorch一致的，所以Libtorch还是一个很强大的张量库，有着类似Pytorch的清晰接口，这在C++中很难得的。如果你用过C++ Tensor库，就会发现写法比较复杂，学习成本。因为强类型的限制和通用容器类型的缺失，C++相比Python天然更复杂，库设计者因为语言使用习惯，以及为了性能等因素，设计的接口一般都是高效但难用的。而Libtorch采用了与Pytorch类似的函数接口，如果你使用过Pytorch的话，使用Libtorch学习成本很低，后面会看到具体的例子。&lt;/p&gt;
&lt;p&gt;另一个问题是，很多Python库中基础的操作，例如&lt;code&gt;numpy.einsum&lt;/code&gt;函数，在C++中没有合适的替代，看看&lt;a href=&quot;https://stackoverflow.com/questions/65347170/numpy-einsum-equivalent-for-xtensor-c&quot;&gt;这些&lt;/a&gt;搜索你就知道了。Libtorch解决了这个问题，Pytorch中有的它都有，所以在C++中可以简单地用&lt;code&gt;torch::einsum&lt;/code&gt;来使用einsum函数，简直是C++开发者的福音。&lt;/p&gt;
&lt;p&gt;此外Libtorch 是支持GPU的，主要用于模型的推理过程，但我猜测使用GPU的话，Libtorch的Tensor操作在速度上相比别的C++ Tensor 库可能有优势，具体速度需要测试对比。当然使用C++代码的话速度不是瓶颈，本身CPU代码就够快了。&lt;/p&gt;
&lt;p&gt;Libtorch另一个优势是编译简单，只要你安装了Pytorch，Libtorch就可以直接使用，省去了复杂的安装和配置，一分钟内就能跑起来一个简单的的示例程序。&lt;/p&gt;
&lt;p&gt;总结来说，Libtorch有以下很吸引人的特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;强大如Numpy和Pytorch的C++ Tensor库，写法优雅丝滑，并且是支持GPU的。&lt;/li&gt;
&lt;li&gt;可以训练神经网络&lt;/li&gt;
&lt;li&gt;可以推理神经网络模型，用在C++环境的模型部署场景&lt;/li&gt;
&lt;li&gt;编译简单&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于Pytorch开发团队是以Python优先的思路来进行Pytorch的开发的，因此我感觉Libtorch的重视程度不是很高，文档和教程也比较少，官网的示例也几乎没有，因此写一个比较完善的教程是比较有意义的。&lt;/p&gt;
&lt;p&gt;这个系列文章中，我会对Libtorch 的Tensor库和推理神经网络过程进行介绍，因为这些内容在实际对于用Libtorch来进行网络训练的部分进行跳过，因为这部分使用的场景不是很多（用Python训练网络比C++香多了)。&lt;/p&gt;
&lt;p&gt;本篇以Mac下的操作为例，对Libtorch的安装和简单使用进行介绍，后续内容近期会更新，敬请关注。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
    <category term="C++" scheme="http://vra.github.io/tags/C/"/>
    
    <category term="Pytorch" scheme="http://vra.github.io/tags/Pytorch/"/>
    
    <category term="Libtorch" scheme="http://vra.github.io/tags/Libtorch/"/>
    
  </entry>
  
  <entry>
    <title>nanoGPT + 鲁迅</title>
    <link href="http://vra.github.io/2023/02/12/nanogpt-and-luxun/"/>
    <id>http://vra.github.io/2023/02/12/nanogpt-and-luxun/</id>
    <published>2023-02-12T15:24:02.000Z</published>
    <updated>2023-02-12T16:33:42.275Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-起因"><a href="#1-起因" class="headerlink" title="1. 起因"></a>1. 起因</h2><p>今晚看到了Simon Willison 的只使用自己的博客内容来训练nanoGPT的<a href="https://til.simonwillison.net/llms/training-nanogpt-on-my-blog">实验</a>，觉得挺有意思，突发奇想，能不能在鲁迅的文集上训练一个nanoGPT，然后生成很具辨识度的鲁迅风格的文字呢？由于nanoGPT结构简单，鲁迅的文集在GitHub上可以下载到，因此通过简单的代码修改加实验，就得到一个在鲁迅作品上训练的GPT2模型(无别的语料库的预训练），简单测试下，以“故乡”开头，让模型生成鲁迅风格的文字：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">故乡，债是佩服的。</span><br><span class="line"> 我一向对于新青年的态度，先来说话，谢容易做的，然而伏园已经见过几样，感觉的是另外捧之数，以为先前的例子。今但近来做了做事，自己也还不做，不能先行通，所以生在冷静和“人生”，三妇一苦闷，觉得大约是如此隔膜</span><br><span class="line">和曹操，于是非意模茶炛，可以说是太高了，所以现在便能教育，竟�如此。</span><br><span class="line"> 但汝实在有给法历代的，不久就在绝末年间，我想显出向大家饮一趟，而汉子大毒是怀旧的，就要贫足有打劫，可以永掠的。这种事情，中国有一个大官左翼阿，（陀思妥习），有敢请佛喜，总要适说一点�</span><br></pre></td></tr></table></figure><p>还算有鲁迅文字的风格，但逻辑一窍不通，整体还是难让人满意，不知道是GPT2能力的问题还是我实验设置的问题。 Anyway，这里共享一下我实验的流程，有兴趣的朋友可以参考，进行改进。本文涉及的代码修改代码已经提交到这个<a href="https://github.com/vra/nanoGPT">仓库了</a>，可以参考，文末会附上更多例子。</p><span id="more"></span><h2 id="2-操作流程"><a href="#2-操作流程" class="headerlink" title="2. 操作流程"></a>2. 操作流程</h2><h3 id="2-1-下载nanoGPT源码并安装依赖"><a href="#2-1-下载nanoGPT源码并安装依赖" class="headerlink" title="2.1 下载nanoGPT源码并安装依赖"></a>2.1 下载nanoGPT源码并安装依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/karpathy/nanoGPT</span><br><span class="line"><span class="built_in">cd</span> nanoGPT</span><br><span class="line">conda create --name nanogpt  python=3.9</span><br><span class="line">conda activate nanogpt</span><br><span class="line">pip install transformers datasets tiktoken tqdm wandb numpy httpx torch torchvision</span><br></pre></td></tr></table></figure><h3 id="2-2-数据预处理"><a href="#2-2-数据预处理" class="headerlink" title="2.2 数据预处理"></a>2.2 数据预处理</h3><p>进入代码目录后，重建文件夹<code>data/lunxun</code>，用于存放数据。</p><p>从<a href="https://github.com/gzx1996/luxun/blob/master/book/book.txt">这里</a>下载鲁迅全集，放到<code>data/luxun</code>目录下，然后进行下面的处理：</p><ul><li>去掉所有编者加的注释(由于注释都是以<code>[n]</code>这种形式开头的，因此在VIM中可以用<code>0,$s/^\[.\+//g</code>命令来去掉)</li><li>由于我们想要的是鲁迅白话文的风格，因此手动去掉所有文言文的作品和翻译作品(文言文在最开头的《坟》集子里，翻译作品在最后)</li><li>去掉单行的日期文字（如<code>(一九一八年二月二日)</code>，可以在VIM中用<code>g/^(一九.\+/d</code>去掉)</li></ul><p>我处理后的文本地址在<a href="https://github.com/vra/nanoGPT/tree/master/data/luxun/book.txt">这里</a>。</p><p>然后编写代码<code>prepare.py</code>, 读取文本，构造训练集和验证集，数据比例9:1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> tiktoken</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">input_file_path = os.path.join(os.path.dirname(__file__), <span class="string">&quot;book.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">entries = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(input_file_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        <span class="keyword">if</span> line.strip() <span class="keyword">and</span> <span class="built_in">len</span>(line) &gt; <span class="number">2</span>:</span><br><span class="line">            entries.append(line)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;len of lines: <span class="subst">&#123;<span class="built_in">len</span>(entries)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Shuffle entries</span></span><br><span class="line">random.shuffle(entries)</span><br><span class="line"></span><br><span class="line">n = <span class="built_in">len</span>(entries)</span><br><span class="line">train_entries = entries[: <span class="built_in">int</span>(n * <span class="number">0.9</span>)]</span><br><span class="line">val_entries = entries[<span class="built_in">int</span>(n * <span class="number">0.9</span>):]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn those into strings</span></span><br><span class="line">train_data = <span class="string">&quot; &quot;</span>.join(<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(entry) <span class="keyword">for</span> entry <span class="keyword">in</span> train_entries)</span><br><span class="line">val_data = <span class="string">&quot; &quot;</span>.join(<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(entry) <span class="keyword">for</span> entry <span class="keyword">in</span> val_entries)</span><br><span class="line"></span><br><span class="line"><span class="comment"># encode with tiktoken gpt2 bpe</span></span><br><span class="line">enc = tiktoken.get_encoding(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line">train_ids = enc.encode_ordinary(train_data)</span><br><span class="line">val_ids = enc.encode_ordinary(val_data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;train has <span class="subst">&#123;<span class="built_in">len</span>(train_ids):,&#125;</span> tokens&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;val has <span class="subst">&#123;<span class="built_in">len</span>(val_ids):,&#125;</span> tokens&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># export to bin files</span></span><br><span class="line">train_ids = np.array(train_ids, dtype=np.uint16)</span><br><span class="line">val_ids = np.array(val_ids, dtype=np.uint16)</span><br><span class="line">train_ids.tofile(os.path.join(os.path.dirname(__file__), <span class="string">&quot;train.bin&quot;</span>))</span><br><span class="line">val_ids.tofile(os.path.join(os.path.dirname(__file__), <span class="string">&quot;val.bin&quot;</span>))</span><br></pre></td></tr></table></figure><p>处理好的训练验证集在<a href="https://github.com/vra/nanoGPT/tree/master/data/luxun">这里</a>，可以直接使用。</p><h3 id="2-3-训练网络"><a href="#2-3-训练网络" class="headerlink" title="2.3 训练网络"></a>2.3 训练网络</h3><p>数据集构建完成后，就可以训练模型了。在代码库根目录，执行下面的命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python train.py \</span><br><span class="line">  --dataset=luxun \</span><br><span class="line">--compile=False \</span><br><span class="line">--batch_size=8 \</span><br><span class="line">--dtype=float16</span><br></pre></td></tr></table></figure><p>具体训练参数可以查看<code>train.py</code>，包括训练的层数、batch size，训练后端等等。</p><p>训练的模型默认保存在<code>out/ckpt.pt</code>。</p><p>训练22000次迭代的时候我停止了实验，loss是0.15左右。</p><h3 id="2-4-测试模型"><a href="#2-4-测试模型" class="headerlink" title="2.4 测试模型"></a>2.4 测试模型</h3><p>测试代码在<code>sample.py</code>，默认提示词为空(<code>start=&#39;\n&#39;</code>)可以通过添加<code>--start=&quot;xxx&quot;</code>来修改提示词:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python sample.py --start=<span class="string">&quot;故乡&quot;</span></span><br></pre></td></tr></table></figure><h2 id="3-更多例子"><a href="#3-更多例子" class="headerlink" title="3. 更多例子"></a>3. 更多例子</h2><h3 id="3-1-人工智能"><a href="#3-1-人工智能" class="headerlink" title="3.1 人工智能"></a>3.1 人工智能</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">人工智能力。两社丈一多，西辛，是发昏了的结果，但去的四五十岁，死的陈源教授却很不通，我也就不再有了。忍不知道阿Ｑ的名字是怎么写的？这不过是一个问境。他总还拿着四个年的过头放在心里，说道，“哀，遇的。他可</span><br><span class="line">是弯口，道是阿Ｑ；近来已经做了杜师长了，半年的大武人，你还和他对面具汗说：‘非常救命！’‘是情愧 夫子’的学理论矛盾的工人，……而且跳不过是这三秒……。”</span><br><span class="line"> 而已 偶战线告了一个大问题，拿去做的纠纷，而他们就癖在《试玈书》的第一幅，来因为又是删节的，还和所放的做。不过如果加以细见，不想多写了东�</span><br></pre></td></tr></table></figure><h3 id="3-2-文艺复兴"><a href="#3-2-文艺复兴" class="headerlink" title="3.2 文艺复兴"></a>3.2 文艺复兴</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">文艺复兴运动，也是指惺把文艺当承受照时代，更易于政治家，中国并不见立刻，万分折中间，更何况失了国家，只有拜读之处，这就是政治心软到新舖式的必读书。……”</span><br><span class="line"> 我们──由此满可知道河南的内心眼和明白的点灵魂。我在曾经想做以看空虚洋，决不叫看情形。因为我想，便可以支持生活的原因，至少，更进一步而到中国来，他们也给了世界上的美�家所指见的最多也并非精微坏，莫非看翻译</span><br><span class="line">，可说是不算太多了。</span><br><span class="line"> 问题。</span><br><span class="line"> “我们没有见过这种东西，便怎么办呢？”</span><br><span class="line"> 递进句也不是有许多话。</span><br><span class="line"> “可以可以，”四铭吃了点</span><br></pre></td></tr></table></figure><h3 id="3-3-新文化"><a href="#3-3-新文化" class="headerlink" title="3.3 新文化"></a>3.3 新文化</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">新文化运动，也许因为他们已经有了“力”这句话的责任了。在那里和他们的风化是并不相禁多的。</span><br><span class="line"> 阿呼呜呼兮呜呼阿呼，</span><br><span class="line"> 八九年</span><br><span class="line"> 二、浙江艳七百</span><br><span class="line"> 一九二五年十二月三十日风雨之夜示，此地声声流鼓近山腌至责诼谢。</span><br><span class="line"> 阿Ｑ的讲到文学说，他们会打断了阿Ｑ的名目退向王的头发，向公司被挤出去了。</span><br><span class="line"> 最末的批评，是“没有话派的书，对于政府来往往解释，加以泄除，以政治的运命，至于失败，那倒是往往会说，我非常危险。</span><br><span class="line"> 小娘枟不用小说的经济字的由校的文章，使是屠戮政府，是凡这些的，但我知道画家一致攻，一致的经历</span><br></pre></td></tr></table></figure><p>如果本文操作中有误的地方，还请专业人士多指出讨论。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-起因&quot;&gt;&lt;a href=&quot;#1-起因&quot; class=&quot;headerlink&quot; title=&quot;1. 起因&quot;&gt;&lt;/a&gt;1. 起因&lt;/h2&gt;&lt;p&gt;今晚看到了Simon Willison 的只使用自己的博客内容来训练nanoGPT的&lt;a href=&quot;https://til.simonwillison.net/llms/training-nanogpt-on-my-blog&quot;&gt;实验&lt;/a&gt;，觉得挺有意思，突发奇想，能不能在鲁迅的文集上训练一个nanoGPT，然后生成很具辨识度的鲁迅风格的文字呢？由于nanoGPT结构简单，鲁迅的文集在GitHub上可以下载到，因此通过简单的代码修改加实验，就得到一个在鲁迅作品上训练的GPT2模型(无别的语料库的预训练），简单测试下，以“故乡”开头，让模型生成鲁迅风格的文字：&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;故乡，债是佩服的。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 我一向对于新青年的态度，先来说话，谢容易做的，然而伏园已经见过几样，感觉的是另外捧之数，以为先前的例子。今但近来做了做事，自己也还不做，不能先行通，所以生在冷静和“人生”，三妇一苦闷，觉得大约是如此隔膜&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;和曹操，于是非意模茶炛，可以说是太高了，所以现在便能教育，竟�如此。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 但汝实在有给法历代的，不久就在绝末年间，我想显出向大家饮一趟，而汉子大毒是怀旧的，就要贫足有打劫，可以永掠的。这种事情，中国有一个大官左翼阿，（陀思妥习），有敢请佛喜，总要适说一点�&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;还算有鲁迅文字的风格，但逻辑一窍不通，整体还是难让人满意，不知道是GPT2能力的问题还是我实验设置的问题。 Anyway，这里共享一下我实验的流程，有兴趣的朋友可以参考，进行改进。本文涉及的代码修改代码已经提交到这个&lt;a href=&quot;https://github.com/vra/nanoGPT&quot;&gt;仓库了&lt;/a&gt;，可以参考，文末会附上更多例子。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
    <category term="AI" scheme="http://vra.github.io/tags/AI/"/>
    
    <category term="GPT" scheme="http://vra.github.io/tags/GPT/"/>
    
    <category term="Pytorch" scheme="http://vra.github.io/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>关于 np.float 被删除的问题</title>
    <link href="http://vra.github.io/2023/02/05/numpy-remove-np-float/"/>
    <id>http://vra.github.io/2023/02/05/numpy-remove-np-float/</id>
    <published>2023-02-05T03:34:04.000Z</published>
    <updated>2023-02-13T08:37:25.163Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h3><p>在Numpy 1.24版本中，<a href="https://numpy.org/doc/stable/release/1.24.0-notes.html#expired-deprecations">删除</a>了像<code>np.float</code>、<code>np.int</code> 这样的 Python 内置类型的 alias，因此以后在代码中使用这些类型会报错<code>AttributeError: module &#39;numpy&#39; has no attribute &#39;float&#39;</code>, 涉及的类型包括：</p><ul><li><code>numpy.bool</code></li><li><code>numpy.int</code></li><li><code>numpy.float</code></li><li><code>numpy.complex</code></li><li><code>numpy.object</code></li><li><code>numpy.str</code></li><li><code>numpy.long</code></li><li><code>numpy.unicode</code></li></ul><p>那该怎么解决这个错误呢？</p><p>TL;DR</p><ul><li>对于在标量上的操作，直接使用Python内置类型替换<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">foo = np.random.rand(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 原先用法，注意foo[0]是一个标量</span></span><br><span class="line">bar = np.<span class="built_in">float</span>(foo[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 新用法</span></span><br><span class="line">bar = <span class="built_in">float</span>(foo[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></li><li>对于在<code>np.ndarray</code> 上的操作，使用<code>np.float64</code> 或<code>np.float32</code> 来替代，具体选择哪个需要自己根据情况来确定，不同类型精度会有不同，下面举两个例子:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原先用法</span></span><br><span class="line">foo = np.random.rand(<span class="number">10</span>, dtype=np.<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># 新用法</span></span><br><span class="line">foo = np.random.rand(<span class="number">10</span>, dtype=np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原先用法</span></span><br><span class="line">foo = np.random.rand(<span class="number">10</span>).astype(np.<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># 新用法</span></span><br><span class="line">foo = np.random.rand(<span class="number">10</span>).astype(np.float32)</span><br></pre></td></tr></table></figure></li></ul><p>这里列出来了删除类型在标量和<code>np.ndarray</code> 上的替代，方便查找</p><table><thead><tr><th>原先类型</th><th>标量替换类型</th><th><code>np.ndarray</code>替换类型</th></tr></thead><tbody><tr><td>np.int</td><td>int</td><td>np.int32/np.int64</td></tr><tr><td>np.float</td><td>float</td><td>np.float32/np.float64</td></tr><tr><td>np.bool</td><td>bool</td><td>np.bool_</td></tr><tr><td>np.complex</td><td>complex</td><td>np.complex128</td></tr><tr><td>np.object</td><td>object</td><td>-</td></tr><tr><td>np.str</td><td>str</td><td>np.str_</td></tr><tr><td>np.long</td><td>int</td><td>np.int32/np.int64</td></tr><tr><td>np.unicode</td><td>str</td><td>np.str_</td></tr></tbody></table><p>详细说明参考<a href="https://numpy.org/doc/stable/release/1.20.0-notes.html#deprecations">NumPy 1.20.0 Release Notes</a>。</p><p>下面详细说说事情的来龙去脉。</p><span id="more"></span><h3 id="2-代码验证"><a href="#2-代码验证" class="headerlink" title="2. 代码验证"></a>2. 代码验证</h3><p>下面我搭建 Numpy 1.20.0 和 1.24.0 的环境进行简单测试，以及分析为什么会弃用这些类型。</p><p>首先是 Numpy 1.20.0 环境搭建与简单测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python -m venv np1.20</span><br><span class="line"><span class="built_in">source</span> np1.20/bin/activate</span><br><span class="line">pip install numpy==1.20</span><br><span class="line">python -c <span class="string">&quot;import numpy as np; a = np.array([1.0], dtype=np.float)&quot;</span></span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;string&gt;:1: DeprecationWarning: `np.float` is a deprecated <span class="built_in">alias</span> <span class="keyword">for</span> the <span class="built_in">builtin</span> `<span class="built_in">float</span>`. To silence this warning, use `<span class="built_in">float</span>` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar <span class="built_in">type</span>, use `np.float64` here.</span><br><span class="line">Deprecated <span class="keyword">in</span> NumPy 1.20; <span class="keyword">for</span> more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html<span class="comment">#deprecations</span></span><br></pre></td></tr></table></figure><p>仔细看这段输出的话，可以发现从 Numpy 1.20 版本开始，Numpy已经弃用<code>np.float</code> 类型了，并且给出了替换建议，以及详细的说明文档<a href="https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations">地址</a>。</p><p>而在 Numpy 1.24版本里面，正式删除了<code>np.float</code>，可以用下面的代码来测试。<br>首先我们创建一个新的环境，安装Numpy 1.24版本，然后创建一个<code>np.float</code>类型的数组：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python -m venv np1.24</span><br><span class="line"><span class="built_in">source</span> np1.24/bin/activate</span><br><span class="line">pip install numpy==1.24</span><br><span class="line">python -c <span class="string">&quot;import numpy as np; a = np.array([1.0], dtype=np.float)&quot;</span></span><br></pre></td></tr></table></figure><p>输出如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;string&gt;&quot;</span>, line 1, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">&quot;/Users/name/np1.24/lib/python3.9/site-packages/numpy/__init__.py&quot;</span>, line 284, <span class="keyword">in</span> __getattr__</span><br><span class="line">    raise AttributeError(<span class="string">&quot;module &#123;!r&#125; has no attribute &quot;</span></span><br><span class="line">AttributeError: module <span class="string">&#x27;numpy&#x27;</span> has no attribute <span class="string">&#x27;float&#x27;</span></span><br></pre></td></tr></table></figure><p>直接就报了我们开头提到的属性错误。</p><h3 id="3-Why"><a href="#3-Why" class="headerlink" title="3. Why"></a>3. Why</h3><p>其实早在2015年，Numpy 开发者就在<a href="https://github.com/numpy/numpy/pull/6103">策划</a>删除这些类型了，只不过当时使用范围太广，删除造成的影响太大，所以在近8年，1.20-1.24 4个版本的Warning后，才正式删除。<br>为什么要删除这些操作呢？我自己觉得是因为<code>np.float</code> 这种类型太容易误用了。大家都以为<code>np.float</code>是一个Numpy的数据类型，是<code>np.float32</code>的alias，但实际它是内置类型，是<code>int</code>类型的alias。<br>就像下面这个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo = np.array([<span class="number">10</span>], dtype=np.int32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bar = np.<span class="built_in">int</span>(foo)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(bar)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">int</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">baz</span> = <span class="title">np</span>.<span class="title">int32</span>(<span class="params">foo</span>)</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">type</span>(<span class="params">baz</span>)</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> &#x27;<span class="title">numpy</span>.<span class="title">ndarray</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure><p>可以看到，对<code>np.ndarray</code> 数组进行<code>np.int</code> 和<code>np.int32</code>的操作，一个得到<code>int</code>类型的变量，另一个得到的是<code>np.ndarray</code>类型的变量。</p><p>详细的原因可以参考上面的 issue 链接。</p><p>那最早为什么还要引入<code>np.float</code>呢？直接用Python内置的类型不好吗？其实这是在很早的Numpy版本中错误地引入的，那个版本<code>np.float</code>的含义就是<code>np.float64</code> ，只不过后来版本中<code>np.float</code> 的含义修改了，但如果直接删除<code>np.float</code>，有人使用老版本的Numpy，就会在执行<code>from numpy import *</code> 报错。当前那个老版本已经很少有人用了 ，所以就删除了。</p><h3 id="4-带来的影响"><a href="#4-带来的影响" class="headerlink" title="4. 带来的影响"></a>4. 带来的影响</h3><p>这个改动带来的影响可以说是非常大了，简单来说，在 Numpy 1.24.0以上的版本中，使用<code>np.float</code>的代码都会直接报错。而 Numpy 作为 Python 在科学计算中的基础包，被广泛使用的程度无需我赘述。<br>简单在GitHub 搜索了一下，光涉及到<code>np.float</code>的(<a href="https://github.com/search?q=np.float)++lang:Python++&ref=opensearch&type=code">结果1</a>， <a href="https://github.com/search?q=np.float(+lang:Python++&ref=opensearch&type=code">结果2</a>）就有近9万行代码，我自己短期内就在两个仓库中遇到这个问题。好在解决办法也比较直接，希望可以顺利的过渡过去。</p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h3&gt;&lt;p&gt;在Numpy 1.24版本中，&lt;a href=&quot;https://numpy.org/doc/stable/release/1.24.0-notes.html#expired-deprecations&quot;&gt;删除&lt;/a&gt;了像&lt;code&gt;np.float&lt;/code&gt;、&lt;code&gt;np.int&lt;/code&gt; 这样的 Python 内置类型的 alias，因此以后在代码中使用这些类型会报错&lt;code&gt;AttributeError: module &amp;#39;numpy&amp;#39; has no attribute &amp;#39;float&amp;#39;&lt;/code&gt;, 涉及的类型包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;numpy.bool&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy.int&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy.float&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy.complex&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy.object&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy.str&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy.long&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy.unicode&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那该怎么解决这个错误呢？&lt;/p&gt;
&lt;p&gt;TL;DR&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于在标量上的操作，直接使用Python内置类型替换&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;foo = np.random.rand(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 原先用法，注意foo[0]是一个标量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bar = np.&lt;span class=&quot;built_in&quot;&gt;float&lt;/span&gt;(foo[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 新用法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bar = &lt;span class=&quot;built_in&quot;&gt;float&lt;/span&gt;(foo[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;对于在&lt;code&gt;np.ndarray&lt;/code&gt; 上的操作，使用&lt;code&gt;np.float64&lt;/code&gt; 或&lt;code&gt;np.float32&lt;/code&gt; 来替代，具体选择哪个需要自己根据情况来确定，不同类型精度会有不同，下面举两个例子:&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 原先用法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;foo = np.random.rand(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;, dtype=np.&lt;span class=&quot;built_in&quot;&gt;float&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 新用法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;foo = np.random.rand(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;, dtype=np.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 原先用法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;foo = np.random.rand(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;).astype(np.&lt;span class=&quot;built_in&quot;&gt;float&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 新用法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;foo = np.random.rand(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;).astype(np.float32)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里列出来了删除类型在标量和&lt;code&gt;np.ndarray&lt;/code&gt; 上的替代，方便查找&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;原先类型&lt;/th&gt;
&lt;th&gt;标量替换类型&lt;/th&gt;
&lt;th&gt;&lt;code&gt;np.ndarray&lt;/code&gt;替换类型&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;np.int&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;np.int32/np.int64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;np.float&lt;/td&gt;
&lt;td&gt;float&lt;/td&gt;
&lt;td&gt;np.float32/np.float64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;np.bool&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;np.bool_&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;np.complex&lt;/td&gt;
&lt;td&gt;complex&lt;/td&gt;
&lt;td&gt;np.complex128&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;np.object&lt;/td&gt;
&lt;td&gt;object&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;np.str&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;np.str_&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;np.long&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;np.int32/np.int64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;np.unicode&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;np.str_&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;详细说明参考&lt;a href=&quot;https://numpy.org/doc/stable/release/1.20.0-notes.html#deprecations&quot;&gt;NumPy 1.20.0 Release Notes&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下面详细说说事情的来龙去脉。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
    <category term="Numpy" scheme="http://vra.github.io/tags/Numpy/"/>
    
  </entry>
  
  <entry>
    <title>手机上看arxiv上论文的方法</title>
    <link href="http://vra.github.io/2023/01/27/arxiv-on-mobile/"/>
    <id>http://vra.github.io/2023/01/27/arxiv-on-mobile/</id>
    <published>2023-01-27T14:44:41.000Z</published>
    <updated>2023-01-27T15:16:22.167Z</updated>
    
    <content type="html"><![CDATA[<p>有时候想要在手机上访问Arxiv上的论文，打开arxiv.com，发现体验比较差，没有响应式设计，需要不断移动页面才能读完一行文字，影响阅读。偶然发现了<a href="https://www.arxiv-vanity.com/">arxiv-vanity</a>这个网站，发现能很好的满足手机上看arxiv论文的需求，收藏了。</p><span id="more"></span><p>首先看下arxiv-vanity网站的介绍:</p><blockquote><p>arXiv Vanity renders academic papers from arXiv as responsive web pages so you don’t have to squint at a PDF.</p></blockquote><p>翻译成中文就是:</p><blockquote><p>arXiv Vanity 将 arXiv 的学术论文呈现为响应式网页，因此您不必眯着眼睛看 PDF。</p></blockquote><p>exactly what I need!</p><p>那么该如何使用呢？</p><p>在<a href="https://www.arxiv-vanity.com/">arxiv-vanity</a>首页的搜索框中输入arxiv论文的摘要页面，如<code>https://arxiv.org/abs/1605.07683</code>，按右边的按钮，就能将论文转换为HTML文件，并且在不同的设备下自适应地调整大小。</p><p>另外也可以通过<code>https://www.arxiv-vanity.com/papers/&lt;paper_id&gt;</code>的方式访问转换后的HTML页面，比如<code>https://www.arxiv-vanity.com/papers/1605.07683/</code>。</p><p>大概原理是使用<a href="https://dlmf.nist.gov/LaTeXML/">LaTeXML</a>将Latex原文件转换为HTML，再进行显示。具体实现参见<a href="https://github.com/arxiv-vanity/engrafo">源码</a>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;有时候想要在手机上访问Arxiv上的论文，打开arxiv.com，发现体验比较差，没有响应式设计，需要不断移动页面才能读完一行文字，影响阅读。偶然发现了&lt;a href=&quot;https://www.arxiv-vanity.com/&quot;&gt;arxiv-vanity&lt;/a&gt;这个网站，发现能很好的满足手机上看arxiv论文的需求，收藏了。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Latex" scheme="http://vra.github.io/tags/Latex/"/>
    
    <category term="HTML" scheme="http://vra.github.io/tags/HTML/"/>
    
    <category term="Web" scheme="http://vra.github.io/tags/Web/"/>
    
    <category term="总结" scheme="http://vra.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Linux小技巧：使用find命令来删除空文件</title>
    <link href="http://vra.github.io/2023/01/20/linux-delete-empty-files/"/>
    <id>http://vra.github.io/2023/01/20/linux-delete-empty-files/</id>
    <published>2023-01-20T06:36:13.000Z</published>
    <updated>2023-01-20T07:16:39.999Z</updated>
    
    <content type="html"><![CDATA[<p>在某个目录下有很多代码创建的空文件，分布在不同层级的子目录中，我们有没有办法可以快速地全部把它们删掉呢？</p><p><a href="https://man7.org/linux/man-pages/man1/find.1.html">find</a>是Linux系统中的一个强大的命令，通过它我们可以找到空文件，然后将它们进行删除。</p><p>TL;DR<br>最终命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -size 0 -<span class="built_in">print</span> -delete</span><br></pre></td></tr></table></figure><p>几个参数详细的说明见下。</p><span id="more"></span><p><code>-type</code>表示匹配项的文件类型，<code>d</code>表示文件夹，<code>f</code>表示文件，<code>l</code>表示软链接等，完整的类型如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">b: block (buffered) special</span><br><span class="line"></span><br><span class="line">c: character (unbuffered) special</span><br><span class="line"></span><br><span class="line">d: directory</span><br><span class="line"></span><br><span class="line">p: named pipe (FIFO)</span><br><span class="line"></span><br><span class="line">f: regular file</span><br><span class="line"></span><br><span class="line">l: symbolic link; this is never true if the -L option</span><br><span class="line"> : or the -follow option is in effect, unless the</span><br><span class="line"> : symbolic link is broken.  If you want to search for</span><br><span class="line"> : symbolic links when -L is in effect, use -xtype.</span><br><span class="line"></span><br><span class="line">s: socket</span><br></pre></td></tr></table></figure><p>所以下面的命令只会列出当前目录下的所有文件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f</span><br></pre></td></tr></table></figure><p><code>-size</code>用来进行文件和目录的大小判断，例如<code>-size 6c</code>表示大小等于6字节，<code>-size -6c</code>表示小于6字节，<code>-size +6c</code>表示大于6字节，大小单位包括：c：字节，w:双字节，k:1024字节，M：1024<em>1024字节，G：1024</em>1024*1024字节，不加单位的话，等于b:512字节:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 寻找当前目录下大小为0的文件或目录</span></span><br><span class="line">find . -size 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 寻找当前目录下小于512字节的文件或目录</span></span><br><span class="line">find . -size -1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 寻找当前目录下大于1字节的文件或目录</span></span><br><span class="line">find . -size +1c</span><br><span class="line"></span><br><span class="line"><span class="comment"># 寻找当前目录下大于1M的文件或目录</span></span><br><span class="line">find . -size +1M</span><br></pre></td></tr></table></figure><p>有了这个选项，就能很容易地过滤出当前目录下的空文件了:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -size 0</span><br></pre></td></tr></table></figure><p>另一个选项是<code>-delete</code>，它的作用是直接删除找到的文件。</p><p>还有一个选项是<code>-print</code>，即打印匹配的文件路径到标准输出。</p><p>结合这几个选项，我们就能删除当前目录下的所有空文件，并且在删除时打印文件名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -size 0 -<span class="built_in">print</span> -delete</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;在某个目录下有很多代码创建的空文件，分布在不同层级的子目录中，我们有没有办法可以快速地全部把它们删掉呢？&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://man7.org/linux/man-pages/man1/find.1.html&quot;&gt;find&lt;/a&gt;是Linux系统中的一个强大的命令，通过它我们可以找到空文件，然后将它们进行删除。&lt;/p&gt;
&lt;p&gt;TL;DR&lt;br&gt;最终命令如下：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;find . -&lt;span class=&quot;built_in&quot;&gt;type&lt;/span&gt; f -size 0 -&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt; -delete&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;几个参数详细的说明见下。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="http://vra.github.io/tags/Linux/"/>
    
    <category term="总结" scheme="http://vra.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
    <category term="find" scheme="http://vra.github.io/tags/find/"/>
    
  </entry>
  
  <entry>
    <title>python 多个with 语句一起使用</title>
    <link href="http://vra.github.io/2023/01/20/python-with-statement/"/>
    <id>http://vra.github.io/2023/01/20/python-with-statement/</id>
    <published>2023-01-20T05:37:24.000Z</published>
    <updated>2023-01-20T05:58:36.949Z</updated>
    
    <content type="html"><![CDATA[<p>在读《流畅的Python》时，偶然看到下面的语句：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> urlopen(URL) <span class="keyword">as</span> remote, <span class="built_in">open</span>(JSON, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> local:</span><br><span class="line">    local.write(remote.read())</span><br></pre></td></tr></table></figure><p>突然才发现，原来多个with语句可以写到一起!</p><span id="more"></span><p>我之前都是每个<code>with</code>一个层级，像下面这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;in_file&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;out_file&#x27;</span> <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> of:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            of.write(line)</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure><p>这样写每个with语句需要缩进一次，阅读起来逻辑不连续，而且很容易超过每行的字符限制，导致需要换行等问题，不是很方便。</p><p>经过这个偶然的发现，以后上面的代码可以这样写了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;in_file&#x27;</span>) <span class="keyword">as</span> f, <span class="built_in">open</span>(<span class="string">&#x27;out_file&#x27;</span> <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> of:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        of.write(line)</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><p>同时看 <code>with</code> 语句的<a href="https://docs.python.org/3/reference/compound_stmts.html#the-with-statement">官方文档</a>，发现从Python 3.10版本起，还可以用括号将多个with语句括起来:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> (</span><br><span class="line">    <span class="built_in">open</span>(<span class="string">&quot;face_model_choice.txt&quot;</span>) <span class="keyword">as</span> f,</span><br><span class="line">    <span class="built_in">open</span>(<span class="string">&quot;ttt.txt&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> of1,</span><br><span class="line">    <span class="built_in">open</span>(<span class="string">&quot;ttt2.txt&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> of2,</span><br><span class="line">):</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        of1.write(line)</span><br><span class="line">        of2.write(line)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这样看起来也更简洁了。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在读《流畅的Python》时，偶然看到下面的语句：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;with&lt;/span&gt; urlopen(URL) &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; remote, &lt;span class=&quot;built_in&quot;&gt;open&lt;/span&gt;(JSON, &lt;span class=&quot;string&quot;&gt;&amp;#x27;wb&amp;#x27;&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; local:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    local.write(remote.read())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;突然才发现，原来多个with语句可以写到一起!&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
    <category term="总结" scheme="http://vra.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
    <category term="TIL" scheme="http://vra.github.io/tags/TIL/"/>
    
  </entry>
  
</feed>
